{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE421 Assignment 1 Linear Regression",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuCPSTLGICtk",
        "colab_type": "code",
        "outputId": "bc241364-7113-4385-9a25-dad9a6c23615",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y24KvnGAINt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData():\n",
        "    with np.load('notMNIST.npz') as data :\n",
        "        Data, Target = data ['images'], data['labels']\n",
        "        posClass = 2\n",
        "        negClass = 9\n",
        "        dataIndx = (Target==posClass) + (Target==negClass)\n",
        "        Data = Data[dataIndx]/255.\n",
        "        Target = Target[dataIndx].reshape(-1, 1)\n",
        "        Target[Target==posClass] = 1\n",
        "        Target[Target==negClass] = 0\n",
        "        np.random.seed(421)\n",
        "        randIndx = np.arange(len(Data))\n",
        "        np.random.shuffle(randIndx)\n",
        "        Data, Target = Data[randIndx], Target[randIndx]\n",
        "        trainData, trainTarget = Data[:3500], Target[:3500]\n",
        "        validData, validTarget = Data[3500:3600], Target[3500:3600]\n",
        "        testData, testTarget = Data[3600:], Target[3600:]\n",
        "    return trainData, validData, testData, trainTarget, validTarget, testTarget"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMpnaSQYLTzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
        "trainData = trainData.reshape(3500,784)\n",
        "validData = validData.reshape(100,784)\n",
        "testData = testData.reshape(145,784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoPyC7xSIP3v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MSE(W, b, x, y, reg):\n",
        "    # Your implementation here\n",
        "    x = np.insert(x, 0, 1, axis=1)\n",
        "    W_b = np.insert(W, 0, b)\n",
        "    y = y.reshape(y.shape[0])\n",
        "    MSE_Loss = (np.linalg.norm(np.dot(x,W_b) - y)**2)/len(x) + (reg/2)*np.linalg.norm(W)**2\n",
        "    return MSE_Loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWljAfQbLHv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradMSE(W, b, x, y, reg):\n",
        "    # Your implementation here\n",
        "    x = np.insert(x, 0, 1, axis=1)\n",
        "    W_b = np.insert(W, 0, b)\n",
        "    y = y.reshape(y.shape[0])\n",
        "    grad_wb = (2*np.dot(np.transpose(x),(np.dot(x,W_b) - y)))/len(x) + reg*W_b\n",
        "    return grad_wb[1:], grad_wb[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uc2Z3PXnvhga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(W, b, x, y):\n",
        "   x = np.insert(x, 0, 1, axis=1)\n",
        "   W_b = np.insert(W, 0, b)\n",
        "   y = y.reshape(y.shape[0])\n",
        "   pred = np.dot(x,W_b)\n",
        "   pred = np.where(pred >= 0.5, 1, 0)\n",
        "   accuracy = np.sum(pred == y)/len(pred)\n",
        "   return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aGV8VkotgAj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad_descent(W, b, x, y, v_x, v_y, test_x, test_y, alpha, epochs, reg, error_tol):\n",
        "    # Your implementation here\n",
        "    training_loss = []\n",
        "    training_accuracy = []\n",
        "    validation_loss = []\n",
        "    validation_accuracy = []\n",
        "    test_loss = []\n",
        "    test_accuracy = []\n",
        "    for i in range(epochs):\n",
        "        dl_dw, dl_db = gradMSE(W, b, x, y, reg) # The gradient based on loss for each image\n",
        "        W_new = W - alpha*(dl_dw) # Updates weights\n",
        "        b -= alpha*(dl_db) # Updates bias\n",
        "\n",
        "        if (np.linalg.norm(W_new - W) < error_tol):\n",
        "            return [W, b, training_loss, validation_loss, test_loss, training_accuracy, validation_accuracy, test_accuracy]\n",
        "  \n",
        "        W = W_new\n",
        "        # Training Loss:\n",
        "        t_accuracy = accuracy(W,b,x,y)\n",
        "        t_loss = MSE(W, b, x, y, reg)\n",
        "        print(\"Epoch: %d, Training Loss: %0.2f, Training Accuracy: %0.2f\" % (i, t_loss, t_accuracy))\n",
        "        training_loss += [t_loss]\n",
        "        training_accuracy += [t_accuracy]\n",
        "\n",
        "        # Validation Loss:\n",
        "        v_accuracy = accuracy(W,b,v_x,v_y)\n",
        "        v_loss = MSE(W, b, v_x, v_y, reg)\n",
        "        print(\"Epoch: %d, Validation Loss: %0.2f, Validation Accuracy: %0.2f\" % (i, v_loss, v_accuracy))\n",
        "        validation_loss += [v_loss]\n",
        "        validation_accuracy += [v_accuracy]\n",
        "\n",
        "        # Testing Loss:\n",
        "        test_acc = accuracy(W,b,test_x,test_y)\n",
        "        te_loss = MSE(W, b, test_x, test_y, reg)\n",
        "        print(\"Epoch: %d, Testing Loss: %0.2f, Testing Accuracy: %0.2f\" % (i, te_loss, test_acc))\n",
        "        test_loss += [te_loss]\n",
        "        test_accuracy += [test_acc]\n",
        "      \n",
        "    return [W, b, training_loss, validation_loss, test_loss, training_accuracy, validation_accuracy, test_accuracy]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1hhsAQlmapX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize Parameters and Hyperparameters:\n",
        "W_i = np.random.rand(28*28)\n",
        "W_i = W_i/np.linalg.norm(W_i)\n",
        "b_i = 0\n",
        "l_r = [0.005, 0.001, 0.0001]\n",
        "reg = 0 #[0.001, 0.1, 0.5]\n",
        "epochs = 5000\n",
        "error_tol = 10**-7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO5ctPwezeSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Collecting the data:\n",
        "\n",
        "weight = np.empty([len(l_r), 28*28])\n",
        "bias = np.empty([len(l_r), 1])\n",
        "training_error = np.empty([len(l_r), epochs])\n",
        "training_accuracy = np.empty([len(l_r), epochs])\n",
        "validation_error = np.empty([len(l_r), epochs])\n",
        "validation_accuracy = np.empty([len(l_r), epochs])\n",
        "testing_error = np.empty([len(l_r), epochs])\n",
        "testing_accuracy = np.empty([len(l_r), epochs])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6__tNiPWxIjP",
        "colab_type": "code",
        "outputId": "1e85ce71-4037-4c09-c174-5923384eed3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "W = W_i\n",
        "b = b_i\n",
        "r = 1\n",
        "[weight[r], bias[r], training_error[r], validation_error[r], testing_error[r], training_accuracy[r], validation_accuracy[r], testing_accuracy[r]] = grad_descent(W, b, trainData, trainTarget, validData, validTarget, testData, testTarget, l_r[r], epochs, reg, error_tol)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Training Loss: 42.43, Training Accuracy: 0.50\n",
            "Epoch: 0, Validation Loss: 46.06, Validation Accuracy: 0.51\n",
            "Epoch: 0, Testing Loss: 45.15, Testing Accuracy: 0.45\n",
            "Epoch: 1, Training Loss: 22.78, Training Accuracy: 0.50\n",
            "Epoch: 1, Validation Loss: 25.41, Validation Accuracy: 0.51\n",
            "Epoch: 1, Testing Loss: 24.29, Testing Accuracy: 0.45\n",
            "Epoch: 2, Training Loss: 12.42, Training Accuracy: 0.50\n",
            "Epoch: 2, Validation Loss: 14.37, Validation Accuracy: 0.51\n",
            "Epoch: 2, Testing Loss: 13.27, Testing Accuracy: 0.45\n",
            "Epoch: 3, Training Loss: 6.94, Training Accuracy: 0.50\n",
            "Epoch: 3, Validation Loss: 8.43, Validation Accuracy: 0.52\n",
            "Epoch: 3, Testing Loss: 7.43, Testing Accuracy: 0.46\n",
            "Epoch: 4, Training Loss: 4.04, Training Accuracy: 0.50\n",
            "Epoch: 4, Validation Loss: 5.19, Validation Accuracy: 0.52\n",
            "Epoch: 4, Testing Loss: 4.32, Testing Accuracy: 0.46\n",
            "Epoch: 5, Training Loss: 2.49, Training Accuracy: 0.51\n",
            "Epoch: 5, Validation Loss: 3.41, Validation Accuracy: 0.52\n",
            "Epoch: 5, Testing Loss: 2.66, Testing Accuracy: 0.49\n",
            "Epoch: 6, Training Loss: 1.66, Training Accuracy: 0.51\n",
            "Epoch: 6, Validation Loss: 2.41, Validation Accuracy: 0.48\n",
            "Epoch: 6, Testing Loss: 1.77, Testing Accuracy: 0.52\n",
            "Epoch: 7, Training Loss: 1.21, Training Accuracy: 0.51\n",
            "Epoch: 7, Validation Loss: 1.83, Validation Accuracy: 0.54\n",
            "Epoch: 7, Testing Loss: 1.28, Testing Accuracy: 0.53\n",
            "Epoch: 8, Training Loss: 0.95, Training Accuracy: 0.51\n",
            "Epoch: 8, Validation Loss: 1.49, Validation Accuracy: 0.51\n",
            "Epoch: 8, Testing Loss: 1.00, Testing Accuracy: 0.54\n",
            "Epoch: 9, Training Loss: 0.80, Training Accuracy: 0.53\n",
            "Epoch: 9, Validation Loss: 1.27, Validation Accuracy: 0.48\n",
            "Epoch: 9, Testing Loss: 0.84, Testing Accuracy: 0.56\n",
            "Epoch: 10, Training Loss: 0.71, Training Accuracy: 0.56\n",
            "Epoch: 10, Validation Loss: 1.13, Validation Accuracy: 0.49\n",
            "Epoch: 10, Testing Loss: 0.75, Testing Accuracy: 0.56\n",
            "Epoch: 11, Training Loss: 0.65, Training Accuracy: 0.58\n",
            "Epoch: 11, Validation Loss: 1.03, Validation Accuracy: 0.50\n",
            "Epoch: 11, Testing Loss: 0.68, Testing Accuracy: 0.57\n",
            "Epoch: 12, Training Loss: 0.61, Training Accuracy: 0.59\n",
            "Epoch: 12, Validation Loss: 0.96, Validation Accuracy: 0.53\n",
            "Epoch: 12, Testing Loss: 0.64, Testing Accuracy: 0.60\n",
            "Epoch: 13, Training Loss: 0.58, Training Accuracy: 0.60\n",
            "Epoch: 13, Validation Loss: 0.90, Validation Accuracy: 0.53\n",
            "Epoch: 13, Testing Loss: 0.61, Testing Accuracy: 0.62\n",
            "Epoch: 14, Training Loss: 0.55, Training Accuracy: 0.61\n",
            "Epoch: 14, Validation Loss: 0.85, Validation Accuracy: 0.53\n",
            "Epoch: 14, Testing Loss: 0.59, Testing Accuracy: 0.63\n",
            "Epoch: 15, Training Loss: 0.53, Training Accuracy: 0.62\n",
            "Epoch: 15, Validation Loss: 0.81, Validation Accuracy: 0.55\n",
            "Epoch: 15, Testing Loss: 0.57, Testing Accuracy: 0.63\n",
            "Epoch: 16, Training Loss: 0.51, Training Accuracy: 0.63\n",
            "Epoch: 16, Validation Loss: 0.78, Validation Accuracy: 0.56\n",
            "Epoch: 16, Testing Loss: 0.55, Testing Accuracy: 0.65\n",
            "Epoch: 17, Training Loss: 0.50, Training Accuracy: 0.64\n",
            "Epoch: 17, Validation Loss: 0.75, Validation Accuracy: 0.56\n",
            "Epoch: 17, Testing Loss: 0.53, Testing Accuracy: 0.66\n",
            "Epoch: 18, Training Loss: 0.48, Training Accuracy: 0.65\n",
            "Epoch: 18, Validation Loss: 0.72, Validation Accuracy: 0.56\n",
            "Epoch: 18, Testing Loss: 0.52, Testing Accuracy: 0.67\n",
            "Epoch: 19, Training Loss: 0.47, Training Accuracy: 0.66\n",
            "Epoch: 19, Validation Loss: 0.70, Validation Accuracy: 0.57\n",
            "Epoch: 19, Testing Loss: 0.50, Testing Accuracy: 0.68\n",
            "Epoch: 20, Training Loss: 0.45, Training Accuracy: 0.67\n",
            "Epoch: 20, Validation Loss: 0.68, Validation Accuracy: 0.59\n",
            "Epoch: 20, Testing Loss: 0.49, Testing Accuracy: 0.69\n",
            "Epoch: 21, Training Loss: 0.44, Training Accuracy: 0.67\n",
            "Epoch: 21, Validation Loss: 0.66, Validation Accuracy: 0.59\n",
            "Epoch: 21, Testing Loss: 0.48, Testing Accuracy: 0.70\n",
            "Epoch: 22, Training Loss: 0.43, Training Accuracy: 0.68\n",
            "Epoch: 22, Validation Loss: 0.64, Validation Accuracy: 0.61\n",
            "Epoch: 22, Testing Loss: 0.47, Testing Accuracy: 0.72\n",
            "Epoch: 23, Training Loss: 0.42, Training Accuracy: 0.68\n",
            "Epoch: 23, Validation Loss: 0.62, Validation Accuracy: 0.62\n",
            "Epoch: 23, Testing Loss: 0.46, Testing Accuracy: 0.72\n",
            "Epoch: 24, Training Loss: 0.41, Training Accuracy: 0.69\n",
            "Epoch: 24, Validation Loss: 0.60, Validation Accuracy: 0.62\n",
            "Epoch: 24, Testing Loss: 0.45, Testing Accuracy: 0.72\n",
            "Epoch: 25, Training Loss: 0.40, Training Accuracy: 0.69\n",
            "Epoch: 25, Validation Loss: 0.59, Validation Accuracy: 0.63\n",
            "Epoch: 25, Testing Loss: 0.44, Testing Accuracy: 0.72\n",
            "Epoch: 26, Training Loss: 0.39, Training Accuracy: 0.70\n",
            "Epoch: 26, Validation Loss: 0.57, Validation Accuracy: 0.64\n",
            "Epoch: 26, Testing Loss: 0.43, Testing Accuracy: 0.72\n",
            "Epoch: 27, Training Loss: 0.38, Training Accuracy: 0.71\n",
            "Epoch: 27, Validation Loss: 0.56, Validation Accuracy: 0.64\n",
            "Epoch: 27, Testing Loss: 0.42, Testing Accuracy: 0.75\n",
            "Epoch: 28, Training Loss: 0.37, Training Accuracy: 0.71\n",
            "Epoch: 28, Validation Loss: 0.54, Validation Accuracy: 0.64\n",
            "Epoch: 28, Testing Loss: 0.41, Testing Accuracy: 0.77\n",
            "Epoch: 29, Training Loss: 0.37, Training Accuracy: 0.72\n",
            "Epoch: 29, Validation Loss: 0.53, Validation Accuracy: 0.66\n",
            "Epoch: 29, Testing Loss: 0.41, Testing Accuracy: 0.77\n",
            "Epoch: 30, Training Loss: 0.36, Training Accuracy: 0.72\n",
            "Epoch: 30, Validation Loss: 0.52, Validation Accuracy: 0.66\n",
            "Epoch: 30, Testing Loss: 0.40, Testing Accuracy: 0.78\n",
            "Epoch: 31, Training Loss: 0.35, Training Accuracy: 0.73\n",
            "Epoch: 31, Validation Loss: 0.51, Validation Accuracy: 0.67\n",
            "Epoch: 31, Testing Loss: 0.39, Testing Accuracy: 0.78\n",
            "Epoch: 32, Training Loss: 0.34, Training Accuracy: 0.73\n",
            "Epoch: 32, Validation Loss: 0.50, Validation Accuracy: 0.68\n",
            "Epoch: 32, Testing Loss: 0.38, Testing Accuracy: 0.79\n",
            "Epoch: 33, Training Loss: 0.34, Training Accuracy: 0.74\n",
            "Epoch: 33, Validation Loss: 0.49, Validation Accuracy: 0.69\n",
            "Epoch: 33, Testing Loss: 0.38, Testing Accuracy: 0.80\n",
            "Epoch: 34, Training Loss: 0.33, Training Accuracy: 0.74\n",
            "Epoch: 34, Validation Loss: 0.48, Validation Accuracy: 0.70\n",
            "Epoch: 34, Testing Loss: 0.37, Testing Accuracy: 0.80\n",
            "Epoch: 35, Training Loss: 0.32, Training Accuracy: 0.75\n",
            "Epoch: 35, Validation Loss: 0.47, Validation Accuracy: 0.70\n",
            "Epoch: 35, Testing Loss: 0.36, Testing Accuracy: 0.80\n",
            "Epoch: 36, Training Loss: 0.32, Training Accuracy: 0.75\n",
            "Epoch: 36, Validation Loss: 0.46, Validation Accuracy: 0.70\n",
            "Epoch: 36, Testing Loss: 0.36, Testing Accuracy: 0.81\n",
            "Epoch: 37, Training Loss: 0.31, Training Accuracy: 0.76\n",
            "Epoch: 37, Validation Loss: 0.45, Validation Accuracy: 0.70\n",
            "Epoch: 37, Testing Loss: 0.35, Testing Accuracy: 0.82\n",
            "Epoch: 38, Training Loss: 0.31, Training Accuracy: 0.76\n",
            "Epoch: 38, Validation Loss: 0.44, Validation Accuracy: 0.70\n",
            "Epoch: 38, Testing Loss: 0.35, Testing Accuracy: 0.82\n",
            "Epoch: 39, Training Loss: 0.30, Training Accuracy: 0.77\n",
            "Epoch: 39, Validation Loss: 0.43, Validation Accuracy: 0.71\n",
            "Epoch: 39, Testing Loss: 0.34, Testing Accuracy: 0.82\n",
            "Epoch: 40, Training Loss: 0.30, Training Accuracy: 0.77\n",
            "Epoch: 40, Validation Loss: 0.42, Validation Accuracy: 0.72\n",
            "Epoch: 40, Testing Loss: 0.33, Testing Accuracy: 0.82\n",
            "Epoch: 41, Training Loss: 0.29, Training Accuracy: 0.78\n",
            "Epoch: 41, Validation Loss: 0.41, Validation Accuracy: 0.72\n",
            "Epoch: 41, Testing Loss: 0.33, Testing Accuracy: 0.83\n",
            "Epoch: 42, Training Loss: 0.29, Training Accuracy: 0.78\n",
            "Epoch: 42, Validation Loss: 0.41, Validation Accuracy: 0.73\n",
            "Epoch: 42, Testing Loss: 0.32, Testing Accuracy: 0.82\n",
            "Epoch: 43, Training Loss: 0.28, Training Accuracy: 0.78\n",
            "Epoch: 43, Validation Loss: 0.40, Validation Accuracy: 0.73\n",
            "Epoch: 43, Testing Loss: 0.32, Testing Accuracy: 0.83\n",
            "Epoch: 44, Training Loss: 0.28, Training Accuracy: 0.79\n",
            "Epoch: 44, Validation Loss: 0.39, Validation Accuracy: 0.75\n",
            "Epoch: 44, Testing Loss: 0.31, Testing Accuracy: 0.83\n",
            "Epoch: 45, Training Loss: 0.27, Training Accuracy: 0.79\n",
            "Epoch: 45, Validation Loss: 0.39, Validation Accuracy: 0.75\n",
            "Epoch: 45, Testing Loss: 0.31, Testing Accuracy: 0.83\n",
            "Epoch: 46, Training Loss: 0.27, Training Accuracy: 0.79\n",
            "Epoch: 46, Validation Loss: 0.38, Validation Accuracy: 0.75\n",
            "Epoch: 46, Testing Loss: 0.30, Testing Accuracy: 0.83\n",
            "Epoch: 47, Training Loss: 0.26, Training Accuracy: 0.79\n",
            "Epoch: 47, Validation Loss: 0.37, Validation Accuracy: 0.75\n",
            "Epoch: 47, Testing Loss: 0.30, Testing Accuracy: 0.84\n",
            "Epoch: 48, Training Loss: 0.26, Training Accuracy: 0.80\n",
            "Epoch: 48, Validation Loss: 0.37, Validation Accuracy: 0.76\n",
            "Epoch: 48, Testing Loss: 0.30, Testing Accuracy: 0.84\n",
            "Epoch: 49, Training Loss: 0.25, Training Accuracy: 0.80\n",
            "Epoch: 49, Validation Loss: 0.36, Validation Accuracy: 0.77\n",
            "Epoch: 49, Testing Loss: 0.29, Testing Accuracy: 0.85\n",
            "Epoch: 50, Training Loss: 0.25, Training Accuracy: 0.80\n",
            "Epoch: 50, Validation Loss: 0.35, Validation Accuracy: 0.78\n",
            "Epoch: 50, Testing Loss: 0.29, Testing Accuracy: 0.85\n",
            "Epoch: 51, Training Loss: 0.25, Training Accuracy: 0.81\n",
            "Epoch: 51, Validation Loss: 0.35, Validation Accuracy: 0.78\n",
            "Epoch: 51, Testing Loss: 0.28, Testing Accuracy: 0.85\n",
            "Epoch: 52, Training Loss: 0.24, Training Accuracy: 0.81\n",
            "Epoch: 52, Validation Loss: 0.34, Validation Accuracy: 0.78\n",
            "Epoch: 52, Testing Loss: 0.28, Testing Accuracy: 0.85\n",
            "Epoch: 53, Training Loss: 0.24, Training Accuracy: 0.81\n",
            "Epoch: 53, Validation Loss: 0.34, Validation Accuracy: 0.78\n",
            "Epoch: 53, Testing Loss: 0.27, Testing Accuracy: 0.86\n",
            "Epoch: 54, Training Loss: 0.24, Training Accuracy: 0.81\n",
            "Epoch: 54, Validation Loss: 0.33, Validation Accuracy: 0.78\n",
            "Epoch: 54, Testing Loss: 0.27, Testing Accuracy: 0.86\n",
            "Epoch: 55, Training Loss: 0.23, Training Accuracy: 0.82\n",
            "Epoch: 55, Validation Loss: 0.33, Validation Accuracy: 0.78\n",
            "Epoch: 55, Testing Loss: 0.27, Testing Accuracy: 0.86\n",
            "Epoch: 56, Training Loss: 0.23, Training Accuracy: 0.82\n",
            "Epoch: 56, Validation Loss: 0.32, Validation Accuracy: 0.78\n",
            "Epoch: 56, Testing Loss: 0.26, Testing Accuracy: 0.86\n",
            "Epoch: 57, Training Loss: 0.23, Training Accuracy: 0.82\n",
            "Epoch: 57, Validation Loss: 0.32, Validation Accuracy: 0.78\n",
            "Epoch: 57, Testing Loss: 0.26, Testing Accuracy: 0.86\n",
            "Epoch: 58, Training Loss: 0.22, Training Accuracy: 0.82\n",
            "Epoch: 58, Validation Loss: 0.31, Validation Accuracy: 0.78\n",
            "Epoch: 58, Testing Loss: 0.26, Testing Accuracy: 0.86\n",
            "Epoch: 59, Training Loss: 0.22, Training Accuracy: 0.83\n",
            "Epoch: 59, Validation Loss: 0.31, Validation Accuracy: 0.78\n",
            "Epoch: 59, Testing Loss: 0.25, Testing Accuracy: 0.86\n",
            "Epoch: 60, Training Loss: 0.22, Training Accuracy: 0.83\n",
            "Epoch: 60, Validation Loss: 0.30, Validation Accuracy: 0.78\n",
            "Epoch: 60, Testing Loss: 0.25, Testing Accuracy: 0.86\n",
            "Epoch: 61, Training Loss: 0.21, Training Accuracy: 0.83\n",
            "Epoch: 61, Validation Loss: 0.30, Validation Accuracy: 0.79\n",
            "Epoch: 61, Testing Loss: 0.25, Testing Accuracy: 0.86\n",
            "Epoch: 62, Training Loss: 0.21, Training Accuracy: 0.83\n",
            "Epoch: 62, Validation Loss: 0.30, Validation Accuracy: 0.79\n",
            "Epoch: 62, Testing Loss: 0.24, Testing Accuracy: 0.86\n",
            "Epoch: 63, Training Loss: 0.21, Training Accuracy: 0.83\n",
            "Epoch: 63, Validation Loss: 0.29, Validation Accuracy: 0.79\n",
            "Epoch: 63, Testing Loss: 0.24, Testing Accuracy: 0.86\n",
            "Epoch: 64, Training Loss: 0.20, Training Accuracy: 0.84\n",
            "Epoch: 64, Validation Loss: 0.29, Validation Accuracy: 0.80\n",
            "Epoch: 64, Testing Loss: 0.24, Testing Accuracy: 0.86\n",
            "Epoch: 65, Training Loss: 0.20, Training Accuracy: 0.84\n",
            "Epoch: 65, Validation Loss: 0.28, Validation Accuracy: 0.81\n",
            "Epoch: 65, Testing Loss: 0.23, Testing Accuracy: 0.86\n",
            "Epoch: 66, Training Loss: 0.20, Training Accuracy: 0.84\n",
            "Epoch: 66, Validation Loss: 0.28, Validation Accuracy: 0.82\n",
            "Epoch: 66, Testing Loss: 0.23, Testing Accuracy: 0.86\n",
            "Epoch: 67, Training Loss: 0.20, Training Accuracy: 0.84\n",
            "Epoch: 67, Validation Loss: 0.28, Validation Accuracy: 0.82\n",
            "Epoch: 67, Testing Loss: 0.23, Testing Accuracy: 0.86\n",
            "Epoch: 68, Training Loss: 0.19, Training Accuracy: 0.85\n",
            "Epoch: 68, Validation Loss: 0.27, Validation Accuracy: 0.82\n",
            "Epoch: 68, Testing Loss: 0.22, Testing Accuracy: 0.86\n",
            "Epoch: 69, Training Loss: 0.19, Training Accuracy: 0.85\n",
            "Epoch: 69, Validation Loss: 0.27, Validation Accuracy: 0.82\n",
            "Epoch: 69, Testing Loss: 0.22, Testing Accuracy: 0.88\n",
            "Epoch: 70, Training Loss: 0.19, Training Accuracy: 0.85\n",
            "Epoch: 70, Validation Loss: 0.26, Validation Accuracy: 0.82\n",
            "Epoch: 70, Testing Loss: 0.22, Testing Accuracy: 0.88\n",
            "Epoch: 71, Training Loss: 0.19, Training Accuracy: 0.85\n",
            "Epoch: 71, Validation Loss: 0.26, Validation Accuracy: 0.82\n",
            "Epoch: 71, Testing Loss: 0.22, Testing Accuracy: 0.88\n",
            "Epoch: 72, Training Loss: 0.18, Training Accuracy: 0.85\n",
            "Epoch: 72, Validation Loss: 0.26, Validation Accuracy: 0.82\n",
            "Epoch: 72, Testing Loss: 0.21, Testing Accuracy: 0.88\n",
            "Epoch: 73, Training Loss: 0.18, Training Accuracy: 0.85\n",
            "Epoch: 73, Validation Loss: 0.25, Validation Accuracy: 0.82\n",
            "Epoch: 73, Testing Loss: 0.21, Testing Accuracy: 0.88\n",
            "Epoch: 74, Training Loss: 0.18, Training Accuracy: 0.86\n",
            "Epoch: 74, Validation Loss: 0.25, Validation Accuracy: 0.82\n",
            "Epoch: 74, Testing Loss: 0.21, Testing Accuracy: 0.88\n",
            "Epoch: 75, Training Loss: 0.18, Training Accuracy: 0.86\n",
            "Epoch: 75, Validation Loss: 0.25, Validation Accuracy: 0.82\n",
            "Epoch: 75, Testing Loss: 0.21, Testing Accuracy: 0.88\n",
            "Epoch: 76, Training Loss: 0.18, Training Accuracy: 0.86\n",
            "Epoch: 76, Validation Loss: 0.25, Validation Accuracy: 0.82\n",
            "Epoch: 76, Testing Loss: 0.20, Testing Accuracy: 0.88\n",
            "Epoch: 77, Training Loss: 0.17, Training Accuracy: 0.86\n",
            "Epoch: 77, Validation Loss: 0.24, Validation Accuracy: 0.82\n",
            "Epoch: 77, Testing Loss: 0.20, Testing Accuracy: 0.88\n",
            "Epoch: 78, Training Loss: 0.17, Training Accuracy: 0.86\n",
            "Epoch: 78, Validation Loss: 0.24, Validation Accuracy: 0.82\n",
            "Epoch: 78, Testing Loss: 0.20, Testing Accuracy: 0.88\n",
            "Epoch: 79, Training Loss: 0.17, Training Accuracy: 0.86\n",
            "Epoch: 79, Validation Loss: 0.24, Validation Accuracy: 0.82\n",
            "Epoch: 79, Testing Loss: 0.20, Testing Accuracy: 0.88\n",
            "Epoch: 80, Training Loss: 0.17, Training Accuracy: 0.86\n",
            "Epoch: 80, Validation Loss: 0.23, Validation Accuracy: 0.82\n",
            "Epoch: 80, Testing Loss: 0.20, Testing Accuracy: 0.88\n",
            "Epoch: 81, Training Loss: 0.17, Training Accuracy: 0.86\n",
            "Epoch: 81, Validation Loss: 0.23, Validation Accuracy: 0.83\n",
            "Epoch: 81, Testing Loss: 0.19, Testing Accuracy: 0.88\n",
            "Epoch: 82, Training Loss: 0.16, Training Accuracy: 0.86\n",
            "Epoch: 82, Validation Loss: 0.23, Validation Accuracy: 0.84\n",
            "Epoch: 82, Testing Loss: 0.19, Testing Accuracy: 0.88\n",
            "Epoch: 83, Training Loss: 0.16, Training Accuracy: 0.87\n",
            "Epoch: 83, Validation Loss: 0.23, Validation Accuracy: 0.84\n",
            "Epoch: 83, Testing Loss: 0.19, Testing Accuracy: 0.88\n",
            "Epoch: 84, Training Loss: 0.16, Training Accuracy: 0.87\n",
            "Epoch: 84, Validation Loss: 0.22, Validation Accuracy: 0.84\n",
            "Epoch: 84, Testing Loss: 0.19, Testing Accuracy: 0.88\n",
            "Epoch: 85, Training Loss: 0.16, Training Accuracy: 0.87\n",
            "Epoch: 85, Validation Loss: 0.22, Validation Accuracy: 0.84\n",
            "Epoch: 85, Testing Loss: 0.19, Testing Accuracy: 0.88\n",
            "Epoch: 86, Training Loss: 0.16, Training Accuracy: 0.87\n",
            "Epoch: 86, Validation Loss: 0.22, Validation Accuracy: 0.84\n",
            "Epoch: 86, Testing Loss: 0.18, Testing Accuracy: 0.88\n",
            "Epoch: 87, Training Loss: 0.16, Training Accuracy: 0.87\n",
            "Epoch: 87, Validation Loss: 0.22, Validation Accuracy: 0.84\n",
            "Epoch: 87, Testing Loss: 0.18, Testing Accuracy: 0.88\n",
            "Epoch: 88, Training Loss: 0.15, Training Accuracy: 0.87\n",
            "Epoch: 88, Validation Loss: 0.21, Validation Accuracy: 0.84\n",
            "Epoch: 88, Testing Loss: 0.18, Testing Accuracy: 0.88\n",
            "Epoch: 89, Training Loss: 0.15, Training Accuracy: 0.88\n",
            "Epoch: 89, Validation Loss: 0.21, Validation Accuracy: 0.84\n",
            "Epoch: 89, Testing Loss: 0.18, Testing Accuracy: 0.88\n",
            "Epoch: 90, Training Loss: 0.15, Training Accuracy: 0.88\n",
            "Epoch: 90, Validation Loss: 0.21, Validation Accuracy: 0.84\n",
            "Epoch: 90, Testing Loss: 0.18, Testing Accuracy: 0.88\n",
            "Epoch: 91, Training Loss: 0.15, Training Accuracy: 0.88\n",
            "Epoch: 91, Validation Loss: 0.21, Validation Accuracy: 0.84\n",
            "Epoch: 91, Testing Loss: 0.17, Testing Accuracy: 0.89\n",
            "Epoch: 92, Training Loss: 0.15, Training Accuracy: 0.88\n",
            "Epoch: 92, Validation Loss: 0.21, Validation Accuracy: 0.84\n",
            "Epoch: 92, Testing Loss: 0.17, Testing Accuracy: 0.90\n",
            "Epoch: 93, Training Loss: 0.15, Training Accuracy: 0.88\n",
            "Epoch: 93, Validation Loss: 0.20, Validation Accuracy: 0.84\n",
            "Epoch: 93, Testing Loss: 0.17, Testing Accuracy: 0.90\n",
            "Epoch: 94, Training Loss: 0.15, Training Accuracy: 0.88\n",
            "Epoch: 94, Validation Loss: 0.20, Validation Accuracy: 0.84\n",
            "Epoch: 94, Testing Loss: 0.17, Testing Accuracy: 0.90\n",
            "Epoch: 95, Training Loss: 0.14, Training Accuracy: 0.88\n",
            "Epoch: 95, Validation Loss: 0.20, Validation Accuracy: 0.85\n",
            "Epoch: 95, Testing Loss: 0.17, Testing Accuracy: 0.90\n",
            "Epoch: 96, Training Loss: 0.14, Training Accuracy: 0.88\n",
            "Epoch: 96, Validation Loss: 0.20, Validation Accuracy: 0.85\n",
            "Epoch: 96, Testing Loss: 0.17, Testing Accuracy: 0.90\n",
            "Epoch: 97, Training Loss: 0.14, Training Accuracy: 0.88\n",
            "Epoch: 97, Validation Loss: 0.20, Validation Accuracy: 0.85\n",
            "Epoch: 97, Testing Loss: 0.16, Testing Accuracy: 0.90\n",
            "Epoch: 98, Training Loss: 0.14, Training Accuracy: 0.88\n",
            "Epoch: 98, Validation Loss: 0.19, Validation Accuracy: 0.85\n",
            "Epoch: 98, Testing Loss: 0.16, Testing Accuracy: 0.90\n",
            "Epoch: 99, Training Loss: 0.14, Training Accuracy: 0.88\n",
            "Epoch: 99, Validation Loss: 0.19, Validation Accuracy: 0.85\n",
            "Epoch: 99, Testing Loss: 0.16, Testing Accuracy: 0.90\n",
            "Epoch: 100, Training Loss: 0.14, Training Accuracy: 0.88\n",
            "Epoch: 100, Validation Loss: 0.19, Validation Accuracy: 0.85\n",
            "Epoch: 100, Testing Loss: 0.16, Testing Accuracy: 0.90\n",
            "Epoch: 101, Training Loss: 0.14, Training Accuracy: 0.89\n",
            "Epoch: 101, Validation Loss: 0.19, Validation Accuracy: 0.85\n",
            "Epoch: 101, Testing Loss: 0.16, Testing Accuracy: 0.90\n",
            "Epoch: 102, Training Loss: 0.14, Training Accuracy: 0.89\n",
            "Epoch: 102, Validation Loss: 0.19, Validation Accuracy: 0.86\n",
            "Epoch: 102, Testing Loss: 0.16, Testing Accuracy: 0.90\n",
            "Epoch: 103, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 103, Validation Loss: 0.18, Validation Accuracy: 0.86\n",
            "Epoch: 103, Testing Loss: 0.16, Testing Accuracy: 0.90\n",
            "Epoch: 104, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 104, Validation Loss: 0.18, Validation Accuracy: 0.86\n",
            "Epoch: 104, Testing Loss: 0.16, Testing Accuracy: 0.90\n",
            "Epoch: 105, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 105, Validation Loss: 0.18, Validation Accuracy: 0.86\n",
            "Epoch: 105, Testing Loss: 0.15, Testing Accuracy: 0.90\n",
            "Epoch: 106, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 106, Validation Loss: 0.18, Validation Accuracy: 0.86\n",
            "Epoch: 106, Testing Loss: 0.15, Testing Accuracy: 0.90\n",
            "Epoch: 107, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 107, Validation Loss: 0.18, Validation Accuracy: 0.86\n",
            "Epoch: 107, Testing Loss: 0.15, Testing Accuracy: 0.90\n",
            "Epoch: 108, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 108, Validation Loss: 0.18, Validation Accuracy: 0.86\n",
            "Epoch: 108, Testing Loss: 0.15, Testing Accuracy: 0.90\n",
            "Epoch: 109, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 109, Validation Loss: 0.17, Validation Accuracy: 0.86\n",
            "Epoch: 109, Testing Loss: 0.15, Testing Accuracy: 0.90\n",
            "Epoch: 110, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 110, Validation Loss: 0.17, Validation Accuracy: 0.86\n",
            "Epoch: 110, Testing Loss: 0.15, Testing Accuracy: 0.90\n",
            "Epoch: 111, Training Loss: 0.13, Training Accuracy: 0.89\n",
            "Epoch: 111, Validation Loss: 0.17, Validation Accuracy: 0.87\n",
            "Epoch: 111, Testing Loss: 0.15, Testing Accuracy: 0.90\n",
            "Epoch: 112, Training Loss: 0.12, Training Accuracy: 0.89\n",
            "Epoch: 112, Validation Loss: 0.17, Validation Accuracy: 0.87\n",
            "Epoch: 112, Testing Loss: 0.15, Testing Accuracy: 0.90\n",
            "Epoch: 113, Training Loss: 0.12, Training Accuracy: 0.89\n",
            "Epoch: 113, Validation Loss: 0.17, Validation Accuracy: 0.87\n",
            "Epoch: 113, Testing Loss: 0.14, Testing Accuracy: 0.90\n",
            "Epoch: 114, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 114, Validation Loss: 0.17, Validation Accuracy: 0.87\n",
            "Epoch: 114, Testing Loss: 0.14, Testing Accuracy: 0.90\n",
            "Epoch: 115, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 115, Validation Loss: 0.17, Validation Accuracy: 0.87\n",
            "Epoch: 115, Testing Loss: 0.14, Testing Accuracy: 0.90\n",
            "Epoch: 116, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 116, Validation Loss: 0.16, Validation Accuracy: 0.87\n",
            "Epoch: 116, Testing Loss: 0.14, Testing Accuracy: 0.90\n",
            "Epoch: 117, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 117, Validation Loss: 0.16, Validation Accuracy: 0.87\n",
            "Epoch: 117, Testing Loss: 0.14, Testing Accuracy: 0.90\n",
            "Epoch: 118, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 118, Validation Loss: 0.16, Validation Accuracy: 0.87\n",
            "Epoch: 118, Testing Loss: 0.14, Testing Accuracy: 0.91\n",
            "Epoch: 119, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 119, Validation Loss: 0.16, Validation Accuracy: 0.87\n",
            "Epoch: 119, Testing Loss: 0.14, Testing Accuracy: 0.92\n",
            "Epoch: 120, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 120, Validation Loss: 0.16, Validation Accuracy: 0.87\n",
            "Epoch: 120, Testing Loss: 0.14, Testing Accuracy: 0.91\n",
            "Epoch: 121, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 121, Validation Loss: 0.16, Validation Accuracy: 0.88\n",
            "Epoch: 121, Testing Loss: 0.14, Testing Accuracy: 0.91\n",
            "Epoch: 122, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 122, Validation Loss: 0.16, Validation Accuracy: 0.88\n",
            "Epoch: 122, Testing Loss: 0.14, Testing Accuracy: 0.91\n",
            "Epoch: 123, Training Loss: 0.12, Training Accuracy: 0.90\n",
            "Epoch: 123, Validation Loss: 0.16, Validation Accuracy: 0.88\n",
            "Epoch: 123, Testing Loss: 0.13, Testing Accuracy: 0.91\n",
            "Epoch: 124, Training Loss: 0.11, Training Accuracy: 0.90\n",
            "Epoch: 124, Validation Loss: 0.16, Validation Accuracy: 0.88\n",
            "Epoch: 124, Testing Loss: 0.13, Testing Accuracy: 0.91\n",
            "Epoch: 125, Training Loss: 0.11, Training Accuracy: 0.90\n",
            "Epoch: 125, Validation Loss: 0.15, Validation Accuracy: 0.88\n",
            "Epoch: 125, Testing Loss: 0.13, Testing Accuracy: 0.91\n",
            "Epoch: 126, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 126, Validation Loss: 0.15, Validation Accuracy: 0.88\n",
            "Epoch: 126, Testing Loss: 0.13, Testing Accuracy: 0.91\n",
            "Epoch: 127, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 127, Validation Loss: 0.15, Validation Accuracy: 0.88\n",
            "Epoch: 127, Testing Loss: 0.13, Testing Accuracy: 0.91\n",
            "Epoch: 128, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 128, Validation Loss: 0.15, Validation Accuracy: 0.89\n",
            "Epoch: 128, Testing Loss: 0.13, Testing Accuracy: 0.91\n",
            "Epoch: 129, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 129, Validation Loss: 0.15, Validation Accuracy: 0.89\n",
            "Epoch: 129, Testing Loss: 0.13, Testing Accuracy: 0.92\n",
            "Epoch: 130, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 130, Validation Loss: 0.15, Validation Accuracy: 0.89\n",
            "Epoch: 130, Testing Loss: 0.13, Testing Accuracy: 0.92\n",
            "Epoch: 131, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 131, Validation Loss: 0.15, Validation Accuracy: 0.89\n",
            "Epoch: 131, Testing Loss: 0.13, Testing Accuracy: 0.92\n",
            "Epoch: 132, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 132, Validation Loss: 0.15, Validation Accuracy: 0.89\n",
            "Epoch: 132, Testing Loss: 0.13, Testing Accuracy: 0.92\n",
            "Epoch: 133, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 133, Validation Loss: 0.15, Validation Accuracy: 0.89\n",
            "Epoch: 133, Testing Loss: 0.13, Testing Accuracy: 0.92\n",
            "Epoch: 134, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 134, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 134, Testing Loss: 0.13, Testing Accuracy: 0.92\n",
            "Epoch: 135, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 135, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 135, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 136, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 136, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 136, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 137, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 137, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 137, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 138, Training Loss: 0.11, Training Accuracy: 0.91\n",
            "Epoch: 138, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 138, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 139, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 139, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 139, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 140, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 140, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 140, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 141, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 141, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 141, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 142, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 142, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 142, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 143, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 143, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 143, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 144, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 144, Validation Loss: 0.14, Validation Accuracy: 0.89\n",
            "Epoch: 144, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 145, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 145, Validation Loss: 0.13, Validation Accuracy: 0.89\n",
            "Epoch: 145, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 146, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 146, Validation Loss: 0.13, Validation Accuracy: 0.89\n",
            "Epoch: 146, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 147, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 147, Validation Loss: 0.13, Validation Accuracy: 0.89\n",
            "Epoch: 147, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 148, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 148, Validation Loss: 0.13, Validation Accuracy: 0.89\n",
            "Epoch: 148, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 149, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 149, Validation Loss: 0.13, Validation Accuracy: 0.89\n",
            "Epoch: 149, Testing Loss: 0.12, Testing Accuracy: 0.92\n",
            "Epoch: 150, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 150, Validation Loss: 0.13, Validation Accuracy: 0.89\n",
            "Epoch: 150, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 151, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 151, Validation Loss: 0.13, Validation Accuracy: 0.90\n",
            "Epoch: 151, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 152, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 152, Validation Loss: 0.13, Validation Accuracy: 0.90\n",
            "Epoch: 152, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 153, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 153, Validation Loss: 0.13, Validation Accuracy: 0.90\n",
            "Epoch: 153, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 154, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 154, Validation Loss: 0.13, Validation Accuracy: 0.90\n",
            "Epoch: 154, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 155, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 155, Validation Loss: 0.13, Validation Accuracy: 0.90\n",
            "Epoch: 155, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 156, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 156, Validation Loss: 0.13, Validation Accuracy: 0.90\n",
            "Epoch: 156, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 157, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 157, Validation Loss: 0.13, Validation Accuracy: 0.90\n",
            "Epoch: 157, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 158, Training Loss: 0.10, Training Accuracy: 0.91\n",
            "Epoch: 158, Validation Loss: 0.13, Validation Accuracy: 0.90\n",
            "Epoch: 158, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 159, Training Loss: 0.09, Training Accuracy: 0.91\n",
            "Epoch: 159, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 159, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 160, Training Loss: 0.09, Training Accuracy: 0.91\n",
            "Epoch: 160, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 160, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 161, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 161, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 161, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 162, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 162, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 162, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 163, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 163, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 163, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 164, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 164, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 164, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 165, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 165, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 165, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 166, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 166, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 166, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 167, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 167, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 167, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 168, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 168, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 168, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 169, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 169, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 169, Testing Loss: 0.11, Testing Accuracy: 0.92\n",
            "Epoch: 170, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 170, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 170, Testing Loss: 0.10, Testing Accuracy: 0.92\n",
            "Epoch: 171, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 171, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 171, Testing Loss: 0.10, Testing Accuracy: 0.92\n",
            "Epoch: 172, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 172, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 172, Testing Loss: 0.10, Testing Accuracy: 0.92\n",
            "Epoch: 173, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 173, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 173, Testing Loss: 0.10, Testing Accuracy: 0.92\n",
            "Epoch: 174, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 174, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 174, Testing Loss: 0.10, Testing Accuracy: 0.92\n",
            "Epoch: 175, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 175, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 175, Testing Loss: 0.10, Testing Accuracy: 0.92\n",
            "Epoch: 176, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 176, Validation Loss: 0.12, Validation Accuracy: 0.90\n",
            "Epoch: 176, Testing Loss: 0.10, Testing Accuracy: 0.92\n",
            "Epoch: 177, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 177, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 177, Testing Loss: 0.10, Testing Accuracy: 0.92\n",
            "Epoch: 178, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 178, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 178, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 179, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 179, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 179, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 180, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 180, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 180, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 181, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 181, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 181, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 182, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 182, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 182, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 183, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 183, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 183, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 184, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 184, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 184, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 185, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 185, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 185, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 186, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 186, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 186, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 187, Training Loss: 0.09, Training Accuracy: 0.92\n",
            "Epoch: 187, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 187, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 188, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 188, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 188, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 189, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 189, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 189, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 190, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 190, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 190, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 191, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 191, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 191, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 192, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 192, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 192, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 193, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 193, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 193, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 194, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 194, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 194, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 195, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 195, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 195, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 196, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 196, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 196, Testing Loss: 0.10, Testing Accuracy: 0.93\n",
            "Epoch: 197, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 197, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 197, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 198, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 198, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 198, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 199, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 199, Validation Loss: 0.11, Validation Accuracy: 0.90\n",
            "Epoch: 199, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 200, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 200, Validation Loss: 0.10, Validation Accuracy: 0.90\n",
            "Epoch: 200, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 201, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 201, Validation Loss: 0.10, Validation Accuracy: 0.90\n",
            "Epoch: 201, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 202, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 202, Validation Loss: 0.10, Validation Accuracy: 0.90\n",
            "Epoch: 202, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 203, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 203, Validation Loss: 0.10, Validation Accuracy: 0.90\n",
            "Epoch: 203, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 204, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 204, Validation Loss: 0.10, Validation Accuracy: 0.90\n",
            "Epoch: 204, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 205, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 205, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 205, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 206, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 206, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 206, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 207, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 207, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 207, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 208, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 208, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 208, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 209, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 209, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 209, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 210, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 210, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 210, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 211, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 211, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 211, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 212, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 212, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 212, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 213, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 213, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 213, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 214, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 214, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 214, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 215, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 215, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 215, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 216, Training Loss: 0.08, Training Accuracy: 0.92\n",
            "Epoch: 216, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 216, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 217, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 217, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 217, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 218, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 218, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 218, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 219, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 219, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 219, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 220, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 220, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 220, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 221, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 221, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 221, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 222, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 222, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 222, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 223, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 223, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 223, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 224, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 224, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 224, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 225, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 225, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 225, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 226, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 226, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 226, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 227, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 227, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 227, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 228, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 228, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 228, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 229, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 229, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 229, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 230, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 230, Validation Loss: 0.10, Validation Accuracy: 0.91\n",
            "Epoch: 230, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 231, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 231, Validation Loss: 0.09, Validation Accuracy: 0.91\n",
            "Epoch: 231, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 232, Training Loss: 0.08, Training Accuracy: 0.93\n",
            "Epoch: 232, Validation Loss: 0.09, Validation Accuracy: 0.91\n",
            "Epoch: 232, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 233, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 233, Validation Loss: 0.09, Validation Accuracy: 0.91\n",
            "Epoch: 233, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 234, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 234, Validation Loss: 0.09, Validation Accuracy: 0.91\n",
            "Epoch: 234, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 235, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 235, Validation Loss: 0.09, Validation Accuracy: 0.91\n",
            "Epoch: 235, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 236, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 236, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 236, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 237, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 237, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 237, Testing Loss: 0.09, Testing Accuracy: 0.93\n",
            "Epoch: 238, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 238, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 238, Testing Loss: 0.08, Testing Accuracy: 0.93\n",
            "Epoch: 239, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 239, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 239, Testing Loss: 0.08, Testing Accuracy: 0.93\n",
            "Epoch: 240, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 240, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 240, Testing Loss: 0.08, Testing Accuracy: 0.93\n",
            "Epoch: 241, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 241, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 241, Testing Loss: 0.08, Testing Accuracy: 0.93\n",
            "Epoch: 242, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 242, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 242, Testing Loss: 0.08, Testing Accuracy: 0.93\n",
            "Epoch: 243, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 243, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 243, Testing Loss: 0.08, Testing Accuracy: 0.93\n",
            "Epoch: 244, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 244, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 244, Testing Loss: 0.08, Testing Accuracy: 0.93\n",
            "Epoch: 245, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 245, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 245, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 246, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 246, Validation Loss: 0.09, Validation Accuracy: 0.92\n",
            "Epoch: 246, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 247, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 247, Validation Loss: 0.09, Validation Accuracy: 0.93\n",
            "Epoch: 247, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 248, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 248, Validation Loss: 0.09, Validation Accuracy: 0.93\n",
            "Epoch: 248, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 249, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 249, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 249, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 250, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 250, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 250, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 251, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 251, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 251, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 252, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 252, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 252, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 253, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 253, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 253, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 254, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 254, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 254, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 255, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 255, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 255, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 256, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 256, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 256, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 257, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 257, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 257, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 258, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 258, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 258, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 259, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 259, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 259, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 260, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 260, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 260, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 261, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 261, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 261, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 262, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 262, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 262, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 263, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 263, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 263, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 264, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 264, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 264, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 265, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 265, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 265, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 266, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 266, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 266, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 267, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 267, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 267, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 268, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 268, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 268, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 269, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 269, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 269, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 270, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 270, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 270, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 271, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 271, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 271, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 272, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 272, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 272, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 273, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 273, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 273, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 274, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 274, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 274, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 275, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 275, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 275, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 276, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 276, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 276, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 277, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 277, Validation Loss: 0.09, Validation Accuracy: 0.94\n",
            "Epoch: 277, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 278, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 278, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 278, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 279, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 279, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 279, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 280, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 280, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 280, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 281, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 281, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 281, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 282, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 282, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 282, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 283, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 283, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 283, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 284, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 284, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 284, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 285, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 285, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 285, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 286, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 286, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 286, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 287, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 287, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 287, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 288, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 288, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 288, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 289, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 289, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 289, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 290, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 290, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 290, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 291, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 291, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 291, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 292, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 292, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 292, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 293, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 293, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 293, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 294, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 294, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 294, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 295, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 295, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 295, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 296, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 296, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 296, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 297, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 297, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 297, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 298, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 298, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 298, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 299, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 299, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 299, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 300, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 300, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 300, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 301, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 301, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 301, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 302, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 302, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 302, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 303, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 303, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 303, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 304, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 304, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 304, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 305, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 305, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 305, Testing Loss: 0.08, Testing Accuracy: 0.94\n",
            "Epoch: 306, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 306, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 306, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 307, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 307, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 307, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 308, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 308, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 308, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 309, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 309, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 309, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 310, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 310, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 310, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 311, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 311, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 311, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 312, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 312, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 312, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 313, Training Loss: 0.07, Training Accuracy: 0.93\n",
            "Epoch: 313, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 313, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 314, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 314, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 314, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 315, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 315, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 315, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 316, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 316, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 316, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 317, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 317, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 317, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 318, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 318, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 318, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 319, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 319, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 319, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 320, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 320, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 320, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 321, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 321, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 321, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 322, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 322, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 322, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 323, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 323, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 323, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 324, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 324, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 324, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 325, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 325, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 325, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 326, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 326, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 326, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 327, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 327, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 327, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 328, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 328, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 328, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 329, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 329, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 329, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 330, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 330, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 330, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 331, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 331, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 331, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 332, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 332, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 332, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 333, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 333, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 333, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 334, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 334, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 334, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 335, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 335, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 335, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 336, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 336, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 336, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 337, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 337, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 337, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 338, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 338, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 338, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 339, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 339, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 339, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 340, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 340, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 340, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 341, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 341, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 341, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 342, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 342, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 342, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 343, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 343, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 343, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 344, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 344, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 344, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 345, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 345, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 345, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 346, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 346, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 346, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 347, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 347, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 347, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 348, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 348, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 348, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 349, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 349, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 349, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 350, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 350, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 350, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 351, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 351, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 351, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 352, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 352, Validation Loss: 0.08, Validation Accuracy: 0.94\n",
            "Epoch: 352, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 353, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 353, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 353, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 354, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 354, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 354, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 355, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 355, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 355, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 356, Training Loss: 0.06, Training Accuracy: 0.93\n",
            "Epoch: 356, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 356, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 357, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 357, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 357, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 358, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 358, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 358, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 359, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 359, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 359, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 360, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 360, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 360, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 361, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 361, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 361, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 362, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 362, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 362, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 363, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 363, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 363, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 364, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 364, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 364, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 365, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 365, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 365, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 366, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 366, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 366, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 367, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 367, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 367, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 368, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 368, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 368, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 369, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 369, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 369, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 370, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 370, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 370, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 371, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 371, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 371, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 372, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 372, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 372, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 373, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 373, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 373, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 374, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 374, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 374, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 375, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 375, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 375, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 376, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 376, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 376, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 377, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 377, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 377, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 378, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 378, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 378, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 379, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 379, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 379, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 380, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 380, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 380, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 381, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 381, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 381, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 382, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 382, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 382, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 383, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 383, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 383, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 384, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 384, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 384, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 385, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 385, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 385, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 386, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 386, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 386, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 387, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 387, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 387, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 388, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 388, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 388, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 389, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 389, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 389, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 390, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 390, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 390, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 391, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 391, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 391, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 392, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 392, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 392, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 393, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 393, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 393, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 394, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 394, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 394, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 395, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 395, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 395, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 396, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 396, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 396, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 397, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 397, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 397, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 398, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 398, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 398, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 399, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 399, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 399, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 400, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 400, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 400, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 401, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 401, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 401, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 402, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 402, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 402, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 403, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 403, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 403, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 404, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 404, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 404, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 405, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 405, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 405, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 406, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 406, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 406, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 407, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 407, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 407, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 408, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 408, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 408, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 409, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 409, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 409, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 410, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 410, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 410, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 411, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 411, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 411, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 412, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 412, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 412, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 413, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 413, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 413, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 414, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 414, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 414, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 415, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 415, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 415, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 416, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 416, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 416, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 417, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 417, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 417, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 418, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 418, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 418, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 419, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 419, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 419, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 420, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 420, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 420, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 421, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 421, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 421, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 422, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 422, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 422, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 423, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 423, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 423, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 424, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 424, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 424, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 425, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 425, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 425, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 426, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 426, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 426, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 427, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 427, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 427, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 428, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 428, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 428, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 429, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 429, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 429, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 430, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 430, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 430, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 431, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 431, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 431, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 432, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 432, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 432, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 433, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 433, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 433, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 434, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 434, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 434, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 435, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 435, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 435, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 436, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 436, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 436, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 437, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 437, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 437, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 438, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 438, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 438, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 439, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 439, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 439, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 440, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 440, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 440, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 441, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 441, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 441, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 442, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 442, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 442, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 443, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 443, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 443, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 444, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 444, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 444, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 445, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 445, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 445, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 446, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 446, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 446, Testing Loss: 0.07, Testing Accuracy: 0.94\n",
            "Epoch: 447, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 447, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 447, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 448, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 448, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 448, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 449, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 449, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 449, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 450, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 450, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 450, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 451, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 451, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 451, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 452, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 452, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 452, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 453, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 453, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 453, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 454, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 454, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 454, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 455, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 455, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 455, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 456, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 456, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 456, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 457, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 457, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 457, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 458, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 458, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 458, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 459, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 459, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 459, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 460, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 460, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 460, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 461, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 461, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 461, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 462, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 462, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 462, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 463, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 463, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 463, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 464, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 464, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 464, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 465, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 465, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 465, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 466, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 466, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 466, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 467, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 467, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 467, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 468, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 468, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 468, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 469, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 469, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 469, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 470, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 470, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 470, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 471, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 471, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 471, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 472, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 472, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 472, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 473, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 473, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 473, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 474, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 474, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 474, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 475, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 475, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 475, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 476, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 476, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 476, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 477, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 477, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 477, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 478, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 478, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 478, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 479, Training Loss: 0.06, Training Accuracy: 0.94\n",
            "Epoch: 479, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 479, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 480, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 480, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 480, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 481, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 481, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 481, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 482, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 482, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 482, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 483, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 483, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 483, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 484, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 484, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 484, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 485, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 485, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 485, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 486, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 486, Validation Loss: 0.07, Validation Accuracy: 0.94\n",
            "Epoch: 486, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 487, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 487, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 487, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 488, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 488, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 488, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 489, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 489, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 489, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 490, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 490, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 490, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 491, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 491, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 491, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 492, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 492, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 492, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 493, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 493, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 493, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 494, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 494, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 494, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 495, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 495, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 495, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 496, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 496, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 496, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 497, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 497, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 497, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 498, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 498, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 498, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 499, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 499, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 499, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 500, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 500, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 500, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 501, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 501, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 501, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 502, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 502, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 502, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 503, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 503, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 503, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 504, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 504, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 504, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 505, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 505, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 505, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 506, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 506, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 506, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 507, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 507, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 507, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 508, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 508, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 508, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 509, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 509, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 509, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 510, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 510, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 510, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 511, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 511, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 511, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 512, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 512, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 512, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 513, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 513, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 513, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 514, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 514, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 514, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 515, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 515, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 515, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 516, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 516, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 516, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 517, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 517, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 517, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 518, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 518, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 518, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 519, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 519, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 519, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 520, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 520, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 520, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 521, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 521, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 521, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 522, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 522, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 522, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 523, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 523, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 523, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 524, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 524, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 524, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 525, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 525, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 525, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 526, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 526, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 526, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 527, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 527, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 527, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 528, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 528, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 528, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 529, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 529, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 529, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 530, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 530, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 530, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 531, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 531, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 531, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 532, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 532, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 532, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 533, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 533, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 533, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 534, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 534, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 534, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 535, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 535, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 535, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 536, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 536, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 536, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 537, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 537, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 537, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 538, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 538, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 538, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 539, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 539, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 539, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 540, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 540, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 540, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 541, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 541, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 541, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 542, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 542, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 542, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 543, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 543, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 543, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 544, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 544, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 544, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 545, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 545, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 545, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 546, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 546, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 546, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 547, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 547, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 547, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 548, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 548, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 548, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 549, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 549, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 549, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 550, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 550, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 550, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 551, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 551, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 551, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 552, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 552, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 552, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 553, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 553, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 553, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 554, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 554, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 554, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 555, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 555, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 555, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 556, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 556, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 556, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 557, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 557, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 557, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 558, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 558, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 558, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 559, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 559, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 559, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 560, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 560, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 560, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 561, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 561, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 561, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 562, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 562, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 562, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 563, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 563, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 563, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 564, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 564, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 564, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 565, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 565, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 565, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 566, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 566, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 566, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 567, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 567, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 567, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 568, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 568, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 568, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 569, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 569, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 569, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 570, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 570, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 570, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 571, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 571, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 571, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 572, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 572, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 572, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 573, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 573, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 573, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 574, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 574, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 574, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 575, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 575, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 575, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 576, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 576, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 576, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 577, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 577, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 577, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 578, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 578, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 578, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 579, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 579, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 579, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 580, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 580, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 580, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 581, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 581, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 581, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 582, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 582, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 582, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 583, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 583, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 583, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 584, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 584, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 584, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 585, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 585, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 585, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 586, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 586, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 586, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 587, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 587, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 587, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 588, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 588, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 588, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 589, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 589, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 589, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 590, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 590, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 590, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 591, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 591, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 591, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 592, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 592, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 592, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 593, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 593, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 593, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 594, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 594, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 594, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 595, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 595, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 595, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 596, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 596, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 596, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 597, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 597, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 597, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 598, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 598, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 598, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 599, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 599, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 599, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 600, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 600, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 600, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 601, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 601, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 601, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 602, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 602, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 602, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 603, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 603, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 603, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 604, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 604, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 604, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 605, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 605, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 605, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 606, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 606, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 606, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 607, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 607, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 607, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 608, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 608, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 608, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 609, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 609, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 609, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 610, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 610, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 610, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 611, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 611, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 611, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 612, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 612, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 612, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 613, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 613, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 613, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 614, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 614, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 614, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 615, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 615, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 615, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 616, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 616, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 616, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 617, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 617, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 617, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 618, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 618, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 618, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 619, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 619, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 619, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 620, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 620, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 620, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 621, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 621, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 621, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 622, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 622, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 622, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 623, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 623, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 623, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 624, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 624, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 624, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 625, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 625, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 625, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 626, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 626, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 626, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 627, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 627, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 627, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 628, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 628, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 628, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 629, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 629, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 629, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 630, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 630, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 630, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 631, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 631, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 631, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 632, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 632, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 632, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 633, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 633, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 633, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 634, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 634, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 634, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 635, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 635, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 635, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 636, Training Loss: 0.05, Training Accuracy: 0.94\n",
            "Epoch: 636, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 636, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 637, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 637, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 637, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 638, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 638, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 638, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 639, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 639, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 639, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 640, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 640, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 640, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 641, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 641, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 641, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 642, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 642, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 642, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 643, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 643, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 643, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 644, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 644, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 644, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 645, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 645, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 645, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 646, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 646, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 646, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 647, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 647, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 647, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 648, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 648, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 648, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 649, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 649, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 649, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 650, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 650, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 650, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 651, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 651, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 651, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 652, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 652, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 652, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 653, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 653, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 653, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 654, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 654, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 654, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 655, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 655, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 655, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 656, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 656, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 656, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 657, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 657, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 657, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 658, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 658, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 658, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 659, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 659, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 659, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 660, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 660, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 660, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 661, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 661, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 661, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 662, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 662, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 662, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 663, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 663, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 663, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 664, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 664, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 664, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 665, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 665, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 665, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 666, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 666, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 666, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 667, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 667, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 667, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 668, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 668, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 668, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 669, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 669, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 669, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 670, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 670, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 670, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 671, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 671, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 671, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 672, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 672, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 672, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 673, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 673, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 673, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 674, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 674, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 674, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 675, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 675, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 675, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 676, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 676, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 676, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 677, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 677, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 677, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 678, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 678, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 678, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 679, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 679, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 679, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 680, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 680, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 680, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 681, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 681, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 681, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 682, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 682, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 682, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 683, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 683, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 683, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 684, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 684, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 684, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 685, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 685, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 685, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 686, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 686, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 686, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 687, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 687, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 687, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 688, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 688, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 688, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 689, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 689, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 689, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 690, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 690, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 690, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 691, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 691, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 691, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 692, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 692, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 692, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 693, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 693, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 693, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 694, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 694, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 694, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 695, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 695, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 695, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 696, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 696, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 696, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 697, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 697, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 697, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 698, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 698, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 698, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 699, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 699, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 699, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 700, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 700, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 700, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 701, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 701, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 701, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 702, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 702, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 702, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 703, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 703, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 703, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 704, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 704, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 704, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 705, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 705, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 705, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 706, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 706, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 706, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 707, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 707, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 707, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 708, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 708, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 708, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 709, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 709, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 709, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 710, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 710, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 710, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 711, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 711, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 711, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 712, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 712, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 712, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 713, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 713, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 713, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 714, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 714, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 714, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 715, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 715, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 715, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 716, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 716, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 716, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 717, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 717, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 717, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 718, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 718, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 718, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 719, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 719, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 719, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 720, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 720, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 720, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 721, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 721, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 721, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 722, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 722, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 722, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 723, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 723, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 723, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 724, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 724, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 724, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 725, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 725, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 725, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 726, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 726, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 726, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 727, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 727, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 727, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 728, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 728, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 728, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 729, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 729, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 729, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 730, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 730, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 730, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 731, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 731, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 731, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 732, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 732, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 732, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 733, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 733, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 733, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 734, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 734, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 734, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 735, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 735, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 735, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 736, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 736, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 736, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 737, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 737, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 737, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 738, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 738, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 738, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 739, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 739, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 739, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 740, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 740, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 740, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 741, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 741, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 741, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 742, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 742, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 742, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 743, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 743, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 743, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 744, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 744, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 744, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 745, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 745, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 745, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 746, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 746, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 746, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 747, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 747, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 747, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 748, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 748, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 748, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 749, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 749, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 749, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 750, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 750, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 750, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 751, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 751, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 751, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 752, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 752, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 752, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 753, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 753, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 753, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 754, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 754, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 754, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 755, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 755, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 755, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 756, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 756, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 756, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 757, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 757, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 757, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 758, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 758, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 758, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 759, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 759, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 759, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 760, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 760, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 760, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 761, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 761, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 761, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 762, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 762, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 762, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 763, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 763, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 763, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 764, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 764, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 764, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 765, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 765, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 765, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 766, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 766, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 766, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 767, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 767, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 767, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 768, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 768, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 768, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 769, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 769, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 769, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 770, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 770, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 770, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 771, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 771, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 771, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 772, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 772, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 772, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 773, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 773, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 773, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 774, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 774, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 774, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 775, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 775, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 775, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 776, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 776, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 776, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 777, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 777, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 777, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 778, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 778, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 778, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 779, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 779, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 779, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 780, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 780, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 780, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 781, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 781, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 781, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 782, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 782, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 782, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 783, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 783, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 783, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 784, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 784, Validation Loss: 0.06, Validation Accuracy: 0.94\n",
            "Epoch: 784, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 785, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 785, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 785, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 786, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 786, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 786, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 787, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 787, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 787, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 788, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 788, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 788, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 789, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 789, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 789, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 790, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 790, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 790, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 791, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 791, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 791, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 792, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 792, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 792, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 793, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 793, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 793, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 794, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 794, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 794, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 795, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 795, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 795, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 796, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 796, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 796, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 797, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 797, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 797, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 798, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 798, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 798, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 799, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 799, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 799, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 800, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 800, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 800, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 801, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 801, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 801, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 802, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 802, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 802, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 803, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 803, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 803, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 804, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 804, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 804, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 805, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 805, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 805, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 806, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 806, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 806, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 807, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 807, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 807, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 808, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 808, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 808, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 809, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 809, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 809, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 810, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 810, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 810, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 811, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 811, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 811, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 812, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 812, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 812, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 813, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 813, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 813, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 814, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 814, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 814, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 815, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 815, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 815, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 816, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 816, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 816, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 817, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 817, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 817, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 818, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 818, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 818, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 819, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 819, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 819, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 820, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 820, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 820, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 821, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 821, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 821, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 822, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 822, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 822, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 823, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 823, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 823, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 824, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 824, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 824, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 825, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 825, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 825, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 826, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 826, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 826, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 827, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 827, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 827, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 828, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 828, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 828, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 829, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 829, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 829, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 830, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 830, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 830, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 831, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 831, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 831, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 832, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 832, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 832, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 833, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 833, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 833, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 834, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 834, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 834, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 835, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 835, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 835, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 836, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 836, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 836, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 837, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 837, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 837, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 838, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 838, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 838, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 839, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 839, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 839, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 840, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 840, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 840, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 841, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 841, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 841, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 842, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 842, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 842, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 843, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 843, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 843, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 844, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 844, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 844, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 845, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 845, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 845, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 846, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 846, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 846, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 847, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 847, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 847, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 848, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 848, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 848, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 849, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 849, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 849, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 850, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 850, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 850, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 851, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 851, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 851, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 852, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 852, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 852, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 853, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 853, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 853, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 854, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 854, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 854, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 855, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 855, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 855, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 856, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 856, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 856, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 857, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 857, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 857, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 858, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 858, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 858, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 859, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 859, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 859, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 860, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 860, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 860, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 861, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 861, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 861, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 862, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 862, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 862, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 863, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 863, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 863, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 864, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 864, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 864, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 865, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 865, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 865, Testing Loss: 0.06, Testing Accuracy: 0.94\n",
            "Epoch: 866, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 866, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 866, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 867, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 867, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 867, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 868, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 868, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 868, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 869, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 869, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 869, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 870, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 870, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 870, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 871, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 871, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 871, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 872, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 872, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 872, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 873, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 873, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 873, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 874, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 874, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 874, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 875, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 875, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 875, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 876, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 876, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 876, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 877, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 877, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 877, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 878, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 878, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 878, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 879, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 879, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 879, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 880, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 880, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 880, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 881, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 881, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 881, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 882, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 882, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 882, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 883, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 883, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 883, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 884, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 884, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 884, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 885, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 885, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 885, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 886, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 886, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 886, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 887, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 887, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 887, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 888, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 888, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 888, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 889, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 889, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 889, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 890, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 890, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 890, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 891, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 891, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 891, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 892, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 892, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 892, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 893, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 893, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 893, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 894, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 894, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 894, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 895, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 895, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 895, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 896, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 896, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 896, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 897, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 897, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 897, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 898, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 898, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 898, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 899, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 899, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 899, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 900, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 900, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 900, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 901, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 901, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 901, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 902, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 902, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 902, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 903, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 903, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 903, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 904, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 904, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 904, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 905, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 905, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 905, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 906, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 906, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 906, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 907, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 907, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 907, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 908, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 908, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 908, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 909, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 909, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 909, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 910, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 910, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 910, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 911, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 911, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 911, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 912, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 912, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 912, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 913, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 913, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 913, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 914, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 914, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 914, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 915, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 915, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 915, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 916, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 916, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 916, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 917, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 917, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 917, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 918, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 918, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 918, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 919, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 919, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 919, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 920, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 920, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 920, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 921, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 921, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 921, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 922, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 922, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 922, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 923, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 923, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 923, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 924, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 924, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 924, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 925, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 925, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 925, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 926, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 926, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 926, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 927, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 927, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 927, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 928, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 928, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 928, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 929, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 929, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 929, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 930, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 930, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 930, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 931, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 931, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 931, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 932, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 932, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 932, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 933, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 933, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 933, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 934, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 934, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 934, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 935, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 935, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 935, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 936, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 936, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 936, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 937, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 937, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 937, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 938, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 938, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 938, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 939, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 939, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 939, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 940, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 940, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 940, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 941, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 941, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 941, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 942, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 942, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 942, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 943, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 943, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 943, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 944, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 944, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 944, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 945, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 945, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 945, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 946, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 946, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 946, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 947, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 947, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 947, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 948, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 948, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 948, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 949, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 949, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 949, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 950, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 950, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 950, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 951, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 951, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 951, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 952, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 952, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 952, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 953, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 953, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 953, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 954, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 954, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 954, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 955, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 955, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 955, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 956, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 956, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 956, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 957, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 957, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 957, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 958, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 958, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 958, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 959, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 959, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 959, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 960, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 960, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 960, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 961, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 961, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 961, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 962, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 962, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 962, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 963, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 963, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 963, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 964, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 964, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 964, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 965, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 965, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 965, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 966, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 966, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 966, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 967, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 967, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 967, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 968, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 968, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 968, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 969, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 969, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 969, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 970, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 970, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 970, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 971, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 971, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 971, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 972, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 972, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 972, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 973, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 973, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 973, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 974, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 974, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 974, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 975, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 975, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 975, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 976, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 976, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 976, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 977, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 977, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 977, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 978, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 978, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 978, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 979, Training Loss: 0.05, Training Accuracy: 0.95\n",
            "Epoch: 979, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 979, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 980, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 980, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 980, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 981, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 981, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 981, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 982, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 982, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 982, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 983, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 983, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 983, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 984, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 984, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 984, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 985, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 985, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 985, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 986, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 986, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 986, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 987, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 987, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 987, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 988, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 988, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 988, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 989, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 989, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 989, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 990, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 990, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 990, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 991, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 991, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 991, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 992, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 992, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 992, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 993, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 993, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 993, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 994, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 994, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 994, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 995, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 995, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 995, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 996, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 996, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 996, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 997, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 997, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 997, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 998, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 998, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 998, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 999, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 999, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 999, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1000, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1000, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1000, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1001, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1001, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1001, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1002, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1002, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1002, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1003, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1003, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1003, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1004, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1004, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1004, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1005, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1005, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1005, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1006, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1006, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1006, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1007, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1007, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1007, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1008, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1008, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1008, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1009, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1009, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1009, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1010, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1010, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1010, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1011, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1011, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1011, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1012, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1012, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1012, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1013, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1013, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1013, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1014, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1014, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1014, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1015, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1015, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1015, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1016, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1016, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1016, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1017, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1017, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1017, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1018, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1018, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1018, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1019, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1019, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1019, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1020, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1020, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1020, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1021, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1021, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1021, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1022, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1022, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1022, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1023, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1023, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1023, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1024, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1024, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1024, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1025, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1025, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1025, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1026, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1026, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1026, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1027, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1027, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1027, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1028, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1028, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1028, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1029, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1029, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1029, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1030, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1030, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1030, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1031, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1031, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1031, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1032, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1032, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1032, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1033, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1033, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1033, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1034, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1034, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1034, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1035, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1035, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1035, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1036, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1036, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1036, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1037, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1037, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1037, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1038, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1038, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1038, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1039, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1039, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1039, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1040, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1040, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1040, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1041, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1041, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1041, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1042, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1042, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1042, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1043, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1043, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1043, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1044, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1044, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1044, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1045, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1045, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1045, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1046, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1046, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1046, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1047, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1047, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1047, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1048, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1048, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1048, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1049, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1049, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1049, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1050, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1050, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1050, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1051, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1051, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1051, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1052, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1052, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1052, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1053, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1053, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1053, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1054, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1054, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1054, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1055, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1055, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1055, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1056, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1056, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1056, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1057, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1057, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1057, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1058, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1058, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1058, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1059, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1059, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1059, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1060, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1060, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1060, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1061, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1061, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1061, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1062, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1062, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1062, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1063, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1063, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1063, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1064, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1064, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1064, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1065, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1065, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1065, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1066, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1066, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1066, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1067, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1067, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1067, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1068, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1068, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1068, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1069, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1069, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1069, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1070, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1070, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1070, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1071, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1071, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1071, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1072, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1072, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1072, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1073, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1073, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1073, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1074, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1074, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1074, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1075, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1075, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1075, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1076, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1076, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1076, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1077, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1077, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1077, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1078, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1078, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1078, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1079, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1079, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1079, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1080, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1080, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1080, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1081, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1081, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1081, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1082, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1082, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1082, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1083, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1083, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1083, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1084, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1084, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1084, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1085, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1085, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1085, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1086, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1086, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1086, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1087, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1087, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1087, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1088, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1088, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1088, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1089, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1089, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1089, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1090, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1090, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1090, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1091, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1091, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1091, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1092, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1092, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1092, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1093, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1093, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1093, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1094, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1094, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1094, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1095, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1095, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1095, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1096, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1096, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1096, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1097, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1097, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1097, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1098, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1098, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1098, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1099, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1099, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1099, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1100, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1100, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1100, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1101, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1101, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1101, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1102, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1102, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1102, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1103, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1103, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1103, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1104, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1104, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1104, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1105, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1105, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1105, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1106, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1106, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1106, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1107, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1107, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1107, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1108, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1108, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1108, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1109, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1109, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1109, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1110, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1110, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1110, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1111, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1111, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1111, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1112, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1112, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1112, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1113, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1113, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1113, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1114, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1114, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1114, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1115, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1115, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1115, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1116, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1116, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1116, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1117, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1117, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1117, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1118, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1118, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1118, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1119, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1119, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1119, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1120, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1120, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1120, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1121, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1121, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1121, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1122, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1122, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1122, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1123, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1123, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1123, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1124, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1124, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1124, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1125, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1125, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1125, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1126, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1126, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1126, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1127, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1127, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1127, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1128, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1128, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1128, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1129, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1129, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1129, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1130, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1130, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1130, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1131, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1131, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1131, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1132, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1132, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1132, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1133, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1133, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1133, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1134, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1134, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1134, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1135, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1135, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1135, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1136, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1136, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1136, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1137, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1137, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1137, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1138, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1138, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1138, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1139, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1139, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1139, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1140, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1140, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1140, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1141, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1141, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1141, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1142, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1142, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1142, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1143, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1143, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1143, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1144, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1144, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1144, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1145, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1145, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1145, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1146, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1146, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1146, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1147, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1147, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1147, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1148, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1148, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1148, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1149, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1149, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1149, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1150, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1150, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1150, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1151, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1151, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1151, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1152, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1152, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1152, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1153, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1153, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1153, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1154, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1154, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1154, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1155, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1155, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1155, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1156, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1156, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1156, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1157, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1157, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1157, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1158, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1158, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1158, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1159, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1159, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1159, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1160, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1160, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1160, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1161, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1161, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1161, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1162, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1162, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1162, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1163, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1163, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1163, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1164, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1164, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1164, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1165, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1165, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1165, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1166, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1166, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1166, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1167, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1167, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1167, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1168, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1168, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1168, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1169, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1169, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1169, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1170, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1170, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1170, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1171, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1171, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1171, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1172, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1172, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1172, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1173, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1173, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1173, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1174, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1174, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1174, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1175, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1175, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1175, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1176, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1176, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1176, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1177, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1177, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1177, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1178, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1178, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1178, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1179, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1179, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1179, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1180, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1180, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1180, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1181, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1181, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1181, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1182, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1182, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1182, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1183, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1183, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1183, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1184, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1184, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1184, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1185, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1185, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1185, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1186, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1186, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1186, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1187, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1187, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1187, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1188, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1188, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1188, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1189, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1189, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1189, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1190, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1190, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1190, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1191, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1191, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1191, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1192, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1192, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1192, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1193, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1193, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1193, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1194, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1194, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1194, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1195, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1195, Validation Loss: 0.05, Validation Accuracy: 0.94\n",
            "Epoch: 1195, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1196, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1196, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1196, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1197, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1197, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1197, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1198, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1198, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1198, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1199, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1199, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1199, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1200, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1200, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1200, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1201, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1201, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1201, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1202, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1202, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1202, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1203, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1203, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1203, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1204, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1204, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1204, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1205, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1205, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1205, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1206, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1206, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1206, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1207, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1207, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1207, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1208, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1208, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1208, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1209, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1209, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1209, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1210, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1210, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1210, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1211, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1211, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1211, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1212, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1212, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1212, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1213, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1213, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1213, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1214, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1214, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1214, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1215, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1215, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1215, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1216, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1216, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1216, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1217, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1217, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1217, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1218, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1218, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1218, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1219, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1219, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1219, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1220, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1220, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1220, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1221, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1221, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1221, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1222, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1222, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1222, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1223, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1223, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1223, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1224, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1224, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1224, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1225, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1225, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1225, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1226, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1226, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1226, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1227, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1227, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1227, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1228, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1228, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1228, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1229, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1229, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1229, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1230, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1230, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1230, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1231, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1231, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1231, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1232, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1232, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1232, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1233, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1233, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1233, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1234, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1234, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1234, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1235, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1235, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1235, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1236, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1236, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1236, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1237, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1237, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1237, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1238, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1238, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1238, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1239, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1239, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1239, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1240, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1240, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1240, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1241, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1241, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1241, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1242, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1242, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1242, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1243, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1243, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1243, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1244, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1244, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1244, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1245, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1245, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1245, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1246, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1246, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1246, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1247, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1247, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1247, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1248, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1248, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1248, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1249, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1249, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1249, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1250, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1250, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1250, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1251, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1251, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1251, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1252, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1252, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1252, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1253, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1253, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1253, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1254, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1254, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1254, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1255, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1255, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1255, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1256, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1256, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1256, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1257, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1257, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1257, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1258, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1258, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1258, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1259, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1259, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1259, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1260, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1260, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1260, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1261, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1261, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1261, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1262, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1262, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1262, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1263, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1263, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1263, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1264, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1264, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1264, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1265, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1265, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1265, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1266, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1266, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1266, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1267, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1267, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1267, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1268, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1268, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1268, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1269, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1269, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1269, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1270, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1270, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1270, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1271, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1271, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1271, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1272, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1272, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1272, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1273, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1273, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1273, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1274, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1274, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1274, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1275, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1275, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1275, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1276, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1276, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1276, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1277, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1277, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1277, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1278, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1278, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1278, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1279, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1279, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1279, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1280, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1280, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1280, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1281, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1281, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1281, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1282, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1282, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1282, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1283, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1283, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1283, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1284, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1284, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1284, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1285, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1285, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1285, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1286, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1286, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1286, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1287, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1287, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1287, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1288, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1288, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1288, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1289, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1289, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1289, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1290, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1290, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1290, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1291, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1291, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1291, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1292, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1292, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1292, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1293, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1293, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1293, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1294, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1294, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1294, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1295, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1295, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1295, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1296, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1296, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1296, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1297, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1297, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1297, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1298, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1298, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1298, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1299, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1299, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1299, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1300, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1300, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1300, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1301, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1301, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1301, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1302, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1302, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1302, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1303, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1303, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1303, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1304, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1304, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1304, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1305, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1305, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1305, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1306, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1306, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1306, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1307, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1307, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1307, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1308, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1308, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1308, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1309, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1309, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1309, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1310, Training Loss: 0.04, Training Accuracy: 0.95\n",
            "Epoch: 1310, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1310, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1311, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1311, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1311, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1312, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1312, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1312, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1313, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1313, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1313, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1314, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1314, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1314, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1315, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1315, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1315, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1316, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1316, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1316, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1317, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1317, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1317, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1318, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1318, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1318, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1319, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1319, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1319, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1320, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1320, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1320, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1321, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1321, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1321, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1322, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1322, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1322, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1323, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1323, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1323, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1324, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1324, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1324, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1325, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1325, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1325, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1326, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1326, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1326, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1327, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1327, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1327, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1328, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1328, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1328, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1329, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1329, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1329, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1330, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1330, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1330, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1331, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1331, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1331, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1332, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1332, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1332, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1333, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1333, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1333, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1334, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1334, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1334, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1335, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1335, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1335, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1336, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1336, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1336, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1337, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1337, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1337, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1338, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1338, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1338, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1339, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1339, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1339, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1340, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1340, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1340, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1341, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1341, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1341, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1342, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1342, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1342, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1343, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1343, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1343, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1344, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1344, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1344, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1345, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1345, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1345, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1346, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1346, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1346, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1347, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1347, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1347, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1348, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1348, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1348, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1349, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1349, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1349, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1350, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1350, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1350, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1351, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1351, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1351, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1352, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1352, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1352, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1353, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1353, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1353, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1354, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1354, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1354, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1355, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1355, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1355, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1356, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1356, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1356, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1357, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1357, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1357, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1358, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1358, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1358, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1359, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1359, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1359, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1360, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1360, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1360, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1361, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1361, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1361, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1362, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1362, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1362, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1363, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1363, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1363, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1364, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1364, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1364, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1365, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1365, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1365, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1366, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1366, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1366, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1367, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1367, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1367, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1368, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1368, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1368, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1369, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1369, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1369, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1370, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1370, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1370, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1371, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1371, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1371, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1372, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1372, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1372, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1373, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1373, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1373, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1374, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1374, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1374, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1375, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1375, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1375, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1376, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1376, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1376, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1377, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1377, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1377, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1378, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1378, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1378, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1379, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1379, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1379, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1380, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1380, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1380, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1381, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1381, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1381, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1382, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1382, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1382, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1383, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1383, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1383, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1384, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1384, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1384, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1385, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1385, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1385, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1386, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1386, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1386, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1387, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1387, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1387, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1388, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1388, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1388, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1389, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1389, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1389, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1390, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1390, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1390, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1391, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1391, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1391, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1392, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1392, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1392, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1393, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1393, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1393, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1394, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1394, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1394, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1395, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1395, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1395, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1396, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1396, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1396, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1397, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1397, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1397, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1398, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1398, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1398, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1399, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1399, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1399, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1400, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1400, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1400, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1401, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1401, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1401, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1402, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1402, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1402, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1403, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1403, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1403, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1404, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1404, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1404, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1405, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1405, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1405, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1406, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1406, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1406, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1407, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1407, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1407, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1408, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1408, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1408, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1409, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1409, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1409, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1410, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1410, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1410, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1411, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1411, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1411, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1412, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1412, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1412, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1413, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1413, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1413, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1414, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1414, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1414, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1415, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1415, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1415, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1416, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1416, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1416, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1417, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1417, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1417, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1418, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1418, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1418, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1419, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1419, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1419, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1420, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1420, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1420, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1421, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1421, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1421, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1422, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1422, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1422, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1423, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1423, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1423, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1424, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1424, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1424, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1425, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1425, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1425, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1426, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1426, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1426, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1427, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1427, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1427, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1428, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1428, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1428, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1429, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1429, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1429, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1430, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1430, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1430, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1431, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1431, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1431, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1432, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1432, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1432, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1433, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1433, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1433, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1434, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1434, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1434, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1435, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1435, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1435, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1436, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1436, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1436, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1437, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1437, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1437, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1438, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1438, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1438, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1439, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1439, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1439, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1440, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1440, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1440, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1441, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1441, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1441, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1442, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1442, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1442, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1443, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1443, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1443, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1444, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1444, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1444, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1445, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1445, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1445, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1446, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1446, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1446, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1447, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1447, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1447, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1448, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1448, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1448, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1449, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1449, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1449, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1450, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1450, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1450, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1451, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1451, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1451, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1452, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1452, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1452, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1453, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1453, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1453, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1454, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1454, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1454, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1455, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1455, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1455, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1456, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1456, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1456, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1457, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1457, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1457, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1458, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1458, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1458, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1459, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1459, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1459, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1460, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1460, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1460, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1461, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1461, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1461, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1462, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1462, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1462, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1463, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1463, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1463, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1464, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1464, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1464, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1465, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1465, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1465, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1466, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1466, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1466, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1467, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1467, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1467, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1468, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1468, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1468, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1469, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1469, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1469, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1470, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1470, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1470, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1471, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1471, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1471, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1472, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1472, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1472, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1473, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1473, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1473, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1474, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1474, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1474, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1475, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1475, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1475, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1476, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1476, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1476, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1477, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1477, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1477, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1478, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1478, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1478, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1479, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1479, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1479, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1480, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1480, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1480, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1481, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1481, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1481, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1482, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1482, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1482, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1483, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1483, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1483, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1484, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1484, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1484, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1485, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1485, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1485, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1486, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1486, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1486, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1487, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1487, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1487, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1488, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1488, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1488, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1489, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1489, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1489, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1490, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1490, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1490, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1491, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1491, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1491, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1492, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1492, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1492, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1493, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1493, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1493, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1494, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1494, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1494, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1495, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1495, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1495, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1496, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1496, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1496, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1497, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1497, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1497, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1498, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1498, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1498, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1499, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1499, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1499, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1500, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1500, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1500, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1501, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1501, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1501, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1502, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1502, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1502, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1503, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1503, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1503, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1504, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1504, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1504, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1505, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1505, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1505, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1506, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1506, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1506, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1507, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1507, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1507, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1508, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1508, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1508, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1509, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1509, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1509, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1510, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1510, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1510, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1511, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1511, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1511, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1512, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1512, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1512, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1513, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1513, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1513, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1514, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1514, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1514, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1515, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1515, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1515, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1516, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1516, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1516, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1517, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1517, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1517, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1518, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1518, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1518, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1519, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1519, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1519, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1520, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1520, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1520, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1521, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1521, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1521, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1522, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1522, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1522, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1523, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1523, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1523, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1524, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1524, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1524, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1525, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1525, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1525, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1526, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1526, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1526, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1527, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1527, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1527, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1528, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1528, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1528, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1529, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1529, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1529, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1530, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1530, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1530, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1531, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1531, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1531, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1532, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1532, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1532, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1533, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1533, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1533, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1534, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1534, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1534, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1535, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1535, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1535, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1536, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1536, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1536, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1537, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1537, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1537, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1538, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1538, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1538, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1539, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1539, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1539, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1540, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1540, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1540, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1541, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1541, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1541, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1542, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1542, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1542, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1543, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1543, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1543, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1544, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1544, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1544, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1545, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1545, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1545, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1546, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1546, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1546, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1547, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1547, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1547, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1548, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1548, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1548, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1549, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1549, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1549, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1550, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1550, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1550, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1551, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1551, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1551, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1552, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1552, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1552, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1553, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1553, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1553, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1554, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1554, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1554, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1555, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1555, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1555, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1556, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1556, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1556, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1557, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1557, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1557, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1558, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1558, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1558, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1559, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1559, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1559, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1560, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1560, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1560, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1561, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1561, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1561, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1562, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1562, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1562, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1563, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1563, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1563, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1564, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1564, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1564, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1565, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1565, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1565, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1566, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1566, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1566, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1567, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1567, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1567, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1568, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1568, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1568, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1569, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1569, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1569, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1570, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1570, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1570, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1571, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1571, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1571, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1572, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1572, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1572, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1573, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1573, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1573, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1574, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1574, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1574, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1575, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1575, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1575, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1576, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1576, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1576, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1577, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1577, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1577, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1578, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1578, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1578, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1579, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1579, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1579, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1580, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1580, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1580, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1581, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1581, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1581, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1582, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1582, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1582, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1583, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1583, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1583, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1584, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1584, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1584, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1585, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1585, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1585, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1586, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1586, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1586, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1587, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1587, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1587, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1588, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1588, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1588, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1589, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1589, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1589, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1590, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1590, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1590, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1591, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1591, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1591, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1592, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1592, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1592, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1593, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1593, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1593, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1594, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1594, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1594, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1595, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1595, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1595, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1596, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1596, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1596, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1597, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1597, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1597, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1598, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1598, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1598, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1599, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1599, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1599, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1600, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1600, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1600, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1601, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1601, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1601, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1602, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1602, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1602, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1603, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1603, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1603, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1604, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1604, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1604, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1605, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1605, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1605, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1606, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1606, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1606, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1607, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1607, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1607, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1608, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1608, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1608, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1609, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1609, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1609, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1610, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1610, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1610, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1611, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1611, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1611, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1612, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1612, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1612, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1613, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1613, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1613, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1614, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1614, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1614, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1615, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1615, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1615, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1616, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1616, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1616, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1617, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1617, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1617, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1618, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1618, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1618, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1619, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1619, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1619, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1620, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1620, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1620, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1621, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1621, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1621, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1622, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1622, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1622, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1623, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1623, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1623, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1624, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1624, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1624, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1625, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1625, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1625, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1626, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1626, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1626, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1627, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1627, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1627, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1628, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1628, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1628, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1629, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1629, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1629, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1630, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1630, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1630, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1631, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1631, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1631, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1632, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1632, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1632, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1633, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1633, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1633, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1634, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1634, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1634, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1635, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1635, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1635, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1636, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1636, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1636, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1637, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1637, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1637, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1638, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1638, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1638, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1639, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1639, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1639, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1640, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1640, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1640, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1641, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1641, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1641, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1642, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1642, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1642, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1643, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1643, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1643, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1644, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1644, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1644, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1645, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1645, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1645, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1646, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1646, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1646, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1647, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1647, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1647, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1648, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1648, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1648, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1649, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1649, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1649, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1650, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1650, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1650, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1651, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1651, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1651, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1652, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1652, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1652, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1653, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1653, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1653, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1654, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1654, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1654, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1655, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1655, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1655, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1656, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1656, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1656, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1657, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1657, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1657, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1658, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1658, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1658, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1659, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1659, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1659, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1660, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1660, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1660, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1661, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1661, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1661, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1662, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1662, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1662, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1663, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1663, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1663, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1664, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1664, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1664, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1665, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1665, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1665, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1666, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1666, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1666, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1667, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1667, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1667, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1668, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1668, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1668, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1669, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1669, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1669, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1670, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1670, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1670, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1671, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1671, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1671, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1672, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1672, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1672, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1673, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1673, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1673, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1674, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1674, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1674, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1675, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1675, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1675, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1676, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1676, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1676, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1677, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1677, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1677, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1678, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1678, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1678, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1679, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1679, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1679, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1680, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1680, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1680, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1681, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1681, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1681, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1682, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1682, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1682, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1683, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1683, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1683, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1684, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1684, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1684, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1685, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1685, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1685, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1686, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1686, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1686, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1687, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1687, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1687, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1688, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1688, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1688, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1689, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1689, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1689, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1690, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1690, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1690, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1691, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1691, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1691, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1692, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1692, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1692, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1693, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1693, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1693, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1694, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1694, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1694, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1695, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1695, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1695, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1696, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1696, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1696, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1697, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1697, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1697, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1698, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1698, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1698, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1699, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1699, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1699, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1700, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1700, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1700, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1701, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1701, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1701, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1702, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1702, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1702, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1703, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1703, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1703, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1704, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1704, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1704, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1705, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1705, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1705, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1706, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1706, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1706, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1707, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1707, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1707, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1708, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1708, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1708, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1709, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1709, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1709, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1710, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1710, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1710, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1711, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1711, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1711, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1712, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1712, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1712, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1713, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1713, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1713, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1714, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1714, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1714, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1715, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1715, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1715, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1716, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1716, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1716, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1717, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1717, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1717, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1718, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1718, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1718, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1719, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1719, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1719, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1720, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1720, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1720, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1721, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1721, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1721, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1722, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1722, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1722, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1723, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1723, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1723, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1724, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1724, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1724, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1725, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1725, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1725, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1726, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1726, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1726, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1727, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1727, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1727, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1728, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1728, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1728, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1729, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1729, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1729, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1730, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1730, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1730, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1731, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1731, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1731, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1732, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1732, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1732, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1733, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1733, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1733, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1734, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1734, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1734, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1735, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1735, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1735, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1736, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1736, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1736, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1737, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1737, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1737, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1738, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1738, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1738, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1739, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1739, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1739, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1740, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1740, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1740, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1741, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1741, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1741, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1742, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1742, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1742, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1743, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1743, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1743, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1744, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1744, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1744, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1745, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1745, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1745, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1746, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1746, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1746, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1747, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1747, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1747, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1748, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1748, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1748, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1749, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1749, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1749, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1750, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1750, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1750, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1751, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1751, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1751, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1752, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1752, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1752, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1753, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1753, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1753, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1754, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1754, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1754, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1755, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1755, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1755, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1756, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1756, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1756, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1757, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1757, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1757, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1758, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1758, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1758, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1759, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1759, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1759, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1760, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1760, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1760, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1761, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1761, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1761, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1762, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1762, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1762, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1763, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1763, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1763, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1764, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1764, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1764, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1765, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1765, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1765, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1766, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1766, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1766, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1767, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1767, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1767, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1768, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1768, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1768, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1769, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1769, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1769, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1770, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1770, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1770, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1771, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1771, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1771, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1772, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1772, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1772, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1773, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1773, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1773, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1774, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1774, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1774, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1775, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1775, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1775, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1776, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1776, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1776, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1777, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1777, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1777, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1778, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1778, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1778, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1779, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1779, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1779, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1780, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1780, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1780, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1781, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1781, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1781, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1782, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1782, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1782, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1783, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1783, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1783, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1784, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1784, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1784, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1785, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1785, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1785, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1786, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1786, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1786, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1787, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1787, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1787, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1788, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1788, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1788, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1789, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1789, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1789, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1790, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1790, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1790, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1791, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1791, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1791, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1792, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1792, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1792, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1793, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1793, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1793, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1794, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1794, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1794, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1795, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1795, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1795, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1796, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1796, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1796, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1797, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1797, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1797, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1798, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1798, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1798, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1799, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1799, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1799, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1800, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1800, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1800, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1801, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1801, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1801, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1802, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1802, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1802, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1803, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1803, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1803, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1804, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1804, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1804, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1805, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1805, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1805, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1806, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1806, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1806, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1807, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1807, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1807, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1808, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1808, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1808, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1809, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1809, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1809, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1810, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1810, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1810, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1811, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1811, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1811, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1812, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1812, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1812, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1813, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1813, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1813, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1814, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1814, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1814, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1815, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1815, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1815, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1816, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1816, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1816, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1817, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1817, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1817, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1818, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1818, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1818, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1819, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1819, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1819, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1820, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1820, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1820, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1821, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1821, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1821, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1822, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1822, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1822, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1823, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1823, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1823, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1824, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1824, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1824, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1825, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1825, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1825, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1826, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1826, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1826, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1827, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1827, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1827, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1828, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1828, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1828, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1829, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1829, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1829, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1830, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1830, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1830, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1831, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1831, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1831, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1832, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1832, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1832, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1833, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1833, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1833, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1834, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1834, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1834, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1835, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1835, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1835, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1836, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1836, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1836, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1837, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1837, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1837, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1838, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1838, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1838, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1839, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1839, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1839, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1840, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1840, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1840, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1841, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1841, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1841, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1842, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1842, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1842, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1843, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1843, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1843, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1844, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1844, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1844, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1845, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1845, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1845, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1846, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1846, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1846, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1847, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1847, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1847, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1848, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1848, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1848, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1849, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1849, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1849, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1850, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1850, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1850, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1851, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1851, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1851, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1852, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1852, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1852, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1853, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1853, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1853, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1854, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1854, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1854, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1855, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1855, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1855, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1856, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1856, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1856, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1857, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1857, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1857, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1858, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1858, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1858, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1859, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1859, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1859, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1860, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1860, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1860, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1861, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1861, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1861, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1862, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1862, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1862, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1863, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1863, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1863, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1864, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1864, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1864, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1865, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1865, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1865, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1866, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1866, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1866, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1867, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1867, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1867, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1868, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1868, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1868, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1869, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1869, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1869, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1870, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1870, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1870, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1871, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1871, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1871, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1872, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1872, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1872, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1873, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1873, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1873, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1874, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1874, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1874, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1875, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1875, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1875, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1876, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1876, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1876, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1877, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1877, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1877, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1878, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1878, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1878, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1879, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1879, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1879, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1880, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1880, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1880, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1881, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1881, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1881, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1882, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1882, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1882, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1883, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1883, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1883, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1884, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1884, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1884, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1885, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1885, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1885, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1886, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1886, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1886, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1887, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1887, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1887, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1888, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1888, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1888, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1889, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1889, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1889, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1890, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1890, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1890, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1891, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1891, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1891, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1892, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1892, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1892, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1893, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1893, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1893, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1894, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1894, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1894, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1895, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1895, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1895, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1896, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1896, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1896, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1897, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1897, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1897, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1898, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1898, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1898, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1899, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1899, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1899, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1900, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1900, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1900, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1901, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1901, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1901, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1902, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1902, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1902, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1903, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1903, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1903, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1904, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1904, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1904, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1905, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1905, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1905, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1906, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1906, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1906, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1907, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1907, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1907, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1908, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1908, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1908, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1909, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1909, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1909, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1910, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1910, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1910, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1911, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1911, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1911, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1912, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1912, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1912, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1913, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1913, Validation Loss: 0.05, Validation Accuracy: 0.95\n",
            "Epoch: 1913, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1914, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1914, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1914, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1915, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1915, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1915, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1916, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1916, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1916, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1917, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1917, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1917, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1918, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1918, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1918, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1919, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1919, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1919, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1920, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1920, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1920, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1921, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1921, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1921, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1922, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1922, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1922, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1923, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1923, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1923, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1924, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1924, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1924, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1925, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1925, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1925, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1926, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1926, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1926, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1927, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1927, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1927, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1928, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1928, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1928, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1929, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1929, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1929, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1930, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1930, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1930, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1931, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1931, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1931, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1932, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1932, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1932, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1933, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1933, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1933, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1934, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1934, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1934, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1935, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1935, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1935, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1936, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1936, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1936, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1937, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1937, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1937, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1938, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1938, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1938, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1939, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1939, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1939, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1940, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1940, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1940, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1941, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1941, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1941, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1942, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1942, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1942, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1943, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1943, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1943, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1944, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1944, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1944, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1945, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1945, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1945, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1946, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1946, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1946, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1947, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1947, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1947, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1948, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1948, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1948, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1949, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1949, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1949, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1950, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1950, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1950, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1951, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1951, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1951, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1952, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1952, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1952, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1953, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1953, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1953, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1954, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1954, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1954, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1955, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1955, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1955, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1956, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1956, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1956, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1957, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1957, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1957, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1958, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1958, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1958, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1959, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1959, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1959, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1960, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1960, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1960, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1961, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1961, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1961, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1962, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1962, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1962, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1963, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1963, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1963, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1964, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1964, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1964, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1965, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1965, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1965, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1966, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1966, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1966, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1967, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1967, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1967, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1968, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1968, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1968, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1969, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1969, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1969, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1970, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1970, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1970, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1971, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1971, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1971, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1972, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1972, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1972, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1973, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1973, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1973, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1974, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1974, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1974, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1975, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1975, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1975, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1976, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1976, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1976, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1977, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1977, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1977, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1978, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1978, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1978, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1979, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1979, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1979, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1980, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1980, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1980, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1981, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1981, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1981, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1982, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1982, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1982, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1983, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1983, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1983, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1984, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1984, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1984, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1985, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1985, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1985, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1986, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1986, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1986, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1987, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1987, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1987, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1988, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1988, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1988, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1989, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1989, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1989, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1990, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1990, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1990, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1991, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1991, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1991, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1992, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1992, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1992, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1993, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1993, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1993, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1994, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1994, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1994, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1995, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1995, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1995, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1996, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1996, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1996, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1997, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1997, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1997, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1998, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1998, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1998, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 1999, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 1999, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 1999, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2000, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2000, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2000, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2001, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2001, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2001, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2002, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2002, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2002, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2003, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2003, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2003, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2004, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2004, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2004, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2005, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2005, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2005, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2006, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2006, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2006, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2007, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2007, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2007, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2008, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2008, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2008, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2009, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2009, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2009, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2010, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2010, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2010, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2011, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2011, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2011, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2012, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2012, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2012, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2013, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2013, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2013, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2014, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2014, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2014, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2015, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2015, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2015, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2016, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2016, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2016, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2017, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2017, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2017, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2018, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2018, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2018, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2019, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2019, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2019, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2020, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2020, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2020, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2021, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2021, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2021, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2022, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2022, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2022, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2023, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2023, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2023, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2024, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2024, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2024, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2025, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2025, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2025, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2026, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2026, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2026, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2027, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2027, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2027, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2028, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2028, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2028, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2029, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2029, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2029, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2030, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2030, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2030, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2031, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2031, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2031, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2032, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2032, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2032, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2033, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2033, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2033, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2034, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2034, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2034, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2035, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2035, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2035, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2036, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2036, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2036, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2037, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2037, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2037, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2038, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2038, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2038, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2039, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2039, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2039, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2040, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2040, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2040, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2041, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2041, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2041, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2042, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2042, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2042, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2043, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2043, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2043, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2044, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2044, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2044, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2045, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2045, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2045, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2046, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2046, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2046, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2047, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2047, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2047, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2048, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2048, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2048, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2049, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2049, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2049, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2050, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2050, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2050, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2051, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2051, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2051, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2052, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2052, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2052, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2053, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2053, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2053, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2054, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2054, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2054, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2055, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2055, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2055, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2056, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2056, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2056, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2057, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2057, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2057, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2058, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2058, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2058, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2059, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2059, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2059, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2060, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2060, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2060, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2061, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2061, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2061, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2062, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2062, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2062, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2063, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2063, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2063, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2064, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2064, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2064, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2065, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2065, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2065, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2066, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2066, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2066, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2067, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2067, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2067, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2068, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2068, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2068, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2069, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2069, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2069, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2070, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2070, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2070, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2071, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2071, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2071, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2072, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2072, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2072, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2073, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2073, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2073, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2074, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2074, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2074, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2075, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2075, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2075, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2076, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2076, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2076, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2077, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2077, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2077, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2078, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2078, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2078, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2079, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2079, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2079, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2080, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2080, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2080, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2081, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2081, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2081, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2082, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2082, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2082, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2083, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2083, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2083, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2084, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2084, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2084, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2085, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2085, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2085, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2086, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2086, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2086, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2087, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2087, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2087, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2088, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2088, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2088, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2089, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2089, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2089, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2090, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2090, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2090, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2091, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2091, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2091, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2092, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2092, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2092, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2093, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2093, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2093, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2094, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2094, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2094, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2095, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2095, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2095, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2096, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2096, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2096, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2097, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2097, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2097, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2098, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2098, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2098, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2099, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2099, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2099, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2100, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2100, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2100, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2101, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2101, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2101, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2102, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2102, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2102, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2103, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2103, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2103, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2104, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2104, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2104, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2105, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2105, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2105, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2106, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2106, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2106, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2107, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2107, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2107, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2108, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2108, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2108, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2109, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2109, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2109, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2110, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2110, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2110, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2111, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2111, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2111, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2112, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2112, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2112, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2113, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2113, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2113, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2114, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2114, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2114, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2115, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2115, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2115, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2116, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2116, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2116, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2117, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2117, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2117, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2118, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2118, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2118, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2119, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2119, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2119, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2120, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2120, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2120, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2121, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2121, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2121, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2122, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2122, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2122, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2123, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2123, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2123, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2124, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2124, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2124, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2125, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2125, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2125, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2126, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2126, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2126, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2127, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2127, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2127, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2128, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2128, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2128, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2129, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2129, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2129, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2130, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2130, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2130, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2131, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2131, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2131, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2132, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2132, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2132, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2133, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2133, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2133, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2134, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2134, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2134, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2135, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2135, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2135, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2136, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2136, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2136, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2137, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2137, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2137, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2138, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2138, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2138, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2139, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2139, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2139, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2140, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2140, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2140, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2141, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2141, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2141, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2142, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2142, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2142, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2143, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2143, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2143, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2144, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2144, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2144, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2145, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2145, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2145, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2146, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2146, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2146, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2147, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2147, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2147, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2148, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2148, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2148, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2149, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2149, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2149, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2150, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2150, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2150, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2151, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2151, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2151, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2152, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2152, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2152, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2153, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2153, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2153, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2154, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2154, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2154, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2155, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2155, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2155, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2156, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2156, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2156, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2157, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2157, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2157, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2158, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2158, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2158, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2159, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2159, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2159, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2160, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2160, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2160, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2161, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2161, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2161, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2162, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2162, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2162, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2163, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2163, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2163, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2164, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2164, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2164, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2165, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2165, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2165, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2166, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2166, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2166, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2167, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2167, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2167, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2168, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2168, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2168, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2169, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2169, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2169, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2170, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2170, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2170, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2171, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2171, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2171, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2172, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2172, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2172, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2173, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2173, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2173, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2174, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2174, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2174, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2175, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2175, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2175, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2176, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2176, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2176, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2177, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2177, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2177, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2178, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2178, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2178, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2179, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2179, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2179, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2180, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2180, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2180, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2181, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2181, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2181, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2182, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2182, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2182, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2183, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2183, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2183, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2184, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2184, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2184, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2185, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2185, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2185, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2186, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2186, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2186, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2187, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2187, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2187, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2188, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2188, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2188, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2189, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2189, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2189, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2190, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2190, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2190, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2191, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2191, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2191, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2192, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2192, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2192, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2193, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2193, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2193, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2194, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2194, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2194, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2195, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2195, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2195, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2196, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2196, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2196, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2197, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2197, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2197, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2198, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2198, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2198, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2199, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2199, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2199, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2200, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2200, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2200, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2201, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2201, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2201, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2202, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2202, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2202, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2203, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2203, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2203, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2204, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2204, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2204, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2205, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2205, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2205, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2206, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2206, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2206, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2207, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2207, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2207, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2208, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2208, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2208, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2209, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2209, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2209, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2210, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2210, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2210, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2211, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2211, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2211, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2212, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2212, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2212, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2213, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2213, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2213, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2214, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2214, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2214, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2215, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2215, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2215, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2216, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2216, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2216, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2217, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2217, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2217, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2218, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2218, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2218, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2219, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2219, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2219, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2220, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2220, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2220, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2221, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2221, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2221, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2222, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2222, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2222, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2223, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2223, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2223, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2224, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2224, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2224, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2225, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2225, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2225, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2226, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2226, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2226, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2227, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2227, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2227, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2228, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2228, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2228, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2229, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2229, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2229, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2230, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2230, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2230, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2231, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2231, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2231, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2232, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2232, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2232, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2233, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2233, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2233, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2234, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2234, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2234, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2235, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2235, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2235, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2236, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2236, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2236, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2237, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2237, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2237, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2238, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2238, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2238, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2239, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2239, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2239, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2240, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2240, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2240, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2241, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2241, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2241, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2242, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2242, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2242, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2243, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2243, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2243, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2244, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2244, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2244, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2245, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2245, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2245, Testing Loss: 0.05, Testing Accuracy: 0.94\n",
            "Epoch: 2246, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2246, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2246, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2247, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2247, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2247, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2248, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2248, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2248, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2249, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2249, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2249, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2250, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2250, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2250, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2251, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2251, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2251, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2252, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2252, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2252, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2253, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2253, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2253, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2254, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2254, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2254, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2255, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2255, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2255, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2256, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2256, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2256, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2257, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2257, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2257, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2258, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2258, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2258, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2259, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2259, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2259, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2260, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2260, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2260, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2261, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2261, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2261, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2262, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2262, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2262, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2263, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2263, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2263, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2264, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2264, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2264, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2265, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2265, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2265, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2266, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2266, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2266, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2267, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2267, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2267, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2268, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2268, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2268, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2269, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2269, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2269, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2270, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2270, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2270, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2271, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2271, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2271, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2272, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2272, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2272, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2273, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2273, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2273, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2274, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2274, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2274, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2275, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2275, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2275, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2276, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2276, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2276, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2277, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2277, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2277, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2278, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2278, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2278, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2279, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2279, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2279, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2280, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2280, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2280, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2281, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2281, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2281, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2282, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2282, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2282, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2283, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2283, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2283, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2284, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2284, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2284, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2285, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2285, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2285, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2286, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2286, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2286, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2287, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2287, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2287, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2288, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2288, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2288, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2289, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2289, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2289, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2290, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2290, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2290, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2291, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2291, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2291, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2292, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2292, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2292, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2293, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2293, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2293, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2294, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2294, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2294, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2295, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2295, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2295, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2296, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2296, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2296, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2297, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2297, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2297, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2298, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2298, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2298, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2299, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2299, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2299, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2300, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2300, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2300, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2301, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2301, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2301, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2302, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2302, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2302, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2303, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2303, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2303, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2304, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2304, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2304, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2305, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2305, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2305, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2306, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2306, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2306, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2307, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2307, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2307, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2308, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2308, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2308, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2309, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2309, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2309, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2310, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2310, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2310, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2311, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2311, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2311, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2312, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2312, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2312, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2313, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2313, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2313, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2314, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2314, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2314, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2315, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2315, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2315, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2316, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2316, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2316, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2317, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2317, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2317, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2318, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2318, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2318, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2319, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2319, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2319, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2320, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2320, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2320, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2321, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2321, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2321, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2322, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2322, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2322, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2323, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2323, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2323, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2324, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2324, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2324, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2325, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2325, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2325, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2326, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2326, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2326, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2327, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2327, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2327, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2328, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2328, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2328, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2329, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2329, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2329, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2330, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2330, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2330, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2331, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2331, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2331, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2332, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2332, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2332, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2333, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2333, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2333, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2334, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2334, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2334, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2335, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2335, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2335, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2336, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2336, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2336, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2337, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2337, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2337, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2338, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2338, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2338, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2339, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2339, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2339, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2340, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2340, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2340, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2341, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2341, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2341, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2342, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2342, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2342, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2343, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2343, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2343, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2344, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2344, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2344, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2345, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2345, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2345, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2346, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2346, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2346, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2347, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2347, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2347, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2348, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2348, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2348, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2349, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2349, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2349, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2350, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2350, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2350, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2351, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2351, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2351, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2352, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2352, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2352, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2353, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2353, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2353, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2354, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2354, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2354, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2355, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2355, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2355, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2356, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2356, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2356, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2357, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2357, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2357, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2358, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2358, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2358, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2359, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2359, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2359, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2360, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2360, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2360, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2361, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2361, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2361, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2362, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2362, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2362, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2363, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2363, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2363, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2364, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2364, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2364, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2365, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2365, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2365, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2366, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2366, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2366, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2367, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2367, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2367, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2368, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2368, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2368, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2369, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2369, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2369, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2370, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2370, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2370, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2371, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2371, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2371, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2372, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2372, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2372, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2373, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2373, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2373, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2374, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2374, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2374, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2375, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2375, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2375, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2376, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2376, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2376, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2377, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2377, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2377, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2378, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2378, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2378, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2379, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2379, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2379, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2380, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2380, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2380, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2381, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2381, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2381, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2382, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2382, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2382, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2383, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2383, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2383, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2384, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2384, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2384, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2385, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2385, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2385, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2386, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2386, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2386, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2387, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2387, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2387, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2388, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2388, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2388, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2389, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2389, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2389, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2390, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2390, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2390, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2391, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2391, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2391, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2392, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2392, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2392, Testing Loss: 0.05, Testing Accuracy: 0.95\n",
            "Epoch: 2393, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2393, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2393, Testing Loss: 0.04, Testing Accuracy: 0.95\n",
            "Epoch: 2394, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2394, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2394, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2395, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2395, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2395, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2396, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2396, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2396, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2397, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2397, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2397, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2398, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2398, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2398, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2399, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2399, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2399, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2400, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2400, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2400, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2401, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2401, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2401, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2402, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2402, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2402, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2403, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2403, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2403, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2404, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2404, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2404, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2405, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2405, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2405, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2406, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2406, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2406, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2407, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2407, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2407, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2408, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2408, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2408, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2409, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2409, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2409, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2410, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2410, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2410, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2411, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2411, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2411, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2412, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2412, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2412, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2413, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2413, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2413, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2414, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2414, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2414, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2415, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2415, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2415, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2416, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2416, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2416, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2417, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2417, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2417, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2418, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2418, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2418, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2419, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2419, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2419, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2420, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2420, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2420, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2421, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2421, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2421, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2422, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2422, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2422, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2423, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2423, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2423, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2424, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2424, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2424, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2425, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2425, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2425, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2426, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2426, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2426, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2427, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2427, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2427, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2428, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2428, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2428, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2429, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2429, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2429, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2430, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2430, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2430, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2431, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2431, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2431, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2432, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2432, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2432, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2433, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2433, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2433, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2434, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2434, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2434, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2435, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2435, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2435, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2436, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2436, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2436, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2437, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2437, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2437, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2438, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2438, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2438, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2439, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2439, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2439, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2440, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2440, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2440, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2441, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2441, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2441, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2442, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2442, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2442, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2443, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2443, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2443, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2444, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2444, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2444, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2445, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2445, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2445, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2446, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2446, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2446, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2447, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2447, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2447, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2448, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2448, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2448, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2449, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2449, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2449, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2450, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2450, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2450, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2451, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2451, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2451, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2452, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2452, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2452, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2453, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2453, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2453, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2454, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2454, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2454, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2455, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2455, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2455, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2456, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2456, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2456, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2457, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2457, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2457, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2458, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2458, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2458, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2459, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2459, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2459, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2460, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2460, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2460, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2461, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2461, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2461, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2462, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2462, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2462, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2463, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2463, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2463, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2464, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2464, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2464, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2465, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2465, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2465, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2466, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2466, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2466, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2467, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2467, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2467, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2468, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2468, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2468, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2469, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2469, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2469, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2470, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2470, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2470, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2471, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2471, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2471, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2472, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2472, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2472, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2473, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2473, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2473, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2474, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2474, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2474, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2475, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2475, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2475, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2476, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2476, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2476, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2477, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2477, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2477, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2478, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2478, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2478, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2479, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2479, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2479, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2480, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2480, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2480, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2481, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2481, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2481, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2482, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2482, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2482, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2483, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2483, Validation Loss: 0.04, Validation Accuracy: 0.95\n",
            "Epoch: 2483, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2484, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2484, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2484, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2485, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2485, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2485, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2486, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2486, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2486, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2487, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2487, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2487, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2488, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2488, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2488, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2489, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2489, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2489, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2490, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2490, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2490, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2491, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2491, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2491, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2492, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2492, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2492, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2493, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2493, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2493, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2494, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2494, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2494, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2495, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2495, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2495, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2496, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2496, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2496, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2497, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2497, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2497, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2498, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2498, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2498, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2499, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2499, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2499, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2500, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2500, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2500, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2501, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2501, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2501, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2502, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2502, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2502, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2503, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2503, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2503, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2504, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2504, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2504, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2505, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2505, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2505, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2506, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2506, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2506, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2507, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2507, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2507, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2508, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2508, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2508, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2509, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2509, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2509, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2510, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2510, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2510, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2511, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2511, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2511, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2512, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2512, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2512, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2513, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2513, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2513, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2514, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2514, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2514, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2515, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2515, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2515, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2516, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2516, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2516, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2517, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2517, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2517, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2518, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2518, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2518, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2519, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2519, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2519, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2520, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2520, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2520, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2521, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2521, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2521, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2522, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2522, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2522, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2523, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2523, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2523, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2524, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2524, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2524, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2525, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2525, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2525, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2526, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2526, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2526, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2527, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2527, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2527, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2528, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2528, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2528, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2529, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2529, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2529, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2530, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2530, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2530, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2531, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2531, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2531, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2532, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2532, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2532, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2533, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2533, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2533, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2534, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2534, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2534, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2535, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2535, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2535, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2536, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2536, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2536, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2537, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2537, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2537, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2538, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2538, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2538, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2539, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2539, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2539, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2540, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2540, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2540, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2541, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2541, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2541, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2542, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2542, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2542, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2543, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2543, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2543, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2544, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2544, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2544, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2545, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2545, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2545, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2546, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2546, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2546, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2547, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2547, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2547, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2548, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2548, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2548, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2549, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2549, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2549, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2550, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2550, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2550, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2551, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2551, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2551, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2552, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2552, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2552, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2553, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2553, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2553, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2554, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2554, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2554, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2555, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2555, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2555, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2556, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2556, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2556, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2557, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2557, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2557, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2558, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2558, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2558, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2559, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2559, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2559, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2560, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2560, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2560, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2561, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2561, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2561, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2562, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2562, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2562, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2563, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2563, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2563, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2564, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2564, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2564, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2565, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2565, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2565, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2566, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2566, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2566, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2567, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2567, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2567, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2568, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2568, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2568, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2569, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2569, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2569, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2570, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2570, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2570, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2571, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2571, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2571, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2572, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2572, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2572, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2573, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2573, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2573, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2574, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2574, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2574, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2575, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2575, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2575, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2576, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2576, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2576, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2577, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2577, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2577, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2578, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2578, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2578, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2579, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2579, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2579, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2580, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2580, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2580, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2581, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2581, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2581, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2582, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2582, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2582, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2583, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2583, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2583, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2584, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2584, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2584, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2585, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2585, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2585, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2586, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2586, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2586, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2587, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2587, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2587, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2588, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2588, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2588, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2589, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2589, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2589, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2590, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2590, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2590, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2591, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2591, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2591, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2592, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2592, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2592, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2593, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2593, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2593, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2594, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2594, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2594, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2595, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2595, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2595, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2596, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2596, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2596, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2597, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2597, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2597, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2598, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2598, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2598, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2599, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2599, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2599, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2600, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2600, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2600, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2601, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2601, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2601, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2602, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2602, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2602, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2603, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2603, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2603, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2604, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2604, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2604, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2605, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2605, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2605, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2606, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2606, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2606, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2607, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2607, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2607, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2608, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2608, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2608, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2609, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2609, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2609, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2610, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2610, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2610, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2611, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2611, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2611, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2612, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2612, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2612, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2613, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2613, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2613, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2614, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2614, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2614, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2615, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2615, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2615, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2616, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2616, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2616, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2617, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2617, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2617, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2618, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2618, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2618, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2619, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2619, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2619, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2620, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2620, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2620, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2621, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2621, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2621, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2622, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2622, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2622, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2623, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2623, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2623, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2624, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2624, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2624, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2625, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2625, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2625, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2626, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2626, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2626, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2627, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2627, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2627, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2628, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2628, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2628, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2629, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2629, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2629, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2630, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2630, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2630, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2631, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2631, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2631, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2632, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2632, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2632, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2633, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2633, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2633, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2634, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2634, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2634, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2635, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2635, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2635, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2636, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2636, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2636, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2637, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2637, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2637, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2638, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2638, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2638, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2639, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2639, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2639, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2640, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2640, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2640, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2641, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2641, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2641, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2642, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2642, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2642, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2643, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2643, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2643, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2644, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2644, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2644, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2645, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2645, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2645, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2646, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2646, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2646, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2647, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2647, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2647, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2648, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2648, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2648, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2649, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2649, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2649, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2650, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2650, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2650, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2651, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2651, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2651, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2652, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2652, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2652, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2653, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2653, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2653, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2654, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2654, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2654, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2655, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2655, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2655, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2656, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2656, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2656, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2657, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2657, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2657, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2658, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2658, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2658, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2659, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2659, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2659, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2660, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2660, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2660, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2661, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2661, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2661, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2662, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2662, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2662, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2663, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2663, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2663, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2664, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2664, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2664, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2665, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2665, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2665, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2666, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2666, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2666, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2667, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2667, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2667, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2668, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2668, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2668, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2669, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2669, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2669, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2670, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2670, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2670, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2671, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2671, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2671, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2672, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2672, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2672, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2673, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2673, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2673, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2674, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2674, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2674, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2675, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2675, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2675, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2676, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2676, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2676, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2677, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2677, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2677, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2678, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2678, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2678, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2679, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2679, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2679, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2680, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2680, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2680, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2681, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2681, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2681, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2682, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2682, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2682, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2683, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2683, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2683, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2684, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2684, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2684, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2685, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2685, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2685, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2686, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2686, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2686, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2687, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2687, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2687, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2688, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2688, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2688, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2689, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2689, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2689, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2690, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2690, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2690, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2691, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2691, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2691, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2692, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2692, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2692, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2693, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2693, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2693, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2694, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2694, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2694, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2695, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2695, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2695, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2696, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2696, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2696, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2697, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2697, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2697, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2698, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2698, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2698, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2699, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2699, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2699, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2700, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2700, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2700, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2701, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2701, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2701, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2702, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2702, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2702, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2703, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2703, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2703, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2704, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2704, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2704, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2705, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2705, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2705, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2706, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2706, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2706, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2707, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2707, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2707, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2708, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2708, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2708, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2709, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2709, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2709, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2710, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2710, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2710, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2711, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2711, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2711, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2712, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2712, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2712, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2713, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2713, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2713, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2714, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2714, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2714, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2715, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2715, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2715, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2716, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2716, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2716, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2717, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2717, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2717, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2718, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2718, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2718, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2719, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2719, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2719, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2720, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2720, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2720, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2721, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2721, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2721, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2722, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2722, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2722, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2723, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2723, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2723, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2724, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2724, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2724, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2725, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2725, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2725, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2726, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2726, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2726, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2727, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2727, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2727, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2728, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2728, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2728, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2729, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2729, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2729, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2730, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2730, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2730, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2731, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2731, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2731, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2732, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2732, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2732, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2733, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2733, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2733, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2734, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2734, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2734, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2735, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2735, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2735, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2736, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2736, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2736, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2737, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2737, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2737, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2738, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2738, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2738, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2739, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2739, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2739, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2740, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2740, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2740, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2741, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2741, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2741, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2742, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2742, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2742, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2743, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2743, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2743, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2744, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2744, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2744, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2745, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2745, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2745, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2746, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2746, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2746, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2747, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2747, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2747, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2748, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2748, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2748, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2749, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2749, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2749, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2750, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2750, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2750, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2751, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2751, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2751, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2752, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2752, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2752, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2753, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2753, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2753, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2754, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2754, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2754, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2755, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2755, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2755, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2756, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2756, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2756, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2757, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2757, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2757, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2758, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2758, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2758, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2759, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2759, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2759, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2760, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2760, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2760, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2761, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2761, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2761, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2762, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2762, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2762, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2763, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2763, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2763, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2764, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2764, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2764, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2765, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2765, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2765, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2766, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2766, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2766, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2767, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2767, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2767, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2768, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2768, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2768, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2769, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2769, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2769, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2770, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2770, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2770, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2771, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2771, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2771, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2772, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2772, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2772, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2773, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2773, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2773, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2774, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2774, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2774, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2775, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2775, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2775, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2776, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2776, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2776, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2777, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2777, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2777, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2778, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2778, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2778, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2779, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2779, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2779, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2780, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2780, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2780, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2781, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2781, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2781, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2782, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2782, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2782, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2783, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2783, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2783, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2784, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2784, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2784, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2785, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2785, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2785, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2786, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2786, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2786, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2787, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2787, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2787, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2788, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2788, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2788, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2789, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2789, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2789, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2790, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2790, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2790, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2791, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2791, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2791, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2792, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2792, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2792, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2793, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2793, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2793, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2794, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2794, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2794, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2795, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2795, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2795, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2796, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2796, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2796, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2797, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2797, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2797, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2798, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2798, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2798, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2799, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2799, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2799, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2800, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2800, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2800, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2801, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2801, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2801, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2802, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2802, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2802, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2803, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2803, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2803, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2804, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2804, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2804, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2805, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2805, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2805, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2806, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2806, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2806, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2807, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2807, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2807, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2808, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2808, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2808, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2809, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2809, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2809, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2810, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2810, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2810, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2811, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2811, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2811, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2812, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2812, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2812, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2813, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2813, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2813, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2814, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2814, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2814, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2815, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2815, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2815, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2816, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2816, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2816, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2817, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2817, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2817, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2818, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2818, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2818, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2819, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2819, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2819, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2820, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2820, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2820, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2821, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2821, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2821, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2822, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2822, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2822, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2823, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2823, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2823, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2824, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2824, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2824, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2825, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2825, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2825, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2826, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2826, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2826, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2827, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2827, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2827, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2828, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2828, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2828, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2829, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2829, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2829, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2830, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2830, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2830, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2831, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2831, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2831, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2832, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2832, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2832, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2833, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2833, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2833, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2834, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2834, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2834, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2835, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2835, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2835, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2836, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2836, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2836, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2837, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2837, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2837, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2838, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2838, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2838, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2839, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2839, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2839, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2840, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2840, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2840, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2841, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2841, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2841, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2842, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2842, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2842, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2843, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2843, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2843, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2844, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2844, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2844, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2845, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2845, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2845, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2846, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2846, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2846, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2847, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2847, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2847, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2848, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2848, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2848, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2849, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2849, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2849, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2850, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2850, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2850, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2851, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2851, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2851, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2852, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2852, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2852, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2853, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2853, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2853, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2854, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2854, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2854, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2855, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2855, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2855, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2856, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2856, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2856, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2857, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2857, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2857, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2858, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2858, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2858, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2859, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2859, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2859, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2860, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2860, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2860, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2861, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2861, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2861, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2862, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2862, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2862, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2863, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2863, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2863, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2864, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2864, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2864, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2865, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2865, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2865, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2866, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2866, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2866, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2867, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2867, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2867, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2868, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2868, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2868, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2869, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2869, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2869, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2870, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2870, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2870, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2871, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2871, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2871, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2872, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2872, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2872, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2873, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2873, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2873, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2874, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2874, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2874, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2875, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2875, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2875, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2876, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2876, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2876, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2877, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2877, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2877, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2878, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2878, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2878, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2879, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2879, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2879, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2880, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2880, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2880, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2881, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2881, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2881, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2882, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2882, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2882, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2883, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2883, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2883, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2884, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2884, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2884, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2885, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2885, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2885, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2886, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2886, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2886, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2887, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2887, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2887, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2888, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2888, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2888, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2889, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2889, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2889, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2890, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2890, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2890, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2891, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2891, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2891, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2892, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2892, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2892, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2893, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2893, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2893, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2894, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2894, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2894, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2895, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2895, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2895, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2896, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2896, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2896, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2897, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2897, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2897, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2898, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2898, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2898, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2899, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2899, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2899, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2900, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2900, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2900, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2901, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2901, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2901, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2902, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2902, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2902, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2903, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2903, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2903, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2904, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2904, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2904, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2905, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2905, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2905, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2906, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2906, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2906, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2907, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2907, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2907, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2908, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2908, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2908, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2909, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2909, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2909, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2910, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2910, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2910, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2911, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2911, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2911, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2912, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2912, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2912, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2913, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2913, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2913, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2914, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2914, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2914, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2915, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2915, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2915, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2916, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2916, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2916, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2917, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2917, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2917, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2918, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2918, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2918, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2919, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2919, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2919, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2920, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2920, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2920, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2921, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2921, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2921, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2922, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2922, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2922, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2923, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2923, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2923, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2924, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2924, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2924, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2925, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2925, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2925, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2926, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2926, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2926, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2927, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2927, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2927, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2928, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2928, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2928, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2929, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2929, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2929, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2930, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2930, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2930, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2931, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2931, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2931, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2932, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2932, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2932, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2933, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2933, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2933, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2934, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2934, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2934, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2935, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2935, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2935, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2936, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2936, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2936, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2937, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2937, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2937, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2938, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2938, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2938, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2939, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2939, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2939, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2940, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2940, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2940, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2941, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2941, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2941, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2942, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2942, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2942, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2943, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2943, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2943, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2944, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2944, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2944, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2945, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2945, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2945, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2946, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2946, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2946, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2947, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2947, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2947, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2948, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2948, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2948, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2949, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2949, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2949, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2950, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2950, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2950, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2951, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2951, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2951, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2952, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2952, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2952, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2953, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2953, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2953, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2954, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2954, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2954, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2955, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2955, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2955, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2956, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2956, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2956, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2957, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2957, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2957, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2958, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2958, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2958, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2959, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2959, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2959, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2960, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2960, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2960, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2961, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2961, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2961, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2962, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2962, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2962, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2963, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2963, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2963, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2964, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2964, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2964, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2965, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2965, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2965, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2966, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2966, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2966, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2967, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2967, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2967, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2968, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2968, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2968, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2969, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2969, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2969, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2970, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2970, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2970, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2971, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2971, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2971, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2972, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2972, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2972, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2973, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2973, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2973, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2974, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2974, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2974, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2975, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2975, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2975, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2976, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2976, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2976, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2977, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2977, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2977, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2978, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2978, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2978, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2979, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2979, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2979, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2980, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2980, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2980, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2981, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2981, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2981, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2982, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2982, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2982, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2983, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2983, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2983, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2984, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2984, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2984, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2985, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2985, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2985, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2986, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2986, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2986, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2987, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2987, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2987, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2988, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2988, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2988, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2989, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2989, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2989, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2990, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2990, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2990, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2991, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2991, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2991, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2992, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2992, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2992, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2993, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2993, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2993, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2994, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2994, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2994, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2995, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2995, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2995, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2996, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2996, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2996, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2997, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2997, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2997, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2998, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2998, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2998, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 2999, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 2999, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 2999, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3000, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3000, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3000, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3001, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3001, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3001, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3002, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3002, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3002, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3003, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3003, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3003, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3004, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3004, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3004, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3005, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3005, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3005, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3006, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3006, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3006, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3007, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3007, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3007, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3008, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3008, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3008, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3009, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3009, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3009, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3010, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3010, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3010, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3011, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3011, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3011, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3012, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3012, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3012, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3013, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3013, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3013, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3014, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3014, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3014, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3015, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3015, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3015, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3016, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3016, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3016, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3017, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3017, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3017, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3018, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3018, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3018, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3019, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3019, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3019, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3020, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3020, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3020, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3021, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3021, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3021, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3022, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3022, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3022, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3023, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3023, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3023, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3024, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3024, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3024, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3025, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3025, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3025, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3026, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3026, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3026, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3027, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3027, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3027, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3028, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3028, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3028, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3029, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3029, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3029, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3030, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3030, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3030, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3031, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3031, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3031, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3032, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3032, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3032, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3033, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3033, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3033, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3034, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3034, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3034, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3035, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3035, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3035, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3036, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3036, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3036, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3037, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3037, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3037, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3038, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3038, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3038, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3039, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3039, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3039, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3040, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3040, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3040, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3041, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3041, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3041, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3042, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3042, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3042, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3043, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3043, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3043, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3044, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3044, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3044, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3045, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3045, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3045, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3046, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3046, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3046, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3047, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3047, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3047, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3048, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3048, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3048, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3049, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3049, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3049, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3050, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3050, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3050, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3051, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3051, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3051, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3052, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3052, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3052, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3053, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3053, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3053, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3054, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3054, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3054, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3055, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3055, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3055, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3056, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3056, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3056, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3057, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3057, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3057, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3058, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3058, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3058, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3059, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3059, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3059, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3060, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3060, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3060, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3061, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3061, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3061, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3062, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3062, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3062, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3063, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3063, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3063, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3064, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3064, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3064, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3065, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3065, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3065, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3066, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3066, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3066, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3067, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3067, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3067, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3068, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3068, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3068, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3069, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3069, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3069, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3070, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3070, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3070, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3071, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3071, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3071, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3072, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3072, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3072, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3073, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3073, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3073, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3074, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3074, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3074, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3075, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3075, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3075, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3076, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3076, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3076, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3077, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3077, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3077, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3078, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3078, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3078, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3079, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3079, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3079, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3080, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3080, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3080, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3081, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3081, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3081, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3082, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3082, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3082, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3083, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3083, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3083, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3084, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3084, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3084, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3085, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3085, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3085, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3086, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3086, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3086, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3087, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3087, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3087, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3088, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3088, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3088, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3089, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3089, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3089, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3090, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3090, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3090, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3091, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3091, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3091, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3092, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3092, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3092, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3093, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3093, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3093, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3094, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3094, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3094, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3095, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3095, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3095, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3096, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3096, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3096, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3097, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3097, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3097, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3098, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3098, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3098, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3099, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3099, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3099, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3100, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3100, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3100, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3101, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3101, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3101, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3102, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3102, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3102, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3103, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3103, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3103, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3104, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3104, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3104, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3105, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3105, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3105, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3106, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3106, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3106, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3107, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3107, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3107, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3108, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3108, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3108, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3109, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3109, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3109, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3110, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3110, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3110, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3111, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3111, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3111, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3112, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3112, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3112, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3113, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3113, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3113, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3114, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3114, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3114, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3115, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3115, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3115, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3116, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3116, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3116, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3117, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3117, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3117, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3118, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3118, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3118, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3119, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3119, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3119, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3120, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3120, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3120, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3121, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3121, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3121, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3122, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3122, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3122, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3123, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3123, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3123, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3124, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3124, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3124, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3125, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3125, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3125, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3126, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3126, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3126, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3127, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3127, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3127, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3128, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3128, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3128, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3129, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3129, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3129, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3130, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3130, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3130, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3131, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3131, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3131, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3132, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3132, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3132, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3133, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3133, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3133, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3134, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3134, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3134, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3135, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3135, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3135, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3136, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3136, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3136, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3137, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3137, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3137, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3138, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3138, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3138, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3139, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3139, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3139, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3140, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3140, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3140, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3141, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3141, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3141, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3142, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3142, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3142, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3143, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3143, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3143, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3144, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3144, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3144, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3145, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3145, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3145, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3146, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3146, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3146, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3147, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3147, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3147, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3148, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3148, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3148, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3149, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3149, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3149, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3150, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3150, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3150, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3151, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3151, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3151, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3152, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3152, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3152, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3153, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3153, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3153, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3154, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3154, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3154, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3155, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3155, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3155, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3156, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3156, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3156, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3157, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3157, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3157, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3158, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3158, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3158, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3159, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3159, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3159, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3160, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3160, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3160, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3161, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3161, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3161, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3162, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3162, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3162, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3163, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3163, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3163, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3164, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3164, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3164, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3165, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3165, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3165, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3166, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3166, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3166, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3167, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3167, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3167, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3168, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3168, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3168, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3169, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3169, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3169, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3170, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3170, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3170, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3171, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3171, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3171, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3172, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3172, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3172, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3173, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3173, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3173, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3174, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3174, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3174, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3175, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3175, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3175, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3176, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3176, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3176, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3177, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3177, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3177, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3178, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3178, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3178, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3179, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3179, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3179, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3180, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3180, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3180, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3181, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3181, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3181, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3182, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3182, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3182, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3183, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3183, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3183, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3184, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3184, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3184, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3185, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3185, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3185, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3186, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3186, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3186, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3187, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3187, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3187, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3188, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3188, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3188, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3189, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3189, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3189, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3190, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3190, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3190, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3191, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3191, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3191, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3192, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3192, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3192, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3193, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3193, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3193, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3194, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3194, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3194, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3195, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3195, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3195, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3196, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3196, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3196, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3197, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3197, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3197, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3198, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3198, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3198, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3199, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3199, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3199, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3200, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3200, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3200, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3201, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3201, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3201, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3202, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3202, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3202, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3203, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3203, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3203, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3204, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3204, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3204, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3205, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3205, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3205, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3206, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3206, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3206, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3207, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3207, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3207, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3208, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3208, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3208, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3209, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3209, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3209, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3210, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3210, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3210, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3211, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3211, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3211, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3212, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3212, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3212, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3213, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3213, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3213, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3214, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3214, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3214, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3215, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3215, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3215, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3216, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3216, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3216, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3217, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3217, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3217, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3218, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3218, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3218, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3219, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3219, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3219, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3220, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3220, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3220, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3221, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3221, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3221, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3222, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3222, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3222, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3223, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3223, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3223, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3224, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3224, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3224, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3225, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3225, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3225, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3226, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3226, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3226, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3227, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3227, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3227, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3228, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3228, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3228, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3229, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3229, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3229, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3230, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3230, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3230, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3231, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3231, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3231, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3232, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3232, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3232, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3233, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3233, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3233, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3234, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3234, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3234, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3235, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3235, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3235, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3236, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3236, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3236, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3237, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3237, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3237, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3238, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3238, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3238, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3239, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3239, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3239, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3240, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3240, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3240, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3241, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3241, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3241, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3242, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3242, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3242, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3243, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3243, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3243, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3244, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3244, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3244, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3245, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3245, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3245, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3246, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3246, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3246, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3247, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3247, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3247, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3248, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3248, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3248, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3249, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3249, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3249, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3250, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3250, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3250, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3251, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3251, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3251, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3252, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3252, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3252, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3253, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3253, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3253, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3254, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3254, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3254, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3255, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3255, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3255, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3256, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3256, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3256, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3257, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3257, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3257, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3258, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3258, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3258, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3259, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3259, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3259, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3260, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3260, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3260, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3261, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3261, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3261, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3262, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3262, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3262, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3263, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3263, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3263, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3264, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3264, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3264, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3265, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3265, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3265, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3266, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3266, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3266, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3267, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3267, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3267, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3268, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3268, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3268, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3269, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3269, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3269, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3270, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3270, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3270, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3271, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3271, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3271, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3272, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3272, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3272, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3273, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3273, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3273, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3274, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3274, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3274, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3275, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3275, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3275, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3276, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3276, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3276, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3277, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3277, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3277, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3278, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3278, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3278, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3279, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3279, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3279, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3280, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3280, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3280, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3281, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3281, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3281, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3282, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3282, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3282, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3283, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3283, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3283, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3284, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3284, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3284, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3285, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3285, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3285, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3286, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3286, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3286, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3287, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3287, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3287, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3288, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3288, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3288, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3289, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3289, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3289, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3290, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3290, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3290, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3291, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3291, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3291, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3292, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3292, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3292, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3293, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3293, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3293, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3294, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3294, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3294, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3295, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3295, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3295, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3296, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3296, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3296, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3297, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3297, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3297, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3298, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3298, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3298, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3299, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3299, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3299, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3300, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3300, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3300, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3301, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3301, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3301, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3302, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3302, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3302, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3303, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3303, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3303, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3304, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3304, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3304, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3305, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3305, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3305, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3306, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3306, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3306, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3307, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3307, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3307, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3308, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3308, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3308, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3309, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3309, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3309, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3310, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3310, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3310, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3311, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3311, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3311, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3312, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3312, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3312, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3313, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3313, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3313, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3314, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3314, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3314, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3315, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3315, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3315, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3316, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3316, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3316, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3317, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3317, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3317, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3318, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3318, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3318, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3319, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3319, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3319, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3320, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3320, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3320, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3321, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3321, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3321, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3322, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3322, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3322, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3323, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3323, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3323, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3324, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3324, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3324, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3325, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3325, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3325, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3326, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3326, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3326, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3327, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3327, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3327, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3328, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3328, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3328, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3329, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3329, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3329, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3330, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3330, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3330, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3331, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3331, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3331, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3332, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3332, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3332, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3333, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3333, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3333, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3334, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3334, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3334, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3335, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3335, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3335, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3336, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3336, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3336, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3337, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3337, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3337, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3338, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3338, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3338, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3339, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3339, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3339, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3340, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3340, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3340, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3341, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3341, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3341, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3342, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3342, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3342, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3343, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3343, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3343, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3344, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3344, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3344, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3345, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3345, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3345, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3346, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3346, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3346, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3347, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3347, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3347, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3348, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3348, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3348, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3349, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3349, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3349, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3350, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3350, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3350, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3351, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3351, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3351, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3352, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3352, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3352, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3353, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3353, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3353, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3354, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3354, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3354, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3355, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3355, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3355, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3356, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3356, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3356, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3357, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3357, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3357, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3358, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3358, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3358, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3359, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3359, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3359, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3360, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3360, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3360, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3361, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3361, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3361, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3362, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3362, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3362, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3363, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3363, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3363, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3364, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3364, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3364, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3365, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3365, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3365, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3366, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3366, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3366, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3367, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3367, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3367, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3368, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3368, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3368, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3369, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3369, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3369, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3370, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3370, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3370, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3371, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3371, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3371, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3372, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3372, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3372, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3373, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3373, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3373, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3374, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3374, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3374, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3375, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3375, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3375, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3376, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3376, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3376, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3377, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3377, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3377, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3378, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3378, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3378, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3379, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3379, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3379, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3380, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3380, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3380, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3381, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3381, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3381, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3382, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3382, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3382, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3383, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3383, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3383, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3384, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3384, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3384, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3385, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3385, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3385, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3386, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3386, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3386, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3387, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3387, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3387, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3388, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3388, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3388, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3389, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3389, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3389, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3390, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3390, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3390, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3391, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3391, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3391, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3392, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3392, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3392, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3393, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3393, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3393, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3394, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3394, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3394, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3395, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3395, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3395, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3396, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3396, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3396, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3397, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3397, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3397, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3398, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3398, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3398, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3399, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3399, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3399, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3400, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3400, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3400, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3401, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3401, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3401, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3402, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3402, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3402, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3403, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3403, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3403, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3404, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3404, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3404, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3405, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3405, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3405, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3406, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3406, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3406, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3407, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3407, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3407, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3408, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3408, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3408, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3409, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3409, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3409, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3410, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3410, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3410, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3411, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3411, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3411, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3412, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3412, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3412, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3413, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3413, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3413, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3414, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3414, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3414, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3415, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3415, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3415, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3416, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3416, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3416, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3417, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3417, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3417, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3418, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3418, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3418, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3419, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3419, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3419, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3420, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3420, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3420, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3421, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3421, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3421, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3422, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3422, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3422, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3423, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3423, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3423, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3424, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3424, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3424, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3425, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3425, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3425, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3426, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3426, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3426, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3427, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3427, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3427, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3428, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3428, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3428, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3429, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3429, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3429, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3430, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3430, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3430, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3431, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3431, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3431, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3432, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3432, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3432, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3433, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3433, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3433, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3434, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3434, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3434, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3435, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3435, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3435, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3436, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3436, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3436, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3437, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3437, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3437, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3438, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3438, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3438, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3439, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3439, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3439, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3440, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3440, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3440, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3441, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3441, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3441, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3442, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3442, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3442, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3443, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3443, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3443, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3444, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3444, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3444, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3445, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3445, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3445, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3446, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3446, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3446, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3447, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3447, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3447, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3448, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3448, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3448, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3449, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3449, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3449, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3450, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3450, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3450, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3451, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3451, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3451, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3452, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3452, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3452, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3453, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3453, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3453, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3454, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3454, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3454, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3455, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3455, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3455, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3456, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3456, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3456, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3457, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3457, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3457, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3458, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3458, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3458, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3459, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3459, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3459, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3460, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3460, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3460, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3461, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3461, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3461, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3462, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3462, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3462, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3463, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3463, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3463, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3464, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3464, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3464, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3465, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3465, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3465, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3466, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3466, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3466, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3467, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3467, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3467, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3468, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3468, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3468, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3469, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3469, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3469, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3470, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3470, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3470, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3471, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3471, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3471, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3472, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3472, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3472, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3473, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3473, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3473, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3474, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3474, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3474, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3475, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3475, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3475, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3476, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3476, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3476, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3477, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3477, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3477, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3478, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3478, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3478, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3479, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3479, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3479, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3480, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3480, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3480, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3481, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3481, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3481, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3482, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3482, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3482, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3483, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3483, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3483, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3484, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3484, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3484, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3485, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3485, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3485, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3486, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3486, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3486, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3487, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3487, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3487, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3488, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3488, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3488, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3489, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3489, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3489, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3490, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3490, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3490, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3491, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3491, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3491, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3492, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3492, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3492, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3493, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3493, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3493, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3494, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3494, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3494, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3495, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3495, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3495, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3496, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3496, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3496, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3497, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3497, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3497, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3498, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3498, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3498, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3499, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3499, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3499, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3500, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3500, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3500, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3501, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3501, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3501, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3502, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3502, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3502, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3503, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3503, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3503, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3504, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3504, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3504, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3505, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3505, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3505, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3506, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3506, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3506, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3507, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3507, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3507, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3508, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3508, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3508, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3509, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3509, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3509, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3510, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3510, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3510, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3511, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3511, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3511, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3512, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3512, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3512, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3513, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3513, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3513, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3514, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3514, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3514, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3515, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3515, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3515, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3516, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3516, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3516, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3517, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3517, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3517, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3518, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3518, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3518, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3519, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3519, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3519, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3520, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3520, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3520, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3521, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3521, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3521, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3522, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3522, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3522, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3523, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3523, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3523, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3524, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3524, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3524, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3525, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3525, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3525, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3526, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3526, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3526, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3527, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3527, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3527, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3528, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3528, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3528, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3529, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3529, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3529, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3530, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3530, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3530, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3531, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3531, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3531, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3532, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3532, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3532, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3533, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3533, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3533, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3534, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3534, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3534, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3535, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3535, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3535, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3536, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3536, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3536, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3537, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3537, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3537, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3538, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3538, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3538, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3539, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3539, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3539, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3540, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3540, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3540, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3541, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3541, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3541, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3542, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3542, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3542, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3543, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3543, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3543, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3544, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3544, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3544, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3545, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3545, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3545, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3546, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3546, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3546, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3547, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3547, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3547, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3548, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3548, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3548, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3549, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3549, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3549, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3550, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3550, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3550, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3551, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3551, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3551, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3552, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3552, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3552, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3553, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3553, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3553, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3554, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3554, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3554, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3555, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3555, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3555, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3556, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3556, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3556, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3557, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3557, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3557, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3558, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3558, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3558, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3559, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3559, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3559, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3560, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3560, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3560, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3561, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3561, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3561, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3562, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3562, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3562, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3563, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3563, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3563, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3564, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3564, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3564, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3565, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3565, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3565, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3566, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3566, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3566, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3567, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3567, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3567, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3568, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3568, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3568, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3569, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3569, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3569, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3570, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3570, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3570, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3571, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3571, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3571, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3572, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3572, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3572, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3573, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3573, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3573, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3574, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3574, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3574, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3575, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3575, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3575, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3576, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3576, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3576, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3577, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3577, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3577, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3578, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3578, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3578, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3579, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3579, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3579, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3580, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3580, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3580, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3581, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3581, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3581, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3582, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3582, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3582, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3583, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3583, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3583, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3584, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3584, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3584, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3585, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3585, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3585, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3586, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3586, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3586, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3587, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3587, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3587, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3588, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3588, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3588, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3589, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3589, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3589, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3590, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3590, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3590, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3591, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3591, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3591, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3592, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3592, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3592, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3593, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3593, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3593, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3594, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3594, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3594, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3595, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3595, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3595, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3596, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3596, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3596, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3597, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3597, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3597, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3598, Training Loss: 0.04, Training Accuracy: 0.96\n",
            "Epoch: 3598, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3598, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3599, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3599, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3599, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3600, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3600, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3600, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3601, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3601, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3601, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3602, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3602, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3602, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3603, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3603, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3603, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3604, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3604, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3604, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3605, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3605, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3605, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3606, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3606, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3606, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3607, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3607, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3607, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3608, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3608, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3608, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3609, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3609, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3609, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3610, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3610, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3610, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3611, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3611, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3611, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3612, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3612, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3612, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3613, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3613, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3613, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3614, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3614, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3614, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3615, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3615, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3615, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3616, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3616, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3616, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3617, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3617, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3617, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3618, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3618, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3618, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3619, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3619, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3619, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3620, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3620, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3620, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3621, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3621, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3621, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3622, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3622, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3622, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3623, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3623, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3623, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3624, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3624, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3624, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3625, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3625, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3625, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3626, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3626, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3626, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3627, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3627, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3627, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3628, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3628, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3628, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3629, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3629, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3629, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3630, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3630, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3630, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3631, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3631, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3631, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3632, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3632, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3632, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3633, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3633, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3633, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3634, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3634, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3634, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3635, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3635, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3635, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3636, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3636, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3636, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3637, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3637, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3637, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3638, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3638, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3638, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3639, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3639, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3639, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3640, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3640, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3640, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3641, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3641, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3641, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3642, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3642, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3642, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3643, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3643, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3643, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3644, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3644, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3644, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3645, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3645, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3645, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3646, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3646, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3646, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3647, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3647, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3647, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3648, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3648, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3648, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3649, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3649, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3649, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3650, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3650, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3650, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3651, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3651, Validation Loss: 0.04, Validation Accuracy: 0.96\n",
            "Epoch: 3651, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3652, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3652, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3652, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3653, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3653, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3653, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3654, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3654, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3654, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3655, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3655, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3655, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3656, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3656, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3656, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3657, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3657, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3657, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3658, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3658, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3658, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3659, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3659, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3659, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3660, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3660, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3660, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3661, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3661, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3661, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3662, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3662, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3662, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3663, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3663, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3663, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3664, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3664, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3664, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3665, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3665, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3665, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3666, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3666, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3666, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3667, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3667, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3667, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3668, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3668, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3668, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3669, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3669, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3669, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3670, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3670, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3670, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3671, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3671, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3671, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3672, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3672, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3672, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3673, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3673, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3673, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3674, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3674, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3674, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3675, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3675, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3675, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3676, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3676, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3676, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3677, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3677, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3677, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3678, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3678, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3678, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3679, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3679, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3679, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3680, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3680, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3680, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3681, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3681, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3681, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3682, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3682, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3682, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3683, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3683, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3683, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3684, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3684, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3684, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3685, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3685, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3685, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3686, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3686, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3686, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3687, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3687, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3687, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3688, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3688, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3688, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3689, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3689, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3689, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3690, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3690, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3690, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3691, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3691, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3691, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3692, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3692, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3692, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3693, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3693, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3693, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3694, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3694, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3694, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3695, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3695, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3695, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3696, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3696, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3696, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3697, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3697, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3697, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3698, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3698, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3698, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3699, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3699, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3699, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3700, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3700, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3700, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3701, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3701, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3701, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3702, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3702, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3702, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3703, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3703, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3703, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3704, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3704, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3704, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3705, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3705, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3705, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3706, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3706, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3706, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3707, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3707, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3707, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3708, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3708, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3708, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3709, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3709, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3709, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3710, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3710, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3710, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3711, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3711, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3711, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3712, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3712, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3712, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3713, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3713, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3713, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3714, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3714, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3714, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3715, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3715, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3715, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3716, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3716, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3716, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3717, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3717, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3717, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3718, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3718, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3718, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3719, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3719, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3719, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3720, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3720, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3720, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3721, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3721, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3721, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3722, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3722, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3722, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3723, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3723, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3723, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3724, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3724, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3724, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3725, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3725, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3725, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3726, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3726, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3726, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3727, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3727, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3727, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3728, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3728, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3728, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3729, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3729, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3729, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3730, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3730, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3730, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3731, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3731, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3731, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3732, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3732, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3732, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3733, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3733, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3733, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3734, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3734, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3734, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3735, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3735, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3735, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3736, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3736, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3736, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3737, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3737, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3737, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3738, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3738, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3738, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3739, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3739, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3739, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3740, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3740, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3740, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3741, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3741, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3741, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3742, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3742, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3742, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3743, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3743, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3743, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3744, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3744, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3744, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3745, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3745, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3745, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3746, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3746, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3746, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3747, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3747, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3747, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3748, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3748, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3748, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3749, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3749, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3749, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3750, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3750, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3750, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3751, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3751, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3751, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3752, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3752, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3752, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3753, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3753, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3753, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3754, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3754, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3754, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3755, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3755, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3755, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3756, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3756, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3756, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3757, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3757, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3757, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3758, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3758, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3758, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3759, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3759, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3759, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3760, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3760, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3760, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3761, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3761, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3761, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3762, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3762, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3762, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3763, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3763, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3763, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3764, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3764, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3764, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3765, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3765, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3765, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3766, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3766, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3766, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3767, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3767, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3767, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3768, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3768, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3768, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3769, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3769, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3769, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3770, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3770, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3770, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3771, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3771, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3771, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3772, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3772, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3772, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3773, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3773, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3773, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3774, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3774, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3774, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3775, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3775, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3775, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3776, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3776, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3776, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3777, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3777, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3777, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3778, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3778, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3778, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3779, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3779, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3779, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3780, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3780, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3780, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3781, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3781, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3781, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3782, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3782, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3782, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3783, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3783, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3783, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3784, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3784, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3784, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3785, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3785, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3785, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3786, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3786, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3786, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3787, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3787, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3787, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3788, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3788, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3788, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3789, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3789, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3789, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3790, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3790, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3790, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3791, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3791, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3791, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3792, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3792, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3792, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3793, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3793, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3793, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3794, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3794, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3794, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3795, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3795, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3795, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3796, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3796, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3796, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3797, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3797, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3797, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3798, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3798, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3798, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3799, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3799, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3799, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3800, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3800, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3800, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3801, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3801, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3801, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3802, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3802, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3802, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3803, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3803, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3803, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3804, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3804, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3804, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3805, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3805, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3805, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3806, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3806, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3806, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3807, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3807, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3807, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3808, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3808, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3808, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3809, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3809, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3809, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3810, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3810, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3810, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3811, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3811, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3811, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3812, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3812, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3812, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3813, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3813, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3813, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3814, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3814, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3814, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3815, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3815, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3815, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3816, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3816, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3816, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3817, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3817, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3817, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3818, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3818, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3818, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3819, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3819, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3819, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3820, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3820, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3820, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3821, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3821, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3821, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3822, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3822, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3822, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3823, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3823, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3823, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3824, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3824, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3824, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3825, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3825, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3825, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3826, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3826, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3826, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3827, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3827, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3827, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3828, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3828, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3828, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3829, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3829, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3829, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3830, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3830, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3830, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3831, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3831, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3831, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3832, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3832, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3832, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3833, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3833, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3833, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3834, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3834, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3834, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3835, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3835, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3835, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3836, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3836, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3836, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3837, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3837, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3837, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3838, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3838, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3838, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3839, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3839, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3839, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3840, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3840, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3840, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3841, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3841, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3841, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3842, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3842, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3842, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3843, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3843, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3843, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3844, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3844, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3844, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3845, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3845, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3845, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3846, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3846, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3846, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3847, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3847, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3847, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3848, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3848, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3848, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3849, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3849, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3849, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3850, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3850, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3850, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3851, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3851, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3851, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3852, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3852, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3852, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3853, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3853, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3853, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3854, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3854, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3854, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3855, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3855, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3855, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3856, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3856, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3856, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3857, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3857, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3857, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3858, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3858, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3858, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3859, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3859, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3859, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3860, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3860, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3860, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3861, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3861, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3861, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3862, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3862, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3862, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3863, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3863, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3863, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3864, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3864, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3864, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3865, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3865, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3865, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3866, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3866, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3866, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3867, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3867, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3867, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3868, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3868, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3868, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3869, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3869, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3869, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3870, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3870, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3870, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3871, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3871, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3871, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3872, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3872, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3872, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3873, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3873, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3873, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3874, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3874, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3874, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3875, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3875, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3875, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3876, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3876, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3876, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3877, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3877, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3877, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3878, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3878, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3878, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3879, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3879, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3879, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3880, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3880, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3880, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3881, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3881, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3881, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3882, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3882, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3882, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3883, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3883, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3883, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3884, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3884, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3884, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3885, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3885, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3885, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3886, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3886, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3886, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3887, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3887, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3887, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3888, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3888, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3888, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3889, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3889, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3889, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3890, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3890, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3890, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3891, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3891, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3891, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3892, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3892, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3892, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3893, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3893, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3893, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3894, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3894, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3894, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3895, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3895, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3895, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3896, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3896, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3896, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3897, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3897, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3897, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3898, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3898, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3898, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3899, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3899, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3899, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3900, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3900, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3900, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3901, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3901, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3901, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3902, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3902, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3902, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3903, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3903, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3903, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3904, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3904, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3904, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3905, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3905, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3905, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3906, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3906, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3906, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3907, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3907, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3907, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3908, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3908, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3908, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3909, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3909, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3909, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3910, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3910, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3910, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3911, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3911, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3911, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3912, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3912, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3912, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3913, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3913, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3913, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3914, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3914, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3914, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3915, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3915, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3915, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3916, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3916, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3916, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3917, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3917, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3917, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3918, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3918, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3918, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3919, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3919, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3919, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3920, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3920, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3920, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3921, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3921, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3921, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3922, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3922, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3922, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3923, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3923, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3923, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3924, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3924, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3924, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3925, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3925, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3925, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3926, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3926, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3926, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3927, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3927, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3927, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3928, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3928, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3928, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3929, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3929, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3929, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3930, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3930, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3930, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3931, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3931, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3931, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3932, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3932, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3932, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3933, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3933, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3933, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3934, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3934, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3934, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3935, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3935, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3935, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3936, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3936, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3936, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3937, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3937, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3937, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3938, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3938, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3938, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3939, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3939, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3939, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3940, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3940, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3940, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3941, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3941, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3941, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3942, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3942, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3942, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3943, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3943, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3943, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3944, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3944, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3944, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3945, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3945, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3945, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3946, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3946, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3946, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3947, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3947, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3947, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3948, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3948, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3948, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3949, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3949, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3949, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3950, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3950, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3950, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3951, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3951, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3951, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3952, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3952, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3952, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3953, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3953, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3953, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3954, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3954, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3954, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3955, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3955, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3955, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3956, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3956, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3956, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3957, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3957, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3957, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3958, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3958, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3958, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3959, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3959, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3959, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3960, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3960, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3960, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3961, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3961, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3961, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3962, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3962, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3962, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3963, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3963, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3963, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3964, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3964, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3964, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3965, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3965, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3965, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3966, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3966, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3966, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3967, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3967, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3967, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3968, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3968, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3968, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3969, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3969, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3969, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3970, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3970, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3970, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3971, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3971, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3971, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3972, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3972, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3972, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3973, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3973, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3973, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3974, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3974, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3974, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3975, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3975, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3975, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3976, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3976, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3976, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3977, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3977, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3977, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3978, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3978, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3978, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3979, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3979, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3979, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3980, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3980, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3980, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3981, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3981, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3981, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3982, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3982, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3982, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3983, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3983, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3983, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3984, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3984, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3984, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3985, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3985, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3985, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3986, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3986, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3986, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3987, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3987, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3987, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3988, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3988, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3988, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3989, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3989, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3989, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3990, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3990, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3990, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3991, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3991, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3991, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3992, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3992, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3992, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3993, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3993, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3993, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3994, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3994, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3994, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3995, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3995, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3995, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3996, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3996, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3996, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3997, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3997, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3997, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3998, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3998, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3998, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 3999, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 3999, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 3999, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4000, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4000, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4000, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4001, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4001, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4001, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4002, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4002, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4002, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4003, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4003, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4003, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4004, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4004, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4004, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4005, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4005, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4005, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4006, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4006, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4006, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4007, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4007, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4007, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4008, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4008, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4008, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4009, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4009, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4009, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4010, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4010, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4010, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4011, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4011, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4011, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4012, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4012, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4012, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4013, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4013, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4013, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4014, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4014, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4014, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4015, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4015, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4015, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4016, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4016, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4016, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4017, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4017, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4017, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4018, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4018, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4018, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4019, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4019, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4019, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4020, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4020, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4020, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4021, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4021, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4021, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4022, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4022, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4022, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4023, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4023, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4023, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4024, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4024, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4024, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4025, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4025, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4025, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4026, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4026, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4026, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4027, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4027, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4027, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4028, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4028, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4028, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4029, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4029, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4029, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4030, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4030, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4030, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4031, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4031, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4031, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4032, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4032, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4032, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4033, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4033, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4033, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4034, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4034, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4034, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4035, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4035, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4035, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4036, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4036, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4036, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4037, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4037, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4037, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4038, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4038, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4038, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4039, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4039, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4039, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4040, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4040, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4040, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4041, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4041, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4041, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4042, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4042, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4042, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4043, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4043, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4043, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4044, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4044, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4044, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4045, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4045, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4045, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4046, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4046, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4046, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4047, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4047, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4047, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4048, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4048, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4048, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4049, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4049, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4049, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4050, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4050, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4050, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4051, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4051, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4051, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4052, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4052, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4052, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4053, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4053, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4053, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4054, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4054, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4054, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4055, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4055, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4055, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4056, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4056, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4056, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4057, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4057, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4057, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4058, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4058, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4058, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4059, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4059, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4059, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4060, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4060, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4060, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4061, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4061, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4061, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4062, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4062, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4062, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4063, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4063, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4063, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4064, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4064, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4064, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4065, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4065, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4065, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4066, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4066, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4066, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4067, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4067, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4067, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4068, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4068, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4068, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4069, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4069, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4069, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4070, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4070, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4070, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4071, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4071, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4071, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4072, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4072, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4072, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4073, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4073, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4073, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4074, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4074, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4074, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4075, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4075, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4075, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4076, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4076, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4076, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4077, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4077, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4077, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4078, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4078, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4078, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4079, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4079, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4079, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4080, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4080, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4080, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4081, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4081, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4081, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4082, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4082, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4082, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4083, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4083, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4083, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4084, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4084, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4084, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4085, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4085, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4085, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4086, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4086, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4086, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4087, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4087, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4087, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4088, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4088, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4088, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4089, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4089, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4089, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4090, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4090, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4090, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4091, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4091, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4091, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4092, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4092, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4092, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4093, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4093, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4093, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4094, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4094, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4094, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4095, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4095, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4095, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4096, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4096, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4096, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4097, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4097, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4097, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4098, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4098, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4098, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4099, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4099, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4099, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4100, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4100, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4100, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4101, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4101, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4101, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4102, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4102, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4102, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4103, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4103, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4103, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4104, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4104, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4104, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4105, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4105, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4105, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4106, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4106, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4106, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4107, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4107, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4107, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4108, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4108, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4108, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4109, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4109, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4109, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4110, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4110, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4110, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4111, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4111, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4111, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4112, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4112, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4112, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4113, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4113, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4113, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4114, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4114, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4114, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4115, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4115, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4115, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4116, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4116, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4116, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4117, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4117, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4117, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4118, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4118, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4118, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4119, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4119, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4119, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4120, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4120, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4120, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4121, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4121, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4121, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4122, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4122, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4122, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4123, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4123, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4123, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4124, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4124, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4124, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4125, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4125, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4125, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4126, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4126, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4126, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4127, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4127, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4127, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4128, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4128, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4128, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4129, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4129, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4129, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4130, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4130, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4130, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4131, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4131, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4131, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4132, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4132, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4132, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4133, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4133, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4133, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4134, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4134, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4134, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4135, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4135, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4135, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4136, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4136, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4136, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4137, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4137, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4137, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4138, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4138, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4138, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4139, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4139, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4139, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4140, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4140, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4140, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4141, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4141, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4141, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4142, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4142, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4142, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4143, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4143, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4143, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4144, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4144, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4144, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4145, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4145, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4145, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4146, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4146, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4146, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4147, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4147, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4147, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4148, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4148, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4148, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4149, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4149, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4149, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4150, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4150, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4150, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4151, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4151, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4151, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4152, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4152, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4152, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4153, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4153, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4153, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4154, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4154, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4154, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4155, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4155, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4155, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4156, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4156, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4156, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4157, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4157, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4157, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4158, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4158, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4158, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4159, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4159, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4159, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4160, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4160, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4160, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4161, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4161, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4161, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4162, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4162, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4162, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4163, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4163, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4163, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4164, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4164, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4164, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4165, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4165, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4165, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4166, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4166, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4166, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4167, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4167, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4167, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4168, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4168, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4168, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4169, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4169, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4169, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4170, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4170, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4170, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4171, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4171, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4171, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4172, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4172, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4172, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4173, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4173, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4173, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4174, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4174, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4174, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4175, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4175, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4175, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4176, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4176, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4176, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4177, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4177, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4177, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4178, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4178, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4178, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4179, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4179, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4179, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4180, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4180, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4180, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4181, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4181, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4181, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4182, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4182, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4182, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4183, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4183, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4183, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4184, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4184, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4184, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4185, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4185, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4185, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4186, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4186, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4186, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4187, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4187, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4187, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4188, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4188, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4188, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4189, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4189, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4189, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4190, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4190, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4190, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4191, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4191, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4191, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4192, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4192, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4192, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4193, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4193, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4193, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4194, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4194, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4194, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4195, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4195, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4195, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4196, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4196, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4196, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4197, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4197, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4197, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4198, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4198, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4198, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4199, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4199, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4199, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4200, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4200, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4200, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4201, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4201, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4201, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4202, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4202, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4202, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4203, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4203, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4203, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4204, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4204, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4204, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4205, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4205, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4205, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4206, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4206, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4206, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4207, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4207, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4207, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4208, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4208, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4208, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4209, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4209, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4209, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4210, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4210, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4210, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4211, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4211, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4211, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4212, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4212, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4212, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4213, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4213, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4213, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4214, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4214, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4214, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4215, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4215, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4215, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4216, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4216, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4216, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4217, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4217, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4217, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4218, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4218, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4218, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4219, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4219, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4219, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4220, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4220, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4220, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4221, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4221, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4221, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4222, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4222, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4222, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4223, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4223, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4223, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4224, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4224, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4224, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4225, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4225, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4225, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4226, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4226, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4226, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4227, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4227, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4227, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4228, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4228, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4228, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4229, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4229, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4229, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4230, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4230, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4230, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4231, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4231, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4231, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4232, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4232, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4232, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4233, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4233, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4233, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4234, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4234, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4234, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4235, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4235, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4235, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4236, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4236, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4236, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4237, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4237, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4237, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4238, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4238, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4238, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4239, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4239, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4239, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4240, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4240, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4240, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4241, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4241, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4241, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4242, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4242, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4242, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4243, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4243, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4243, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4244, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4244, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4244, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4245, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4245, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4245, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4246, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4246, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4246, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4247, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4247, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4247, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4248, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4248, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4248, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4249, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4249, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4249, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4250, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4250, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4250, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4251, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4251, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4251, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4252, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4252, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4252, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4253, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4253, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4253, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4254, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4254, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4254, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4255, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4255, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4255, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4256, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4256, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4256, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4257, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4257, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4257, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4258, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4258, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4258, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4259, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4259, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4259, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4260, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4260, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4260, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4261, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4261, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4261, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4262, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4262, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4262, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4263, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4263, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4263, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4264, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4264, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4264, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4265, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4265, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4265, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4266, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4266, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4266, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4267, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4267, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4267, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4268, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4268, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4268, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4269, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4269, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4269, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4270, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4270, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4270, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4271, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4271, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4271, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4272, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4272, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4272, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4273, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4273, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4273, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4274, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4274, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4274, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4275, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4275, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4275, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4276, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4276, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4276, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4277, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4277, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4277, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4278, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4278, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4278, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4279, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4279, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4279, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4280, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4280, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4280, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4281, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4281, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4281, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4282, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4282, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4282, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4283, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4283, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4283, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4284, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4284, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4284, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4285, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4285, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4285, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4286, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4286, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4286, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4287, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4287, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4287, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4288, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4288, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4288, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4289, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4289, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4289, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4290, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4290, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4290, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4291, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4291, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4291, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4292, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4292, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4292, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4293, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4293, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4293, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4294, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4294, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4294, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4295, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4295, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4295, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4296, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4296, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4296, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4297, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4297, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4297, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4298, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4298, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4298, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4299, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4299, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4299, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4300, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4300, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4300, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4301, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4301, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4301, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4302, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4302, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4302, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4303, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4303, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4303, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4304, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4304, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4304, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4305, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4305, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4305, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4306, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4306, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4306, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4307, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4307, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4307, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4308, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4308, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4308, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4309, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4309, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4309, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4310, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4310, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4310, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4311, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4311, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4311, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4312, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4312, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4312, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4313, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4313, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4313, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4314, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4314, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4314, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4315, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4315, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4315, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4316, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4316, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4316, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4317, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4317, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4317, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4318, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4318, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4318, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4319, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4319, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4319, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4320, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4320, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4320, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4321, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4321, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4321, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4322, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4322, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4322, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4323, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4323, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4323, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4324, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4324, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4324, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4325, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4325, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4325, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4326, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4326, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4326, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4327, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4327, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4327, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4328, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4328, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4328, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4329, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4329, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4329, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4330, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4330, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4330, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4331, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4331, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4331, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4332, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4332, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4332, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4333, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4333, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4333, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4334, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4334, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4334, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4335, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4335, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4335, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4336, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4336, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4336, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4337, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4337, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4337, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4338, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4338, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4338, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4339, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4339, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4339, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4340, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4340, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4340, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4341, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4341, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4341, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4342, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4342, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4342, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4343, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4343, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4343, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4344, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4344, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4344, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4345, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4345, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4345, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4346, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4346, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4346, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4347, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4347, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4347, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4348, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4348, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4348, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4349, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4349, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4349, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4350, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4350, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4350, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4351, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4351, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4351, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4352, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4352, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4352, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4353, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4353, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4353, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4354, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4354, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4354, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4355, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4355, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4355, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4356, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4356, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4356, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4357, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4357, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4357, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4358, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4358, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4358, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4359, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4359, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4359, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4360, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4360, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4360, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4361, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4361, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4361, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4362, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4362, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4362, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4363, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4363, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4363, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4364, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4364, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4364, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4365, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4365, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4365, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4366, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4366, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4366, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4367, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4367, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4367, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4368, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4368, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4368, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4369, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4369, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4369, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4370, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4370, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4370, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4371, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4371, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4371, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4372, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4372, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4372, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4373, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4373, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4373, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4374, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4374, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4374, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4375, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4375, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4375, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4376, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4376, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4376, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4377, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4377, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4377, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4378, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4378, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4378, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4379, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4379, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4379, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4380, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4380, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4380, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4381, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4381, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4381, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4382, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4382, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4382, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4383, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4383, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4383, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4384, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4384, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4384, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4385, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4385, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4385, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4386, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4386, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4386, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4387, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4387, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4387, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4388, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4388, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4388, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4389, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4389, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4389, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4390, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4390, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4390, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4391, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4391, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4391, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4392, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4392, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4392, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4393, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4393, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4393, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4394, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4394, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4394, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4395, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4395, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4395, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4396, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4396, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4396, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4397, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4397, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4397, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4398, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4398, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4398, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4399, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4399, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4399, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4400, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4400, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4400, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4401, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4401, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4401, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4402, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4402, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4402, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4403, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4403, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4403, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4404, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4404, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4404, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4405, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4405, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4405, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4406, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4406, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4406, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4407, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4407, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4407, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4408, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4408, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4408, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4409, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4409, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4409, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4410, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4410, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4410, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4411, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4411, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4411, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4412, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4412, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4412, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4413, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4413, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4413, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4414, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4414, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4414, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4415, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4415, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4415, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4416, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4416, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4416, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4417, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4417, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4417, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4418, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4418, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4418, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4419, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4419, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4419, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4420, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4420, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4420, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4421, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4421, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4421, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4422, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4422, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4422, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4423, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4423, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4423, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4424, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4424, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4424, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4425, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4425, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4425, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4426, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4426, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4426, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4427, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4427, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4427, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4428, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4428, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4428, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4429, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4429, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4429, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4430, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4430, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4430, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4431, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4431, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4431, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4432, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4432, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4432, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4433, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4433, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4433, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4434, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4434, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4434, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4435, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4435, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4435, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4436, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4436, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4436, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4437, Training Loss: 0.03, Training Accuracy: 0.96\n",
            "Epoch: 4437, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4437, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4438, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4438, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4438, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4439, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4439, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4439, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4440, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4440, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4440, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4441, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4441, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4441, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4442, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4442, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4442, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4443, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4443, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4443, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4444, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4444, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4444, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4445, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4445, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4445, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4446, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4446, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4446, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4447, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4447, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4447, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4448, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4448, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4448, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4449, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4449, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4449, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4450, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4450, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4450, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4451, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4451, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4451, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4452, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4452, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4452, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4453, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4453, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4453, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4454, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4454, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4454, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4455, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4455, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4455, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4456, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4456, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4456, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4457, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4457, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4457, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4458, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4458, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4458, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4459, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4459, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4459, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4460, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4460, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4460, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4461, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4461, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4461, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4462, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4462, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4462, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4463, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4463, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4463, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4464, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4464, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4464, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4465, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4465, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4465, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4466, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4466, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4466, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4467, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4467, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4467, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4468, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4468, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4468, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4469, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4469, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4469, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4470, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4470, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4470, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4471, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4471, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4471, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4472, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4472, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4472, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4473, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4473, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4473, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4474, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4474, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4474, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4475, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4475, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4475, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4476, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4476, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4476, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4477, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4477, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4477, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4478, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4478, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4478, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4479, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4479, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4479, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4480, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4480, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4480, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4481, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4481, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4481, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4482, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4482, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4482, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4483, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4483, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4483, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4484, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4484, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4484, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4485, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4485, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4485, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4486, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4486, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4486, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4487, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4487, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4487, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4488, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4488, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4488, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4489, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4489, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4489, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4490, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4490, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4490, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4491, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4491, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4491, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4492, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4492, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4492, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4493, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4493, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4493, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4494, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4494, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4494, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4495, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4495, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4495, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4496, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4496, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4496, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4497, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4497, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4497, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4498, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4498, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4498, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4499, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4499, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4499, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4500, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4500, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4500, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4501, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4501, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4501, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4502, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4502, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4502, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4503, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4503, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4503, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4504, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4504, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4504, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4505, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4505, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4505, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4506, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4506, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4506, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4507, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4507, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4507, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4508, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4508, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4508, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4509, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4509, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4509, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4510, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4510, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4510, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4511, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4511, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4511, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4512, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4512, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4512, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4513, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4513, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4513, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4514, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4514, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4514, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4515, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4515, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4515, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4516, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4516, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4516, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4517, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4517, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4517, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4518, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4518, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4518, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4519, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4519, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4519, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4520, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4520, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4520, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4521, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4521, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4521, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4522, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4522, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4522, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4523, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4523, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4523, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4524, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4524, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4524, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4525, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4525, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4525, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4526, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4526, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4526, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4527, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4527, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4527, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4528, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4528, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4528, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4529, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4529, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4529, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4530, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4530, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4530, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4531, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4531, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4531, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4532, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4532, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4532, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4533, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4533, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4533, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4534, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4534, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4534, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4535, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4535, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4535, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4536, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4536, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4536, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4537, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4537, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4537, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4538, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4538, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4538, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4539, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4539, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4539, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4540, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4540, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4540, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4541, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4541, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4541, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4542, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4542, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4542, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4543, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4543, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4543, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4544, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4544, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4544, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4545, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4545, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4545, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4546, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4546, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4546, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4547, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4547, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4547, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4548, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4548, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4548, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4549, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4549, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4549, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4550, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4550, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4550, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4551, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4551, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4551, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4552, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4552, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4552, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4553, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4553, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4553, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4554, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4554, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4554, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4555, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4555, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4555, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4556, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4556, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4556, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4557, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4557, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4557, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4558, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4558, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4558, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4559, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4559, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4559, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4560, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4560, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4560, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4561, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4561, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4561, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4562, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4562, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4562, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4563, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4563, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4563, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4564, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4564, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4564, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4565, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4565, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4565, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4566, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4566, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4566, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4567, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4567, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4567, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4568, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4568, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4568, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4569, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4569, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4569, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4570, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4570, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4570, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4571, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4571, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4571, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4572, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4572, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4572, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4573, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4573, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4573, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4574, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4574, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4574, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4575, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4575, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4575, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4576, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4576, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4576, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4577, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4577, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4577, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4578, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4578, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4578, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4579, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4579, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4579, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4580, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4580, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4580, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4581, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4581, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4581, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4582, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4582, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4582, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4583, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4583, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4583, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4584, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4584, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4584, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4585, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4585, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4585, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4586, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4586, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4586, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4587, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4587, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4587, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4588, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4588, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4588, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4589, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4589, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4589, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4590, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4590, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4590, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4591, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4591, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4591, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4592, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4592, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4592, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4593, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4593, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4593, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4594, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4594, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4594, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4595, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4595, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4595, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4596, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4596, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4596, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4597, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4597, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4597, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4598, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4598, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4598, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4599, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4599, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4599, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4600, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4600, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4600, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4601, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4601, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4601, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4602, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4602, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4602, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4603, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4603, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4603, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4604, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4604, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4604, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4605, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4605, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4605, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4606, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4606, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4606, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4607, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4607, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4607, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4608, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4608, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4608, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4609, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4609, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4609, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4610, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4610, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4610, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4611, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4611, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4611, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4612, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4612, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4612, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4613, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4613, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4613, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4614, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4614, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4614, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4615, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4615, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4615, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4616, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4616, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4616, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4617, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4617, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4617, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4618, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4618, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4618, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4619, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4619, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4619, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4620, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4620, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4620, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4621, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4621, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4621, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4622, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4622, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4622, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4623, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4623, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4623, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4624, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4624, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4624, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4625, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4625, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4625, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4626, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4626, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4626, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4627, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4627, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4627, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4628, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4628, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4628, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4629, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4629, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4629, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4630, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4630, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4630, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4631, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4631, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4631, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4632, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4632, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4632, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4633, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4633, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4633, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4634, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4634, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4634, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4635, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4635, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4635, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4636, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4636, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4636, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4637, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4637, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4637, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4638, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4638, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4638, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4639, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4639, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4639, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4640, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4640, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4640, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4641, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4641, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4641, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4642, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4642, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4642, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4643, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4643, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4643, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4644, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4644, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4644, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4645, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4645, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4645, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4646, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4646, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4646, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4647, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4647, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4647, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4648, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4648, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4648, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4649, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4649, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4649, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4650, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4650, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4650, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4651, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4651, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4651, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4652, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4652, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4652, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4653, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4653, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4653, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4654, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4654, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4654, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4655, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4655, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4655, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4656, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4656, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4656, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4657, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4657, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4657, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4658, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4658, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4658, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4659, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4659, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4659, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4660, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4660, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4660, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4661, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4661, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4661, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4662, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4662, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4662, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4663, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4663, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4663, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4664, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4664, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4664, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4665, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4665, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4665, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4666, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4666, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4666, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4667, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4667, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4667, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4668, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4668, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4668, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4669, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4669, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4669, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4670, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4670, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4670, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4671, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4671, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4671, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4672, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4672, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4672, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4673, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4673, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4673, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4674, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4674, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4674, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4675, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4675, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4675, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4676, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4676, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4676, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4677, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4677, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4677, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4678, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4678, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4678, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4679, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4679, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4679, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4680, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4680, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4680, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4681, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4681, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4681, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4682, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4682, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4682, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4683, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4683, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4683, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4684, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4684, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4684, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4685, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4685, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4685, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4686, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4686, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4686, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4687, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4687, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4687, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4688, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4688, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4688, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4689, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4689, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4689, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4690, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4690, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4690, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4691, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4691, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4691, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4692, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4692, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4692, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4693, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4693, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4693, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4694, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4694, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4694, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4695, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4695, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4695, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4696, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4696, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4696, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4697, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4697, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4697, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4698, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4698, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4698, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4699, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4699, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4699, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4700, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4700, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4700, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4701, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4701, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4701, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4702, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4702, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4702, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4703, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4703, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4703, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4704, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4704, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4704, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4705, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4705, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4705, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4706, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4706, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4706, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4707, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4707, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4707, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4708, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4708, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4708, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4709, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4709, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4709, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4710, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4710, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4710, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4711, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4711, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4711, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4712, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4712, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4712, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4713, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4713, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4713, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4714, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4714, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4714, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4715, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4715, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4715, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4716, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4716, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4716, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4717, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4717, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4717, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4718, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4718, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4718, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4719, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4719, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4719, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4720, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4720, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4720, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4721, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4721, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4721, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4722, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4722, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4722, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4723, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4723, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4723, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4724, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4724, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4724, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4725, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4725, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4725, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4726, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4726, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4726, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4727, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4727, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4727, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4728, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4728, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4728, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4729, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4729, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4729, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4730, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4730, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4730, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4731, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4731, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4731, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4732, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4732, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4732, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4733, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4733, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4733, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4734, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4734, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4734, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4735, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4735, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4735, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4736, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4736, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4736, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4737, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4737, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4737, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4738, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4738, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4738, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4739, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4739, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4739, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4740, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4740, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4740, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4741, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4741, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4741, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4742, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4742, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4742, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4743, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4743, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4743, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4744, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4744, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4744, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4745, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4745, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4745, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4746, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4746, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4746, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4747, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4747, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4747, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4748, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4748, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4748, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4749, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4749, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4749, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4750, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4750, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4750, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4751, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4751, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4751, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4752, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4752, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4752, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4753, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4753, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4753, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4754, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4754, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4754, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4755, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4755, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4755, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4756, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4756, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4756, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4757, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4757, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4757, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4758, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4758, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4758, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4759, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4759, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4759, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4760, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4760, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4760, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4761, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4761, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4761, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4762, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4762, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4762, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4763, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4763, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4763, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4764, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4764, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4764, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4765, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4765, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4765, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4766, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4766, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4766, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4767, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4767, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4767, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4768, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4768, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4768, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4769, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4769, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4769, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4770, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4770, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4770, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4771, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4771, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4771, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4772, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4772, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4772, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4773, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4773, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4773, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4774, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4774, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4774, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4775, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4775, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4775, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4776, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4776, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4776, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4777, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4777, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4777, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4778, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4778, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4778, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4779, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4779, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4779, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4780, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4780, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4780, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4781, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4781, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4781, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4782, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4782, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4782, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4783, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4783, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4783, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4784, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4784, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4784, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4785, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4785, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4785, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4786, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4786, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4786, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4787, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4787, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4787, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4788, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4788, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4788, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4789, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4789, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4789, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4790, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4790, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4790, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4791, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4791, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4791, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4792, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4792, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4792, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4793, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4793, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4793, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4794, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4794, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4794, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4795, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4795, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4795, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4796, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4796, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4796, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4797, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4797, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4797, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4798, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4798, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4798, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4799, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4799, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4799, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4800, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4800, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4800, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4801, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4801, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4801, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4802, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4802, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4802, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4803, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4803, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4803, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4804, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4804, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4804, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4805, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4805, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4805, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4806, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4806, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4806, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4807, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4807, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4807, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4808, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4808, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4808, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4809, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4809, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4809, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4810, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4810, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4810, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4811, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4811, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4811, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4812, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4812, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4812, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4813, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4813, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4813, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4814, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4814, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4814, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4815, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4815, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4815, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4816, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4816, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4816, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4817, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4817, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4817, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4818, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4818, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4818, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4819, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4819, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4819, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4820, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4820, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4820, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4821, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4821, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4821, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4822, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4822, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4822, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4823, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4823, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4823, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4824, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4824, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4824, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4825, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4825, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4825, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4826, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4826, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4826, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4827, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4827, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4827, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4828, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4828, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4828, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4829, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4829, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4829, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4830, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4830, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4830, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4831, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4831, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4831, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4832, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4832, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4832, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4833, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4833, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4833, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4834, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4834, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4834, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4835, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4835, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4835, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4836, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4836, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4836, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4837, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4837, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4837, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4838, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4838, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4838, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4839, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4839, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4839, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4840, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4840, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4840, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4841, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4841, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4841, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4842, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4842, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4842, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4843, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4843, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4843, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4844, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4844, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4844, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4845, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4845, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4845, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4846, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4846, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4846, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4847, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4847, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4847, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4848, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4848, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4848, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4849, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4849, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4849, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4850, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4850, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4850, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4851, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4851, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4851, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4852, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4852, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4852, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4853, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4853, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4853, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4854, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4854, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4854, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4855, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4855, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4855, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4856, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4856, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4856, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4857, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4857, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4857, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4858, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4858, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4858, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4859, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4859, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4859, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4860, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4860, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4860, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4861, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4861, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4861, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4862, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4862, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4862, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4863, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4863, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4863, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4864, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4864, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4864, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4865, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4865, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4865, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4866, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4866, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4866, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4867, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4867, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4867, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4868, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4868, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4868, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4869, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4869, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4869, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4870, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4870, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4870, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4871, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4871, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4871, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4872, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4872, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4872, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4873, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4873, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4873, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4874, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4874, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4874, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4875, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4875, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4875, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4876, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4876, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4876, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4877, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4877, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4877, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4878, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4878, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4878, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4879, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4879, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4879, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4880, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4880, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4880, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4881, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4881, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4881, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4882, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4882, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4882, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4883, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4883, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4883, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4884, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4884, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4884, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4885, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4885, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4885, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4886, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4886, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4886, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4887, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4887, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4887, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4888, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4888, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4888, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4889, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4889, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4889, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4890, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4890, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4890, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4891, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4891, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4891, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4892, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4892, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4892, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4893, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4893, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4893, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4894, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4894, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4894, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4895, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4895, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4895, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4896, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4896, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4896, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4897, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4897, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4897, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4898, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4898, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4898, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4899, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4899, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4899, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4900, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4900, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4900, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4901, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4901, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4901, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4902, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4902, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4902, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4903, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4903, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4903, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4904, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4904, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4904, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4905, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4905, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4905, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4906, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4906, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4906, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4907, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4907, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4907, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4908, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4908, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4908, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4909, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4909, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4909, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4910, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4910, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4910, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4911, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4911, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4911, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4912, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4912, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4912, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4913, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4913, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4913, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4914, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4914, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4914, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4915, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4915, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4915, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4916, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4916, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4916, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4917, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4917, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4917, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4918, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4918, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4918, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4919, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4919, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4919, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4920, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4920, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4920, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4921, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4921, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4921, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4922, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4922, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4922, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4923, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4923, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4923, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4924, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4924, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4924, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4925, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4925, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4925, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4926, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4926, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4926, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4927, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4927, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4927, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4928, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4928, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4928, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4929, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4929, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4929, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4930, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4930, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4930, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4931, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4931, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4931, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4932, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4932, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4932, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4933, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4933, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4933, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4934, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4934, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4934, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4935, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4935, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4935, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4936, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4936, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4936, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4937, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4937, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4937, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4938, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4938, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4938, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4939, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4939, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4939, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4940, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4940, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4940, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4941, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4941, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4941, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4942, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4942, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4942, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4943, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4943, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4943, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4944, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4944, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4944, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4945, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4945, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4945, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4946, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4946, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4946, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4947, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4947, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4947, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4948, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4948, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4948, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4949, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4949, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4949, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4950, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4950, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4950, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4951, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4951, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4951, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4952, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4952, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4952, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4953, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4953, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4953, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4954, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4954, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4954, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4955, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4955, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4955, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4956, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4956, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4956, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4957, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4957, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4957, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4958, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4958, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4958, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4959, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4959, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4959, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4960, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4960, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4960, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4961, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4961, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4961, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4962, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4962, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4962, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4963, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4963, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4963, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4964, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4964, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4964, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4965, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4965, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4965, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4966, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4966, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4966, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4967, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4967, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4967, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4968, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4968, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4968, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4969, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4969, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4969, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4970, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4970, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4970, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4971, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4971, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4971, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4972, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4972, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4972, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4973, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4973, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4973, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4974, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4974, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4974, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4975, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4975, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4975, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4976, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4976, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4976, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4977, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4977, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4977, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4978, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4978, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4978, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4979, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4979, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4979, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4980, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4980, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4980, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4981, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4981, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4981, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4982, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4982, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4982, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4983, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4983, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4983, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4984, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4984, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4984, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4985, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4985, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4985, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4986, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4986, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4986, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4987, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4987, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4987, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4988, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4988, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4988, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4989, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4989, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4989, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4990, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4990, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4990, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4991, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4991, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4991, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4992, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4992, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4992, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4993, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4993, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4993, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4994, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4994, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4994, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4995, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4995, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4995, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4996, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4996, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4996, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4997, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4997, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4997, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4998, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4998, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4998, Testing Loss: 0.04, Testing Accuracy: 0.96\n",
            "Epoch: 4999, Training Loss: 0.03, Training Accuracy: 0.97\n",
            "Epoch: 4999, Validation Loss: 0.04, Validation Accuracy: 0.97\n",
            "Epoch: 4999, Testing Loss: 0.04, Testing Accuracy: 0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTVcEJ-PurfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotting_loss(epoch, training_error, validation_error, testing_error, title):\n",
        "    epoch_idx = np.arange(0, epoch)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.plot(epoch_idx,training_error)\n",
        "    plt.plot(epoch_idx,validation_error)\n",
        "    plt.plot(epoch_idx,testing_error)\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss', 'Testing Loss'])\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5JOCTA7t8Kp",
        "colab_type": "code",
        "outputId": "933078ad-77ca-4034-931f-eff79b24dc1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "plotting_loss(epochs, training_error[0], validation_error[0], testing_error[0],\"MSE Losses of BGD w/ lr of 0.005 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py:2832: RuntimeWarning: overflow encountered in double_scalars\n",
            "  elif vmax - vmin <= maxabsvalue * tiny:\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py:417: RuntimeWarning: overflow encountered in double_scalars\n",
            "  return (x0, y0, x1 - x0, y1 - y0)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py:1832: RuntimeWarning: overflow encountered in double_scalars\n",
            "  dv = abs(vmax - vmin)  # > 0 as nonsingular is called before.\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py:2038: RuntimeWarning: overflow encountered in double_scalars\n",
            "  raw_step = (_vmax - _vmin) / nbins\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py:2045: RuntimeWarning: invalid value encountered in greater_equal\n",
            "  istep = np.nonzero(steps >= raw_step)[0][0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m                         \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2066\u001b[0m                     \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1709\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1205\u001b[0m                                                                 renderer)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \"\"\"\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2087\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   2088\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 2089\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2043\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0migood\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m         \u001b[0mistep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mraw_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0;31m# Classic round_numbers mode may require a larger step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzeRR90LFIYm",
        "colab_type": "code",
        "outputId": "682f5bff-c583-42c9-9bc5-fd300968113d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plotting_loss(epochs, training_error[1], validation_error[1], testing_error[1], \"MSE Losses of BGD w/ lr of 0.001 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAJcCAYAAAAo6aqNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi1c1SH6H9rJ",
        "colab_type": "code",
        "outputId": "8361c458-9a27-42a8-8093-e4b1c7af74a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "plotting_loss(epochs, training_error[2], validation_error[2], testing_error[2], \"MSE Losses of BGD w/ lr of 0.0001 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py:2832: RuntimeWarning: overflow encountered in double_scalars\n",
            "  elif vmax - vmin <= maxabsvalue * tiny:\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:2477: RuntimeWarning: overflow encountered in double_scalars\n",
            "  delta = (x1t - x0t) * margin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAJcCAYAAAB5fZnuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdkzuqQ1JnvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotting_accuracy(epoch, training_accuracy, validation_accuracy, testing_accuracy, title):\n",
        "    epoch_idx = np.arange(0, epoch)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.plot(epoch_idx,training_accuracy)\n",
        "    plt.plot(epoch_idx,validation_accuracy)\n",
        "    plt.plot(epoch_idx,testing_accuracy)\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Training Accuracy', 'Validation Accuracy', 'Testing Accuracy'])\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5F1n-Dsq9i3d",
        "colab_type": "code",
        "outputId": "d2be25c0-c0bb-4968-8110-88e0f9c12116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "plotting_accuracy(epochs, training_accuracy[0], validation_accuracy[0], testing_accuracy[0], \"Accuracy of BGD w/ lr of 0.005 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:2483: RuntimeWarning: overflow encountered in double_scalars\n",
            "  x0t -= delta\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAJcCAYAAAB5fZnuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5w5hgneKXuG",
        "colab_type": "code",
        "outputId": "40ae38fc-9535-4209-ba02-219aac612afc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plotting_accuracy(epochs, training_accuracy[1], validation_accuracy[1], testing_accuracy[1], \"Accuracy of BGD w/ lr of 0.001 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAJcCAYAAACxEXM4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDTQIU0oppZRyAw3ClFJKKaXc4P8BBKyJIdg7Q5gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwjNk9zLLX5J",
        "colab_type": "code",
        "outputId": "6e25506b-ec99-4abe-f80a-ed2f6c944779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "plotting_accuracy(epochs, training_accuracy[2], validation_accuracy[2], testing_accuracy[2], \"Accuracy of BGD w/ lr of 0.0001 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:2483: RuntimeWarning: overflow encountered in double_scalars\n",
            "  x0t -= delta\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAJcCAYAAAB5fZnuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSK6mKdxavCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Regularization:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY2rbDGNalJA",
        "colab_type": "code",
        "outputId": "38e49f3b-9b07-4d1a-b28b-4d00d9ce7677",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        }
      },
      "source": [
        "plotting_loss(epochs, training_error[0], validation_error[0], testing_error[0],\"MSE Losses of BGD w/ Regularization of 0.001 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py:2832: RuntimeWarning: overflow encountered in double_scalars\n",
            "  elif vmax - vmin <= maxabsvalue * tiny:\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py:417: RuntimeWarning: overflow encountered in double_scalars\n",
            "  return (x0, y0, x1 - x0, y1 - y0)\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py:1832: RuntimeWarning: overflow encountered in double_scalars\n",
            "  dv = abs(vmax - vmin)  # > 0 as nonsingular is called before.\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py:2038: RuntimeWarning: overflow encountered in double_scalars\n",
            "  raw_step = (_vmax - _vmin) / nbins\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py:2045: RuntimeWarning: invalid value encountered in greater_equal\n",
            "  istep = np.nonzero(steps >= raw_step)[0][0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2063\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2064\u001b[0m                         \u001b[0mdryrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2065\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2066\u001b[0m                     \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1709\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1205\u001b[0m                                                                 renderer)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \"\"\"\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2087\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   2088\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 2089\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2043\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0migood\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m         \u001b[0mistep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mraw_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m         \u001b[0;31m# Classic round_numbers mode may require a larger step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJrbNA2Bbne0",
        "colab_type": "code",
        "outputId": "9b2fa4ad-f437-4608-bc73-223b577cba22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "plotting_accuracy(epochs, training_accuracy[0], validation_accuracy[0], testing_accuracy[0], \"Accuracy of BGD w/ Regularization of 0.001 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:2483: RuntimeWarning: overflow encountered in double_scalars\n",
            "  x0t -= delta\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAJcCAYAAAB5fZnuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmP8PRfEnilnUiBoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Umx3ZzaylO",
        "colab_type": "code",
        "outputId": "4e08e02b-d256-4785-d085-cc64147398e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plotting_loss(epochs, training_error[1], validation_error[1], testing_error[1],\"MSE Losses of BGD w/ Regularization of 0.1 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl4AAAJcCAYAAAAo6aqNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyGRhDYycrCN",
        "colab_type": "code",
        "outputId": "7363eb29-1d48-42a3-a4c4-768f1d3bf2fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plotting_accuracy(epochs, training_accuracy[1], validation_accuracy[1], testing_accuracy[1], \"Accuracy of BGD w/ Regularization of 0.1 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAJcCAYAAACxEXM4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeZxkZ13v8c+vqtdZerbMTJKZZCYJ\ngSSEECAsEgJhlTXBDYNsUYSrElBwuXhBVFQURQQFrgIiCBJErmDACLKETbYkEAjZyL7MZJLZ916q\nznP/OKd6qnuquqtn6kzN8nm/Xv2arnNOVT1d1dP97d/zO8+JlBKSJEk6tCq9HoAkSdKxyBAmSZLU\nA4YwSZKkHjCESZIk9YAhTJIkqQcMYZIkST1gCJMOAxGxMiK+HhE7I+Kvez2eo0lEXBoR3zyI+/+f\niPhgN8dUPO7fR8QfdPtxO3jeX4+IByJiV0QsO9TPL2kfQ5gOCxHx1YjYGhGDvR5Lj7wa2ASMpJR+\ne/rOiPhwRIwXvzh3RsS1EfGUacecEBEfiIj1xXF3FPc7o9i/NiJSsW9X8Yv4cxHxzG59ERHx4oj4\neIvtF0ZE1jT+WyLil7v1vGVKKb0tpfSrB/MYrYJgSunXUkp/cnCjm/M4+oF3As9KKS1IKW1uccy5\nxffXnuLfc2d4vMsi4pqIGIuID5c49K4pftb86rRtKSIejIi+pm39xbY07b6jEXFS07ZnRMRdTbfv\niohnFJ8PRMRfR8R9xff+XRHxrmLfrqaPLCL2Nt1+SYkvgQ4jhjD1XESsBS4AEnDRIX7uvtmPOiTW\nADemmVdP/suU0gJgBPi/wL9HRBWgqGh8C5hH/louBB4NfA2YHrIWF4/zSOCLwKcj4tIufR3PA65s\ns2990/hfD3wgIh7WpectxWH0/dEtK4Eh4IZWOyNiAPgP4GPAEuAjwH8U21tZD/wp8KHuD/WQ2wo8\np+n2c4pt0+0GOq1g/j5wHvA48v+TFwLfByhC8ILi/8Q9wAuatv3LgX0JOtIYwnQ4eDnwHeDDwCua\nd0TEcPGX5N0RsT0ivhkRw8W+J0XEtyJiW0Tc2wgS0//SnV6FKP7qfU1E3ArcWmx7d/EYO4q//i9o\nOr5aTEnd3lSFOiki3jt96jAiroiI17f6IiPiiRFxdfF1XB0RTyy2N77u3yv+Cn7GTC9WEdQ+Diwl\n/6UKeajZAbwspXR7ym1LKf1TSunv2jzOhpTSu4E/At4eEfv9PIiIP46Ivys+74+I3RHxV8Xt4aIq\nsLS4XSEPfJ+fbfwppSuBLcA5Tc91RkR8MSK2FJWyFzXtWxYRny3en6sj4k8b72nsq/A1VzH2q3Y0\n7Zvpvf6jiPhURHwsInYAlxbbPlbsf8+0CkYtIv6o2PfGpu+RGyPiZ4rtZwJ/D/xUcZ9txfYPR8Sf\nNj33qyLituLrvyIiTmzalyLi1yLi1uL7/b0REW2+vsGIeFfkFdH1xeeDEfFQ4JbisG0R8ZUWd78Q\n6APelVIaSyn9LRDA01o9V0rp31NKnwH2q6i1GFclIt5c/F9+MCL+OSIWFfsa7+ErIuKeiNgUEW+a\n4bE+XLwG/1m83t+NiNOa9rf7v/Zn5H+kNN7H9zQ97EfJfxY1vBz45xZP/7fAi5ufbwaPBT6dUlpf\nfN/flVJq9Zg6RhnCdDh4OfAvxcdPR8TKpn3vAB4DPJE8dPwekEXEGuC/gL8DlgPnAtfN4TlfCDwe\nOKu4fXXxGEvJA86/RcRQse8NwIuB55JXcX4F2ENeJXhxI7xExHHAM4r7T1EElf8k/wG+jHxK6D8j\nYllK6dLia//L4q/gL8008MirXy8H7gQeKDY/g/yHfTaH16Dh34EVQKuq1NfIfzFD/gtlA/Dk4vZP\nAbeklLYUtx8H3JFS2jTL+CsRcRFwHHBbsW0+eVXu48VYLgHeFxGN9+e95BWI48kD6yumP+4czPRe\nA1wMfApYTP6+TEopXdZUvXgSeaXkP4rdt5P/gl8E/DHwsYg4IaV0E/BrwLeL+y6ePqCIeBrw58CL\ngBOAu4FPTDvs+eTvwTnFcT/d5ut7E/CE4mt8JPn78uaU0k+AhxfHLE4ptQpWDwd+NK0i+6Om+x2M\nS4uPpwKnAguA90w75knk34dPB95SBNh2LiF/nZeQfx/9Gcz6f+1NwDeAxvt4WdPjfQZ4ckQsjogl\n5O/lf7C/dcAHiueezXeAN0TEb0TEI9oFZx27DGHqqYh4EvlU3CdTSteS/yL7pWJfhTzw/GZKaV1K\nqZ5S+lZKaaw45ksppctTShMppc0ppbmEsD9PKW1JKe0FSCl9rHiMWkrpr4FB9oWSXyX/JXZL8dfs\nD4tjvwdsJ/+FAfkvha+mlB6Y/mTk03S3ppQ+WjzH5cDNwAvmMObfKaoou4B3AX+QUqoX+44jD0gA\nRMRFRcVkZ0T89yyPu774d2mLfd8GTo98uvPJwD8CqyJiAfAU8pDW/DW2m4oEOLEY/17g08AbUko/\nKPY9H7irqNzViu3/D/iFInT+HPCHKaU9KaUbyQPwAZnlvYY8LH0mpZQ1vj+mi4jl5L+0X9v4GlJK\n/1ZUPLKU0r+SV1kf1+GwXgJ8KKX0/eL7+/fJK2drm475i6K6eQ9wFXnIavdYb00pPZhS2kgeFl7W\n4TgWkH9PN9tOPpV2sF4CvDOldEdKaRf513hJTJ3y/eOU0t6U0g+BH5KHyHY+nVL6XkqpRh6WG6/H\ngf5fGwU+C/xi8XFFsa2VPwdeEBGzhdM/B95O/rVfA6yLiIP5A0JHGUOYeu0VwH83VU8+zr4qx3Hk\n/Su3t7jfSW22d+re5hsR8TsRcVMxfbGNvJpxXAfP9RHgpcXnLyWf0mjlRPLqRrO7gVVzGPM7iirK\nPPI+k7+KiEYPy2byCgoAKaUrimNfD7Tr52lojGHL9B1FCLmGPHA9mTx0fQs4n/1D2HOZOYStL8Y0\nQl6laK7ErAEeXwTHbcV78BLyytdy8imy5vdsyvs3F7O817M+duTN7Z8CPp5S+kTT9pdHxHVN4z97\n2uPOZMr3RxFSNjP1+2ND0+d7yAPTrI9VfH5im2On20X+/jQbAXZ2eP+ZtBpXH/um1KHzr3GmYw/m\n/9o/k1eZ201FAlCE2/cAb53pwYo/HN+bUjqfvLL6Z8CHZqnw6RhiCFPPRN7b9SLgKRGxISI2kIeG\nR0bEI8nPFhwFWvVe3NtmO+TTVvOabh/f4pjmM54uIJ/mfBGwpAgK28l7YWZ7ro8BFxfjPZO8OtLK\nevKg0exk8qmNOSmqcT8G/of8r36ALwMvjBZ9XR34GeBB9vULTfc18sD0KPKpvK+RT4U9Dvg6QEQc\nTx4Cv9/B+MeA/w08IiJeWGy+F/haSmlx08eClNKvAxuBGrC66WFOavp8d/HvbO95J+81NH1vtPF3\n5P13b2563DXkU1SXAcuKx/1x0+PO9phTvj+K6dllHMD3x/THIv8+W9/m2OluAM6ZNm12Dm0a+bsw\nrhr7ptS7Zbb/azO9F98g/z5eCcy2rMlfkU+tPqaTQRUVvveST2GfNdvxOjYYwtRLLwTq5D+Qzi0+\nziT/Qfjyor/pQ8A7I+LEyBvkfyryZSz+BXhGRLwoIvoib9xuTEdcB/xsRMyLiIcAr5xlHAvJfxls\nBPoi4i1MrQZ8EPiTiDg9cucU03OklO4jDyYfBf5fu+kr8grRQyPil4rx/mLxdX+u0xerWeTLTjyJ\nfb8c30neG/PRiDitGOdC2k9ZNdYmuwz4Q+D3Z+gn+xp5ZeDGlNI48FXyKdo7i4oA5GeSfX5aL1Fb\nxeP8NfCWYtPnyF+fl0V+AkB/RDw2Is4splz/Hfij4j09g6YG6mIM64CXFt8jv0L70Dzbez2jiPhf\n5BXAl0x7veaT/3LfWBz3y+SVsIYHgNXR/izDy4Ffjnx5iEHgbcB3U0p3dTq2aY/15ohYXvQpvoX8\nj4VOfJX8/+TrIm/mb/RMtWrip/heHgKqQDUihqL9GaWXA6+PiFOK6ey3Af9aTCd202z/1x4g70nb\nT/H9+wLgotm+l1NK28i/h3+v3TER8VuRL88yXIzlFeTfgz9odx8dWwxh6qVXAP+UUron5WfqbUgp\nbSAv87+k+GH+O8D15EFnC3l/RaXoi3ku8NvF9uvY1z/yN8A4+Q/bjzCtubqFL5Cf0fcT8mmLUaZO\nSb0T+CTw3+QVkH8Ehpv2fwR4BO2nIkn5ekzPL8a7mfwH9/PTLE3s0zTOntxdjOWfgH8oHn8TeTP2\nKPlf8DvJX5OFwK9Pe5xtxWNcT/4a/kJKaaYlBr5F/vV+vbh9Y/E8X286ZrZ+sFY+BJwcES9IKe0E\nnkXeV7eefKrp7eT9WpBXmBYV2z9K/gt9rOmxXgX8Lvlr+/BizK3M9l7P5sXkv8Aba7Htioj/U/Sp\n/TV5D90D5N8P/9N0v6+QB+YNEbHfe57ykzH+gLwP7n7yEHnJHMbV7E/Jp5B/RP4ef7/YNqsiHL+Q\nPORuI+/JfGGxvbFw7X813eXN5D1+bySfjt9LU4Vwmg+Rv3dfJz+pZBR47Vy+sA6/htn+r70b+PnI\n1yX82xb3vyGl1Gnl793kobWdPeTfFxvIK/uvAX4upXRHh4+vo1x0+IerpDYi4snklYY1nVaCjiZF\nWN4AnJpS2nGInvPtwPEpJZucJR2xrIRJB6Fo0v5N4IPHYgArLCU/U7O0ABb5GmLnFNOsjyOfYv50\nWc8nSYeClTDpABVnOF1Dfir9sw9VFehYFBGPJZ+CPJF8uu/95Es2+ANM0hHLECZJktQDTkdKkiT1\nwBF3cdrjjjsurV27ttfDkCRJmtW11167KaW0vNW+Iy6ErV27lmuuuabXw5AkSZpVREy/gsMkpyMl\nSZJ6wBAmSZLUA4YwSZKkHjCESZIk9YAhTJIkqQcMYZIkST1gCJMkSeoBQ5gkSVIPGMIkSZJ6wBAm\nSZLUA4YwSZKkHjCESZIk9YAhTJIkqQcMYZIkST1gCJMkSeoBQ5gkSVIPGMIkSZJ6wBAmSZLUA4Yw\nSZKkHjCESZIk9YAhTJIkqQcMYZIkST3Q1+sBSJLUddddDt98Z69HocPdT10Gj3lFz57eECZJOvrc\n/hXYvg4e+qxej0SHs/nLe/r0hjBJ0tGnPg6LVsEvfLjXI5HasidMknT0yWpQ6e/1KKQZWQmTJB19\n6uNQNYQdqE27xrhj4+6ePPeW3ePcdP8OspTYO17nhvU72DtRL+W5Xv5Ta/jZR68u5bE7YQiTJB19\n6hMHFMLqWeKuzbtJCXaMTnDDuu3UsgRAXyV4+KpFjAwdunC3Z7zGj+7bzkQ9a7n/7s17uHfLHgBu\nun8Hm3aPd+V5x2utn+9QqkT+76Lhfs5etYiI6PpzDPZVu/6Yc2EIkyQdVsZrGbvHai33JeCH921j\nx96JGR/j/O27gMT/XLduxuNu37ibz/1w/WSlZePOscnQdaQ4cdEQSxcMcPyiIZ525goWDB58SOyv\nBmeeMMKi4d5UE884fiHLFgz25LkPJUOYJGk/9Sxx7d1b96vAbN87wY3rdzCRdV4pGZvI+PG67R1N\nKaUEtz24i/E2lZ9OfWpgO6Opn9/8xHWzHrtwsI9nn308jULLQ1Ys4PhFwwCcetx8Vi/JP1+3bS+3\n92CK7uSl81i7bF7LfRHRs6Ckg2cIk6TDwJ2bdjPaIqTs2DvBDet3UOsw9Az2VVk5Msg9xRRVw5bd\nE9yyYUfbKs+tD+zigZ2jk7fTLMWgwb65ndc1MtzPI1Ytmpximskpx83nrBNHmD/QeqpowVA/5540\n8/TUqn8bpj60jC+/4CmzPt+qxcMM9c8+LbV43gAPP3HRrMdJnTKESTq2/eS/Yc9mAPZO1Nv23nRL\nluBbt29ia9G7kyW4feOuWafXumH1YB/HtZniefxwcOLxQww3BZ9F8/pZOTK037ErFg6y8ICmvDYe\nwH3aWD/L/rEtsGQVpy1f0L3nlLrMECbpsFLrMARt3DXGzRt2Ttl235Y93LlpXwWolsbIUo2fPLCT\nLXvG9nuM5dlG/mHX6w5uwHNUAZ7Uasf+WaccM82m7ZxhX5ME7OjGWMp22oUwfkSMVD0yWB1ksNq7\n3jNDmCSuuvlBbrw//2W1Ztk8nvSQ41g8bwCAlBK3Pbhrxn6edVv3csemqb/da/XE9eu2satosF4w\n2M8jVy+iUgk27xrn5g35KejNNu0a57YHdx3017NwsA8G1sOqd0FkMEj+Mc0DwPnLTjro59NhauvX\n4PLzez0KHcZe/5jX8ytn/0rPnt8QJvXYWK3Oxp1j7Bytcf267WRZYnSizvXrdrTsEWqWSNywfgdb\nd48z2F/l4SeOMH+g/X/rDTtGufWBqeWOWpbYM77/84wM5Y+ze7xO/QDPFhvsq/DwE0fIEnz/no18\n6aYHJvedsGiIk5ZObTZeOn+AXzzvpMlG6JlUi7O3Fjc1JVciePiJI/RVK1x1z1W87qqMV5z1ClbO\nX9n6QXash2/9HTzqZbDyrAP6GiUduR694tE9fX5DmFQYnaiTEqzfvpfbH9zFqiXDnHrcAob6K1Ma\ngEcn6vRXK4zV6nz3ji1cc/cWtu+d4Pp1O9ixd4KVI4P0Vyvct3Vv2+daVDQpb987wX/fuIHRidZT\ncKctnz/r2jgLh/p4winLuHPT7hmfs+GJpx3H8Yumzn0tntfPpU9cS0Tw1Vse5Ib1O6asE3TcggHO\nPGGk7WNWInjUyYun9BMBVCPoq+YN3LV6Rr2p8jVQrZSy7k/DWJZPP/7M6T/DaYtPa33QfdfAjrfB\n6qfB6c8sbSyS1IohTMecLbvHufL6+9m0K/8lPV7L+Matm7h+3faWxy+dP8CJi4cY7KvywI7RlkFn\n3kCVxcP9nLR0Hrdv3E1KiTNPGGFJMaXXbM94nRvWb+fuzfn03cNWLuT555zIonn9nLZ8PicuzqtA\nI0P9zB889P9FLz53FRefu6rrj9tXrRzSHzhjtfz9Haju/x5MqhfN8BV/FEo69PzJo6PagztH+eG9\n+WrTH/323Vx377aWvU3zB6r8/GNW85AVC+irBKcun8/dm/ewYfsoX7hhA3du3M0jVi9i7bL5zB/o\nY3igyuolwzzjzJU8Zs2S/abV1Htj9TyEzdh0Wy9WF58pqElSSQxhOiLc9uBObtmwizXL5u0XeL5y\n8wN8784t7Nhb48b7dzBRz6jVE7UsY9OuqZfwuPBhyznrhBEeffISnnrGiilrFrWbGnvjc86Ycb8O\nT+NFwJoxhGVFJcxrDErqAUOYDlt3btrNtXdv5c5Nu/j4d+9h65726yhFwPIFg6wcGWLhUB/3bt3D\nuScs5YTFQ5x5/AiVSnD2qhHOOL59X1P7xzZ89cqeiT185MaPMFobnf3gaa7fdD3gdKSkw5c/eVS6\n8VrG3Zt3k4AFg30sWzDADet3cMO67YzX80btlBLXr9vOxp1jXL9uO7vHajSfkLdgsI93X3IuO/ZO\nTN6nYf5AlRc+alVHK17ryPK9Dd/jfde9j75KHxXmtkI7wOlLTp9lOrJRCXM6UtKhZwhTqepZ4g2f\nvI7P/ej+WY+tRH7NtnNWL+Kc1YvZOTrBqsXz+OXz13Y/YF3xOvjJF7r7mOq60cEKjPTx/zbt4dTZ\nLzu4vwdugL8+s/3+WnGShSFMUg8YwnTQtu+Z4If3bZu8PTxQ5cEdY1z+vXu47t58sc7nPeIEnn32\n8fx43XZ2jtV42MqF+zW0D1Qr+y1xUJo7vwYD82DtBYfm+XRAxsbuhz03M7D2yVCdfe2wAzJvKSxr\ns4SFJJXIEKY5u3vzbu7YuJtbHtjJ3Zv3cPn37ml77AWnH8cTTl3GS5+whkXD/bzgkScewpHOoD4B\npz4VLvrbXo9EMxi75ZPwnT9h8KffBvOW93o4ktRVhjB1ZOvucf7z+vt5z1duY8OOqU3SqxYP8+bn\nncmKkUE2bB/j/u17ecSqRaxaMszqJYfp0g31Cc+IOwI0znCcsbleko5QhjDtZ8foBN8sFi/dNVrj\nu3du5icP5NfzGxnq49VPPpXHrFnCI1cvZtFwP4N9FSqVI+wMwvq4IewI0FjryxAm6WhkCOuh3RO7\ned6/P4/No5vbHnPRaRfxZ0/6s0M4Kvirz9/CR79zN5BfCLl/xWdZeObXAEjA5RvzD645pMPqrhNG\nYOPn4SOf7/VINIsgGKgYwiQdfQxhPbRp7yY2j27m6Sc/ndOXnL7f/s/f+Xlu3nLzIRtPSom7N+/h\nX757N49du4T3/NKjWTkyxCu/8Enu3XkCFz/k4kM2ltJ9/R2w6jw47cJej0SzWDOyhmrF5UckHX0M\nYT3UmGp57inP5Vlrn7Xf/ru231VaCLv1gZ3cvnEXEFx184Os27aXH963jZ2jNQCeceZKVo4MTY5z\nzcgaXnPua0oZS0985k1w9rlwNH1NkqQjiiGshyaKhSLbLSY5UB2YbEzull1jNX79Y9fyjVs37bdv\n8bx+Xvu0h/D4U5Zx/kOWTW4fr4+zeHBxV8fRU1kdSPaESZJ6yhDWKzdfydj93wVg4NYvwvr9K16D\nm29nbHQbfPcfDugpxmsZP16/nSxL9PdV2Dte5xu3buLUsRqPXtjPY9cupRIw3F9l8bwBTlo6j77K\nnbAF+F7T4+x6gIGJ8QMex2Eny6t9hjBJUi8ZwnphfA984pcYGxqAE1Yy+N33w9jYfocNLl3M+IIF\n8F+/d0BPMwA8etq2JwD0AxPArZ09ztjqExjcci/86KoDGsdha9FJvR6BJOkYZgjrgd2j2/j0yAJu\nXnMe7LqdwZd9Bpaesd9xAz/6B/b+5F/5x4vanx35wI5Rxmt1EvDpH6ybsm/tsvk87PiFjAz1s2e8\nxgmLhqhWgsG+6pwuSr3tpo8x+NAL4bwDC4OHpajA8FE0xSpJOuIYwnrg6+u/yduXLYFdtzPcN8zK\nZQ+F4aX7HXfKcWdSu6XOu67vcBpwxdSbdwJ3bmza8MABD5lTlp2ZX95FkiR1hSGsB/ZO7Abgc6e9\nghOf+Jv0V1r3Jr3wIS/kOac8h7GJOt+7cwv/9K07+Z/bpq4pdvzIIL//3DO5Z/MeHn/qMs5Zvajr\n442IticPSJKkA2MI64GxWn7Zn4UDC9oGMIBte8Z5++dv4fLv3Tu57bmPOIkLH7aChYN9RMATTl3G\n4nkuZClJ0pHGENYD40UIm6269I7/3hfA/tdTTuWV55/CimLtLkmSdGQzhPXA5PXw+vYPVCkl1m8f\n5fLv3sPHvnMPF597Iu++5FGHeoiSJKlkhrAeGKuPUkmJvmlTkTtHJ3jlR67he3duAeCERUO87un7\nX85IkiQd+QxhJdk5vpNLPncJW8e27rdvrDbKYEpEsVjoj9dt5w+vuIFr786PPXvVCL/9zIfx1DNW\n7HdfSZJ0dDCElWTD7g3cs/MeLlh1ASePnDx15+6NPOzay9kymvGxL9/K13+ykWvv3sqi4X6e/fDj\n+T/PPZNF81zNXZKko5khrCSNaz7+4sN+kaec9JTJ7SklvvqV/+Kpuz7IL3/qBq7K8jMbf/enH8Zv\nXHjanBZRlSRJRy5DWEkmm++r+5aP2LRrjPP+9Es8On7CUwfhISsXcf6jz+R555zA8SNDBjBJko4h\nhrCSNEJY8zIUr/7nawDoow7Am15wDpx66qEfnCRJ6rlKrwdwtGpMRzZC2B0bd/H9e7Zx2vL5/Our\nzssPqpiBJUk6VpkCuujb67/NvTvvZfvYdu7ffT+wbzryD6+4AYB/eNljiB3fy+9gCJMk6ZhlCuiS\nelbnN770G9RSbXLbQGWAZcPL+M4dm/nGrZtYtXiYh6xYCNvy6UhDmCRJxy5TQJeM1cemBLC3Pelt\nPPWkp7JgYAF/+B9fB+CTv/ZT+c6sOK5SPdTDlCRJhwl7wrqk0QPWsHLeShYMLOCau7ZwywM7eekT\nTmbV4uF852QIMwNLknSsMoR1SeNsyIaB6gA3rt/Bz//9t5k3UOV3n3VGvqM2Bt9+b/65IUySpGOW\nIaxLplfCBqoDvPkz1wPw9y99zL4V8O/5Dtz7nfzzBV6WSJKkY5UhrEumV8J2jcL379nG089YwZMf\nunzfjtpo/u8rvwjzlh7CEUqSpMOJ82EH6cE9D/LSK186uSRFw99+6S4AfusZD516h/pE/m/fIJIk\n6dhlJewgffb2z04GsKVDS3nf09/Hk1f8At+8qc4TT1vGI1YvmnqHxrRl0+WMJEnSsccQdpD6mprr\n3/T4N3HB6gu49gfnAxX+8ufP2f8Ok2dG9h+aAUqSpMOSIewgVWPfWl+D1UGuvXsrG3aM8pqnnsbq\nJfP2v8NkJcwQJknSscwQdpCqUxZc7eNVxUW6n3ZGmzMfGz1hhjBJko5pNuYfpOZK2Jdv2MKW3RU+\n8PLzeMyaNmc+ToYwe8IkSTqWWQk7SM09YV+9ZSvHLRjkGWe2qIJlWf7RmI50oVZJko5pJoGD1N/U\nYH/vxiqXPfkkImLqQbd9GT7+on1N+eASFZIkHeMMYQepEbjecPbf8Mc3jfHYtS2mITfflgew838L\n+ufBkrXQP3xoBypJkg4rhrCDVM/qAOzYOR8Y42HHL2xxUNEHdsFvw9DIoRucJEk6bNkTdpDqKQ9h\n7/rSHQCsWNhimtFlKSRJ0jSGsINUm+zzqvDCc0/cvx8M9vWCeUakJEkqGMIOUqMSRqrwxxed3eag\ncSBgyppikiTpWGZP2AH60I8/xOfv/Dw3bbkJgAUDAyya12a6sT5hFUySJE1RaiUsIp4dEbdExG0R\n8cYW+9dExJcj4kcR8dWIWF3meLrpi3d9kVu33jp5+wlrZxh6fcJ+MEmSNEVpISwiqsB7gecAZwEv\njoizph32DuCfU0rnAG8F/rys8XRbLdVYMrRk8vbDVy1qf3BmCJMkSVOVOR35OOC2lNIdABHxCeBi\n4MamY84C3lB8fhXwmRLH01W1rMb8/vls3LsRgNNXFEtT3HgFrLtm6sF3fxsqhjBJkrRPmSFsFXBv\n0+37gMdPO+aHwM8C7wZ+BlgYEctSSpubD4qIVwOvBjj55JNLG/BcTGQTLOhfMHn7xMVD+SeffyPs\nvH//HrBTLzxkY5MkSYe/Xjfm/w7wnoi4FPg6sA6oTz8opfR+4P0A5513XjqUA2ynUQlrWLW4WAG/\nNgqP+WV4/jt7NDJJknQkKAVC6NIAACAASURBVDOErQNOarq9utg2KaW0nrwSRkQsAH4upbStxDF1\nzUQ2MSWEHbegWKS1XvNMSEmSNKsyz468Gjg9Ik6JiAHgEuCK5gMi4riIaIzh94EPlTierqplNUYG\n8ksQVSZWUakUi7TWx6Ha6wKjJEk63JWWFlJKtYi4DPgCUAU+lFK6ISLeClyTUroCuBD484hI5NOR\nrylrPN3WqISdMfE2xsabLlWUuSaYJEmaXaklm5TSlcCV07a9penzTwGfKnMMZallNfor/WzbMcJp\ny4sG/ZTySxR5JqQkSZqFly06QBPZBH2VPjbsGGXFSKMfbCL/1zXBJEnSLAxhByClRC2rUasHO0dr\nnLx0Xr6jPp7/awiTJEmzMIQdgMZFu3fszQA4dfl8mNgLe4rlzewJkyRJs/A0vgNQy2oA7BrNb59a\n3QR/cfa+SljfUI9GJkmSjhSGsAMwkeW9XxO1fFmKxbWNeQB77K/C8jPg7J/t5fAkSdIRwBB2ABqV\nsIl6HsLmVYtF/s/+OVjzxF4NS5IkHUHsCTsAjRC2aWeN/mowEHlvmL1gkiSpU4awA9CYjrxp/W4W\nzxvY1wtWsbAoSZI6Ywg7AI1K2NhE8LSHrWhaH8xKmCRJ6owhbI42793MTVtuym+kKhc89DgXaZUk\nSXPm/NkcXfr5S7lrx10ApGyIZfMHYachTJIkzY0hbI42j27mwpMuZFnt6Xz4piqnr1wA2xo9YYYw\nSZLUGacj52i8Ps4pi06hb/yhDPX3sWz+AFz38XynPWGSJKlDhrA5SCkxVh9jsDrI+u17OXHxMBEB\n9/8oP2B4cW8HKEmSjhiGsDloLE0xWB1k3bZRVi0e3rfzia+zJ0ySJHXMEDYHY/UxAPpjgNse2Mma\nZfPyHfVxA5gkSZoTQ9gcbB/bDsDoRLB7vM6ZJ4xAlkGq2w8mSZLmxBA2B5tHNwOwZXc+Lblm6Xwo\npihdLV+SJM2FIWwOspRfI3KQ5QCsHBl0oVZJknRADGFz0Lhc0Z6xBDD1upFOR0qSpDkwhM1BPdUB\n2D3aCGH9UAQzpyMlSdJcGMLmoJ7lIWzXWMbCwT76qxXYuy3faSVMkiTNgSFsDhqVsD3jiUXzih6w\nf3xm/u/A/B6NSpIkHYkMYXPQ3BM2MlSEsLEdsHgNnPG8Ho5MkiQdaQxhczDZEzaWMTLc1AP2iF+A\n/uE295IkSdqfIWwOGj1hu0cTC4f6IatDyuwHkyRJc2YIm4Nayqcjd49m+XTk5BphnhkpSZLmxhA2\nB81nR44M97lGmCRJOmCGsDnY1xOWWDw80LRGmKvlS5KkuTGEdWi0Nsq7rn1XcavCiYuHmiphhjBJ\nkjQ3hrAO3bj5RraObaUv+km1eaxaMux1IyVJ0gEzhHVotD4KwEvXvA3oY9XiYbj6A/lOe8IkSdIc\nGcI6NFFUvbbszgA4ftEQ/Pjf853Hn9OrYUmSpCOUIaxDY/UxALbtThy3YIDBvmremP+ol8HKs3o8\nOkmSdKQxhHWoEcL2jAWLhosesPqE/WCSJOmAGMI6tLe2F8hD2EgjhGUT9oNJkqQDYgjr0Puuex8A\nu/dW8ksWQV4Jq7haviRJmjtDWIeG+4ZZPrycPaODLBwqglfdSpgkSTowhrAOjWfjXLD6AnaM1vLr\nRqZUTEfaEyZJkubOENah8fo4A5UBdoxOMDLUt++SRYYwSZJ0AAxhHRqrj1GJfsZrGYvm9cNE3qjv\ndSMlSdKBMIR1aLw+Tq1WBWDlwiH4xjvyHYMLezgqSZJ0pDKEdWDL6Bbqqc7YRP5yHb9oCEZ35DvP\n/aUejkySJB2pDGEd+M767wBQyRYAsHT+QN6UP7IK+od7OTRJknSEMoR1YCLLrxt50vCjAJg/0Oca\nYZIk6aAYwjrQCGETEwHA8EDVNcIkSdJBMYR1oBHCxmt5CJs3UIX6uMtTSJKkA2YI68BEPQ9hY41K\nWH81XyfMECZJkg6QIawDjUrYWK3CUH+FSiXySphrhEmSpANkCOtAI4SNjsG8Aa8bKUmSDp4hrAMT\n2QSVqDA6kfJ+sG/+DWy4HqqeHSlJkg6MIawDE9kE/ZV+9ozX8xD2nb+HShXOvKjXQ5MkSUcoQ1gH\nJupFCJuoMzxQXLz7rBfC417V66FJkqQjlCGsA41K2N7xGvP6q/lq+S7UKkmSDoIhrAO1rDZ1OjKr\nuzyFJEk6KIawDvx404+pVqrsHa/nq+VntbwnTJIk6QA5p9aBneM72TK6hb7JSljN6UhJknRQrIR1\nICJ45ppnsmeyJ8wQJkmSDo4hrAP1VKev0lf0hOWXLjKESZKkg2EI60A9qxNUqWWJBY1+fHvCJEnS\nQTCEdaCe6qSUv1Tz+62ESZKkg2cI60Atq5FSHr7m96V8oyFMkiQdBEPYLLaMbmHH+A5+vOlHAMyb\nnI50nTBJknTgDGGzuO7B6wC4fcfNAMyrNiph9oRJkqQDZwibo3mNWUinIyVJ0kEwhM3RsD1hkiSp\nCwxhs0gpTbk9XDWESZKkg2cIm0Ut1abc3lcJsydMkiQdOEPYLLaObp1ye6ia5Z9YCZMkSQfBJDGL\nDbs3AHD6/Auoxs0s/sJf5jsMYZIk6SBYCZvFvP55ADxx5DVcWL2O6obr4PSfhlWP7vHIJEnSkcxy\nzixqWd4TNjYRLKok6BuCl3yyx6OSJElHOiths6hlNapRZe9EnaEqTkNKkqSuMITNopbyELZnvM5g\nJYPwrEhJknTwDGGzqGU1+ip97B2vM1hJLk0hSZK6whA2i3pWp6/Sx+7xOoPV5HSkJEnqCkPYLPZV\nwmoMVDIrYZIkqSsMYbOopRp90cee8ToDFayESZKkrjCEzaKW1ahWquwdrzMQVsIkSVJ3GMJm0ZiO\nzCthnh0pSZK6wxA2i3qqFyGsRn/YmC9JkrrDEDaL5sVa+yIzhEmSpK4whM2iluWN+RP1RH9kUPEl\nkyRJB89EMYtaqhGRV7+shEmSpG4xhM2iltWI4mXqN4RJkqQuMYTNIg9h+RmRVTw7UpIkdUepISwi\nnh0Rt0TEbRHxxhb7T46IqyLiBxHxo4h4bpnjORD1rD5ZCXM6UpIkdUtpISwiqsB7gecAZwEvjoiz\nph32ZuCTKaVHAZcA7ytrPAeqltUgNSphdRvzJUlSV5SZKB4H3JZSuiOlNA58Arh42jEJGCk+XwSs\nL3E8B6Se6tA8HWklTJIkdUGZIWwVcG/T7fuKbc3+CHhpRNwHXAm8ttUDRcSrI+KaiLhm48aNZYy1\nrYlsArL8ZcorYYYwSZJ08Ho9t/Zi4MMppdXAc4GPRsR+Y0opvT+ldF5K6bzly5cf0gHWshqpMR2Z\n6jbmS5KkrigzhK0DTmq6vbrY1uyVwCcBUkrfBoaA40oc05zVU50sBQAVvIC3JEnqjjJD2NXA6RFx\nSkQMkDfeXzHtmHuApwNExJnkIezQzjfOIq+E5S9TJTkdKUmSuqO0EJZSqgGXAV8AbiI/C/KGiHhr\nRFxUHPbbwKsi4ofA5cClKaVU1pgORD2rk2V59StS3UqYJEnqilLLOimlK8kb7pu3vaXp8xuB88sc\nw8GqpRpZCgb7KkUIsxImSZIOnoliFhPZBHUqzBuoQmYIkyRJ3WGimEU9qxchrA+yGux/8qYkSdKc\nGcJmUctq1FPklbAd91sJkyRJXWFZZxa1VKNeDxb2F+cL7Nnc2wFJkqSjgiFsBlnKyFJGrR4s7M/y\njase3dtBSZKko4IhbAb1rA5QhLBiY99Q7wYkSZKOGoawGdRSDYCJeoUFfUUlzJ4wSZLUBYawGdSy\nPITV68FwtQhh1YEejkiSJB0tDGEzmAxhWTBUaYSw/hnuIUmS1BlD2AzqKe8Jq2dVBiv551bCJElS\nNxjCZtCohGX12BfC7AmTJEldYAibQSOE1bJgMKyESZKk7jGEzaARwqr1Oi+96TfyjfaESZKkLjCE\nzaDREzaS9jCQ7YH5K2D1Y3s8KkmSdDQwhM2gUQmrFFcs4jl/AcOLezcgSZJ01DCEzaBRCas2NtiU\nL0mSusQQNoPGZYuqjUqYIUySJHWJIWwGjUrY5HRkVNsfLEmSNAeGsBlMnh3Z2GAlTJIkdYkhbAaT\nPWGpKIVVrIRJkqTuMITNoNETNln/MoRJkqQuMYTNoJaKJSoaG5yOlCRJXWIIm8FkJWxyOtIQJkmS\nusMQNoP91gnz7EhJktQlhrAZNKYj960TZgiTJEndYQibQWOJir6U5RsMYZIkqUsMYTP4yZafANCf\nIt9gT5gkSeoSQ9gMFg4sBGC43p9vMIRJkqQuMYTNIJE3g1Ub05HhyyVJkrrDVDGDrAhffZGfJWkl\nTJIkdYshbAaTlbDGBkOYJEnqEkPYTIqlKfpoVMI8O1KSJHWHIWwGGcV0JI0lKqyESZKk7jCEzSCl\nxnSk64RJkqTuMoTNIJEIKvtCmJctkiRJXWIIm0GjEtYfTkdKkqTuMoTNID87MhioGMIkSVJ3GcJm\nkFIiCAYqxWmS9oRJkqQuMYTNID87MuiPIoS5Yr4kSeoS59dmUmSvgcgg+iCit+ORJElHDUs7M2j0\nhD0k7oHG9SMlSZK6wBA2g/zakcGStMMQJkmSusoQNoNGJSxFFdac3+vhSJKko4ghbAYpJSIF1cig\n2t/r4UiSpKOIIWwGqaiFVclcLV+SJHWVIWwG+Yr5QTWSa4RJkqSuMoTNoNETViW5RpgkSeoqk8UM\nspRBcjpSkiR1nyFsVkGFDCq+VJIkqXtMFjNIKZEIKpGshEmSpK4yhM0go3k60pdKkiR1j8liBo2z\nI/PpSCthkiSpewxhs0iJPIQ5HSlJkrrIEDaDxrUjrYRJkqRuM4TNIJHySljKIKLXw5EkSUcRQ9gM\n8rMjnY6UJEndZwibQb5Yq9ORkiSp+wxhM6gXZ0dGshImSZK6yxA2gyxrWqLCdcIkSVIXmSxmUC/O\njhys7XQ6UpIkddWsISwiXhsRSw7FYA439SwjSPmNvdt6OxhJknRU6aQSthK4OiI+GRHPjjh21mqo\np4woMhgnPLKnY5EkSUeXWUNYSunNwOnAPwKXArdGxNsi4rSSx9ZzeU9YwelISZLURR31hKX8Ioob\nio8asAT4VET8ZYlj67laypgs+xnCJElSF/XNdkBE/CbwcmAT8EHgd1NKExFRAW4Ffq/cIfZOluWN\n+QBUZn2pJEmSOtZJslgK/GxK6e7mjSmlLCKeX86wDg/fffCrMFjcMIRJkqQu6mQ68r+ALY0bETES\nEY8HSCndVNbADjsu1ipJkrqokxD2f4FdTbd3FduOLfaESZKkLuokhEXRmA/k05B0No15RMtSNnWD\n05GSJKmLOglhd0TE6yKiv/j4TeCOsgfWa/VUn7rBSpgkSeqiTkLYrwFPBNYB9wGPB15d5qAOB03F\nv5yVMEmS1EWzJouU0oPAJYdgLIeV/SthhjBJktQ9nawTNgS8Eng4MNTYnlL6lRLH1XP79YSF1zqX\nJEnd00my+ChwPPDTwNeA1cDOMgd1OGiEsBUPnJdvsBImSZK6qJMQ9pCU0h8Au1NKHwGeR94XdlRr\nhLDJF8jGfEmS1EWdhLCJ4t9tEXE2sAhYUd6QDg+NnrAqRYO+lTBJktRFnSSL90fEEuDNwBXAAuAP\nSh3VYaBRCZusfxnCJElSF82YLIqLdO9IKW0Fvg6cekhGdRiYnI5sLFVhY74kSeqiGZNFsTr+7x2i\nsRxWrIRJkqQydVLe+VJE/E5EnBQRSxsfpY+sx/ZVwooNhjBJktRFnSSLXyz+fU3TtsRRPjU52Zgf\nxXphnh0pSZK6qJMV8085FAM53DQqYf1EvsFKmCRJ6qJOVsx/eavtKaV/7v5wDh+NENZXZDArYZIk\nqZs6Ke88tunzIeDpwPeBYyKE9Ufj7EhDmCRJ6p5OpiNf23w7IhYDnyhtRIeJfdORBacjJUlSFx3I\n4le7gaO+T2z/6UhDmCRJ6p5OesI+C0wu1ACcBXyykwePiGcD7yZfbuuDKaW/mLb/b4CnFjfnAStS\nSos7G3q5GmdH9k1etsjpSEmS1D2dlHfe0fR5Dbg7pXTfbHeKiCrwXuCZwH3A1RFxRUrpxsYxKaXX\nNx3/WuBRnQ68bKlYKX+gYgiTJEnd10kIuwe4P6U0ChARwxGxNqV01yz3exxwW0rpjuJ+nwAuBm5s\nc/yLgT/saNSHQKMS9oTaD/IN1YEejkaSJB1tOukJ+zcga7pdL7bNZhVwb9Pt+4pt+4mINeR9Zl9p\ns//VEXFNRFyzcePGDp764DV6wkZjHgwthv7hQ/K8kiTp2NBJCOtLKY03bhSfd7ssdAnwqZSK8tM0\nKaX3p5TOSymdt3z58i4/dWv7zo7MYPV5h+Q5JUnSsaOTELYxIi5q3IiIi4FNHdxvHXBS0+3VxbZW\nLgEu7+AxD5kpjfmeGSlJkrqsk3Txa8C/RMR7itv3AS1X0Z/mauD0iDiFPHxdAvzS9IMi4gxgCfDt\njkZ8iEwuUUFyoVZJktR1nSzWejvwhIhYUNze1ckDp5RqEXEZ8AXyJSo+lFK6ISLeClyTUrqiOPQS\n4BOpcTriYWIyhKXMMyMlSVLXdbJO2NuAv0wpbStuLwF+O6X05tnum1K6Erhy2ra3TLv9R3MZ8KGy\nrxJmCJMkSd3XSU/YcxoBDCCltBV4bnlDOjzs6wnLnI6UJEld10kIq0bEYONGRAwDgzMcf1RozI72\nJxvzJUlS93WSLv4F+HJE/BMQwKXAR8oc1OGgUQmrUnc6UpIkdV0njflvj4gfAs8gv4bkF4A1ZQ+s\n1ybXCbMxX5IklaCT6UiAB8gD2C8ATwNuKm1Eh4kpjfn2hEmSpC5rWwmLiIeSX8/xxeSLs/4rECml\npx6isfVUI4RVrYRJkqQSzDQdeTPwDeD5KaXbACLi9YdkVIeBybMjU93GfEmS1HUzTUf+LHA/cFVE\nfCAink7emH9McDpSkiSVqW0ISyl9JqV0CXAGcBXwW8CKiPi/EfGsQzXAXnE6UpIklWnWxvyU0u6U\n0sdTSi8gvwj3D4D/XfrIeszLFkmSpDJ1enYkkK+Wn1J6f0rp6WUN6HCxb4kKe8IkSVL3zSmEHUsy\niulIe8IkSVIJDGFtNC5bVCE5HSlJkrrOENZGYzoyEoYwSZLUdYawNhohrAJOR0qSpK4zhLVRy/LF\nWitgY74kSeo6Q1gbkyEs2RMmSZK6zxDWRj1zOlKSJJXHENZGrdGYD1bCJElS1xnC2qjXmyphhjBJ\nktRlhrA26o2zI1OyMV+SJHWdIayNRmN+gD1hkiSp6wxhbTQqYVVwOlKSJHWdIayNRk+YjfmSJKkM\nhrA2aqkOyelISZJUDkNYG1mWUUQwG/MlSVLXGcLayNcJa4QwK2GSJKm7DGFt1LM6kYoQ5nSkJEnq\nMkNYG3UrYZIkqUSGsDbqWUak4oYhTJIkdZkhrI0sJWzMlyRJZTGEtVHPMgJ7wiRJUjkMYW1kxYr5\ngNORkiSp6wxhbdRS89mRvkySJKm7TBdtZFnWmIw0hEmSpK4zXbThEhWSJKlMhrA2stS0RIWN+ZIk\nqcsMYW1kqfnsSF8mSZLUXaaLNuqeHSlJkkpkCGsjyzKvHSlJkkpjCGujnprOjqz4MkmSpO4yXbRh\nT5gkSSqT6aINz46UJEllMoS1kU2ZjjSESZKk7jKEtTElhFkJkyRJXWYIayOfjrQnTJIklcN00UZG\n2vfiOB0pSZK6zBDWxtTpSF8mSZLUXaaLNmzMlyRJZTKEtZFSRh/FGhVWwiRJUpeZLtrIUsYgE/mN\n6kBvByNJko46hrA2MhIpVaHSB9X+Xg9HkiQdZQxhbaSU5S/O8NJeD0WSJB2FDGFtZI0QZlO+JEkq\ngSGsjdRYJ8zV8iVJUgkMYW3k05EJKr5EkiSp+0wYbWQ0piP7ej0USZJ0FDKEtZFSogpOR0qSpFIY\nwtrIK2HJxnxJklQKQ1gbKdmYL0mSymMIayORUU3YmC9JkkphwmgjkagEVsIkSVIpDGFtpJRRSfaE\nSZKkchjC2khknh0pSZJKYwhrI18x30qYJEkqhyGsDc+OlCRJZTKEtZVR9bJFkiSpJCaMNvZNR3rZ\nIkmS1H2GsDYm1wlzOlKSJJXAENZWKqYjDWGSJKn7DGFtpMa1I62ESZKkEhjC2tjXE+ZLJEmSus+E\n0VayJ0ySJJXGENaWi7VKkqTyGMLayM+OtCdMkiSVwxDWlmdHSpKk8hjC2kqeHSlJkkpjCGsrUUmZ\nZ0dKkqRSmDDaalw70ssWSZKk7jOEtROJio35kiSpJIawtmzMlyRJ5TGEtZVcokKSJJXGENZCSimf\njsTGfEmSVA4TRguJBGBPmCRJKo0hrIUsZQD2hEmSpNKUGsIi4tkRcUtE3BYRb2xzzIsi4saIuCEi\nPl7meDo1GcJSZiVMkiSVorRFsCKiCrwXeCZwH3B1RFyRUrqx6ZjTgd8Hzk8pbY2IFWWNZy4aIcwL\neEuSpLKUWQl7HHBbSumOlNI48Ang4mnHvAp4b0ppK0BK6cESx9OxfSEMK2GSJKkUZYawVcC9Tbfv\nK7Y1eyjw0Ij4n4j4TkQ8u9UDRcSrI+KaiLhm48aNJQ13n32N+Xh2pCRJKkWvE0YfcDpwIfBi4AMR\nsXj6QSml96eUzkspnbd8+fLSB9WohAVYCZMkSaUoM4StA05qur262NbsPuCKlNJESulO4Cfkoayn\npkxHeu1ISZJUgjJD2NXA6RFxSkQMAJcAV0w75jPkVTAi4jjy6ck7ShxTR+pZHYCwMV+SJJWktBCW\nUqoBlwFfAG4CPplSuiEi3hoRFxWHfQHYHBE3AlcBv5tS2lzWmDpVzxpLVOB0pCRJKkWpc20ppSuB\nK6dte0vT5wl4Q/Fx2MgajflgY74kSSqFCaOFKdORVsIkSVIJDGEt1BqN+Ql7wiRJUikMYS1kmYu1\nSpKkchnCWqhlTeuEWQmTJEklMIS10OgJq9oTJkmSSmIIayGjqIR52SJJklQSE0YLNXvCJElSyQxh\nLXjZIkmSVDZDWAuNsyMjedkiSZJUDkNYC05HSpKkshnCWqin/OxIL1skSZLKYsJooZ41XTvSSpgk\nSSqBIayFrFEJsydMkiSVxBDWQpbySliAlTBJklQKQ1gLU3vCDGGSJKn7DGEteHakJEkqmyGshak9\nYb5EkiSp+0wYLWSeHSlJkkpmCGuhXly2KMDLFkmSpFIYwlqYvHZkwsZ8SZJUCkNYC/XJxvzkdKQk\nSSqFIayFOnljfj4daQiTJEndZwhrISsqYdUEhC+RJEnqPhNGC/XUdHaklTBJklQCQ1gL2eTZkfaE\nSZKkchjCWmgsUWElTJIklcUQ1kI9KxrzE1bCJElSKQxhLWRWwiRJUskMYS1kRWN+leTZkZIkqRQm\njBYai7W6TpgkSSqLIayFjObLFnntSEmS1H2GsBam9ITZmC9JkkpgCGth8uxIkpUwSZJUCkNYC41K\n2OjI6VDxJZIkSd1nwmihcXZkeGakJEkqiSmjhcnLFhnCJElSSUwZLUw25hvCJElSSUwZLVgJkyRJ\nZTNltLBviQpfHkmSVA5TRgv1yenI6PFIJEnS0coQ1sK+SpghTJIklcMQ1oI9YZIkqWymjBZSsU6Y\nZ0dKkqSymDJaqLtEhSRJKpkpo4V905FevFuSJJXDENaCi7VKkqSymTJayFyiQpIklcwQ1kLCsyMl\nSVK5TBktZCkRyRAmSZLKY8poIUsZgY35kiSpPIawFqpjm6mQwJ4wSZJUEkNYCyfd9SmqKYHTkZIk\nqSSmjBYSxQtjJUySJJXEENZCFhQ9Yb48kiSpHKaMFjIalTBfHkmSVA5TRguJIBJQ8eWRJEnlMGW0\nUA+KsyN9eSRJUjlMGS0koIo9YZIkqTymjBYyyKcjPTtSkiSVxBDWQkYQ4HSkJEkqjSmjhVT0hFXq\nE70eiiRJOkoZwlpIjX/7h3s6DkmSdPQyhLWQyBdrzRae2OuhSJKko5QhrIVGCAvXCZMkSSUxZbQw\nGcI8O1KSJJXEENZGJIio9noYkiTpKGUIayE1lqhwOlKSJJXElNFCCgiSK+ZLkqTSmDJayMDFWiVJ\nUqlMGS14dqQkSSqbKaMNz46UJEllMoS1kGicHenLI0mSymHKaKFx2SKnIyVJUllMGS00esJszJck\nSWUxZUyXEimi6AlzsVZJklQOQ9h09QmgWCfM6UhJklQSU8Z09XGvHSlJkkpnCJsum5hszLcnTJIk\nlcWUMd3odhvzJUlS6UwZ0939LRJQSRjCJElSaUwZ0629YF8lDHvCJElSOQxh0y0+aXKJCmzMlyRJ\nJTGEtZBmP0SSJOmgGMJayKcj901KSpIkdZshrAXPjpQkSWUzZbSwL4RZCZMkSeUoNYRFxLMj4paI\nuC0i3thi/6URsTEiris+frXM8XTilg07AQgbwyRJUon6ynrgyK9+/V7gmcB9wNURcUVK6cZph/5r\nSumyssYxV/ds2WMlTJIkla7MStjjgNtSSneklMaBTwAXl/h8XfHMs1aSzF6SJKlkZYawVcC9Tbfv\nK7ZN93MR8aOI+FREnNTqgSLi1RFxTURcs3HjxjLGOoWLtUqSpLL1ujH/s8DalNI5wBeBj7Q6KKX0\n/pTSeSml85YvX176oBLFYq2VaunPJUmSjk1lhrB1QHNla3WxbVJKaXNKaay4+UHgMSWOZ04qrhMm\nSZJKVGYIuxo4PSJOiYgB4BLgiuYDIuKEppsXATeVOJ6OZY1PXCdMkiSVpLSzI1NKtYi4DPgC/7+9\nO4+vorr/P/76JIBhCWsEBFSQaiFCCBCxQmRREaiUHVlFSflqcEW/+sMqaqVqoV9qLUK1iIAo3sgi\nRqvRgqLiQ2UJJgEJCsqlZRXCvglJzu+PO0kTuEASE29C38/H4z4yc2bmzJk5edx8cubMORAOzHLO\nfW1mE4HVzrm3gXvNrA+QDewFbiur8hSHwxuiQkGYiIiIlJEyC8IAnHPvAe+dkvZ4geXfAb8ryzKU\nhEbMFxERkbKmKCMIeA3k1AAAHWxJREFUZwrCREREpGwpyjgDBWEiIiJSlhRlBKER80VERKSsKQgL\nwuUNTaGWMBERESkjijKCCLSEObWEiYiISJlREBaE3o4UERGRsqYo4ww0TpiIiIiUJUUZQaglTERE\nRMqaoowgcvPGCdPckSIiIlJGFIQFoZYwERERKWuKMoJwmIIwERERKVOKMs5AQZiIiIiUJUUZQTjA\nnMYJExERkbKjICwIVz0qsNCwdWgLIiIiIuetSqEuQHnkIhtiF7WH8MqhLoqIiIicpxSEBeH+0zVf\nRESkkJMnT7J161aOHz8e6qJIORIREUGTJk2oXLnoDTgKwoJwzmHqDyYiIkFs3bqVyMhImjZtqr8V\nAgTihqysLLZu3UqzZs2KfJz6hJ2BWsJERCSY48ePU69ePQVgks/MqFevXrFbRxWEBaGWMBERORv9\njZBTleR3QkFYEOoTJiIiImVNQVgQuS5X/+WIiEi5lJWVRWxsLLGxsTRs2JDGjRvnr584caJIeYwe\nPZpvvvnmrPtMnz6defPmlUaRAdi1axeVKlVi5syZpZZnRaeO+WegljARESmP6tWrR1paGgC///3v\nqVGjBg8++GChfZxzOOcICwve1jJ79uxznueuu+766YUtYP78+VxzzTX4fD7GjBlTqnkXlJ2dTaVK\nFSO8qRil/JnpcaSIiBTFk+98zfrtB0s1z+hGNXniN1cW+7hNmzbRp08f2rZty1dffcWSJUt48skn\nWbNmDceOHWPIkCE8/vjjAMTHxzNt2jRatWpFVFQUiYmJpKSkUK1aNZKTk6lfvz4TJkwgKiqKcePG\nER8fT3x8PB999BEHDhxg9uzZdOzYkSNHjjBq1CgyMzOJjo7G7/czc+ZMYmNjTyufz+fj+eefZ9Cg\nQezYsYOLLroIgHfffZfHHnuMnJwcGjRowD//+U8OHTrE3XffzVdffQXAxIkT6d27N1FRUezfvx+A\npKQkli5dysyZMxk5ciSRkZGkpqbStWtXBgwYwP3338/x48epVq0ac+bM4fLLLyc7O5uHHnqIJUuW\nEBYWRmJiIr/4xS+YMWMGCxcuBCAlJYVZs2axYMGCEtVfcSgIC8I5h2IwERGpaDZs2MDcuXOJi4sD\nYNKkSdStW5fs7Gy6devGoEGDiI6OLnTMgQMH6NKlC5MmTeKBBx5g1qxZPPzww6fl7Zxj5cqVvP32\n20ycOJH333+f559/noYNG7Jo0SLS09Np165d0HL5/X727t1L+/btGTx4MPPnz+e+++5j586djB07\nluXLl3PppZeyd+9eINDCd+GFF5KRkYFzLj/wOpsdO3bw5ZdfEhYWxoEDB1i+fDmVKlXi/fffZ8KE\nCbzxxhu88MILbN++nfT0dMLDw9m7dy+1a9fm7rvvJisri3r16jF79mwSEhKKe+tLREFYEGoJExGR\noihJi1VZat68eX4ABoHWp5dffpns7Gy2b9/O+vXrTwvCqlatSq9evQBo3749y5cvD5r3gAED8vfx\n+/0AfPbZZ4wfPx6ANm3acOWVwe9HUlISQ4YMAWDo0KHceeed3HfffXzxxRd069aNSy+9FIC6desC\nsHTpUt566y0g8NZhnTp1yM7OPuu1Dx48OP/x6/79+xk1ahTfffddoX2WLl3KuHHjCA8PL3S+ESNG\n8PrrrzNixAhSU1Px+XxnPVdpURAWhIaoEBGRiqh69er5yxs3buSvf/0rK1eupHbt2owcOTLoOFZV\nqlTJXw4PDz9jsHPBBRecc58z8fl87Nmzh1deeQWA7du38/333xcrj7CwsMCTKs+p11Lw2h999FF6\n9OjBnXfeyaZNm+jZs+dZ805ISGDgwIEADBkyJD9IK2t6OzIItYSJiEhFd/DgQSIjI6lZsyY7duzg\ngw8+KPVzdOrUifnz5wOwdu1a1q9ff9o+69evJzs7m23btuH3+/H7/Tz00EMkJSXRsWNHli1bxpYt\nWwDyH0d2796d6dOnA4GGkX379hEWFkadOnXYuHEjubm5LF68+IzlOnDgAI0bNwZgzpw5+endu3fn\nxRdfJCcnp9D5Lr74YqKiopg0aRK33XbbT7spxaAg7AwUhImISEXWrl07oqOjadGiBaNGjaJTp06l\nfo577rmHbdu2ER0dzZNPPkl0dDS1atUqtI/P56N///6F0gYOHIjP56NBgwa88MIL9O3blzZt2jBi\nxAgAnnjiCXbt2kWrVq2IjY3Nf0Q6efJkevToQceOHWnSpMkZyzV+/Hgeeugh2rVrV6j17I477qBh\nw4bExMTQpk2b/AASYPjw4TRr1owrrrjiJ9+XorKChasI4uLi3OrVq8v0HD0W9iCuYRxPxz9dpucR\nEZGKJzMzk5YtW4a6GOVCdnY22dnZREREsHHjRm688UY2btxYYYaIKCgxMZFrrrmGW2+9tcR5BPvd\nMLNU51xcsP0r3l36GTgqVmAqIiISCocPH+b6668nOzsb5xx///vfK2QAFhsbS506dZg6derPet6K\nd6d+BuoTJiIicm61a9cmNTU11MX4yfIGv/25qU9YEM45wky3RkRERMqOIo0gNESFiIiIlDUFYUHo\ncaSIiIiUNQVhQahjvoiIiJQ1BWFB6HGkiIiUV926dTtt4NXnnnuOsWPHnvW4GjVqAIHR6gcNGhR0\nn65du3KuYaCee+45jh49mr/+61//ukhzOxZVbGwsQ4cOLbX8yjMFYUHocaSIiJRXw4YNIykpqVBa\nUlISw4YNK9LxjRo1YuHChSU+/6lB2HvvvUft2rVLnF9BmZmZ5OTksHz5co4cOVIqeQZT3GmXyoqG\nqAjiZM5JLgi/INTFEBGR8i7lYdi5tnTzbNgaek064+ZBgwYxYcIETpw4QZUqVfD7/Wzfvp1rr72W\nw4cP07dvX/bt28fJkyd56qmn6Nu3b6Hj/X4/vXv3Zt26dRw7dozRo0eTnp5OixYtOHbsWP5+Y8eO\nZdWqVRw7doxBgwbx5JNPMnXqVLZv3063bt2Iiopi2bJlNG3alNWrVxMVFcWzzz7LrFmzABgzZgzj\nxo3D7/fTq1cv4uPj+fzzz2ncuDHJyclUrVr1tGvz+XzccsstZGZmkpyczPDhwwHYtGkTiYmJ7N69\nm/DwcBYsWEDz5s2ZPHkyr732GmFhYfTq1YtJkybRtWtXpkyZQlxcHHv27CEuLg6/38+cOXN48803\nOXz4MDk5Obz77rtnvFdz585lypQpmBkxMTH87W9/IyYmhm+//ZbKlStz8OBB2rRpk79eUgrCgvgx\n50eqhFc5944iIiI/s7p169KhQwdSUlLo27cvSUlJ3HzzzZgZERERLF68mJo1a7Jnzx5+9atf0adP\nnzN2sXnhhReoVq0amZmZZGRk0K5du/xtTz/9NHXr1iUnJ4frr7+ejIwM7r33Xp599lmWLVtGVFRU\nobxSU1OZPXs2K1aswDnH1VdfTZcuXfLne/T5fLz00kvcfPPNLFq0iJEjR55WnjfeeIMlS5awYcMG\nnn/++fwgbMSIETz88MP079+f48ePk5ubS0pKCsnJyaxYsYJq1arlzwN5NmvWrCEjI4O6deuSnZ0d\n9F6tX7+ep556is8//5yoqCj27t1LZGQkXbt25d1336Vfv34kJSUxYMCAnxSAgYKw0zjnOJF7Qi1h\nIiJybmdpsSpLeY8k84Kwl19+GQj8DXvkkUf49NNPCQsLY9u2bezatYuGDRsGzefTTz/l3nvvBSAm\nJoaYmJj8bfPnz2fGjBlkZ2ezY8cO1q9fX2j7qT777DP69+9P9erVARgwYADLly+nT58+NGvWjNjY\nWADat2+P3+8/7fi81rRLLrmExo0bk5CQwN69e6lcuTLbtm3Ln38yIiICgKVLlzJ69GiqVasGBILT\nc+nevXv+fme6Vx999BGDBw/ODzLz9h8zZgx/+tOf6NevH7Nnz+all1465/nORX3CTnEi9wSAWsJE\nRKTc6tu3Lx9++CFr1qzh6NGjtG/fHoB58+axe/duUlNTSUtLo0GDBhw/frzY+W/evJkpU6bw4Ycf\nkpGRwU033VSifPJccMF/GjbCw8OD9sny+Xxs2LCBpk2b0rx5cw4ePMiiRYuKfa5KlSqRm5sLcFqZ\n8wJEKP696tSpE36/n48//picnBxatWpV7LKdSkHYKX7M+RFALWEiIlJu1ahRg27dupGQkFCoQ/6B\nAweoX78+lStXZtmyZWzZsuWs+XTu3JnXX38dgHXr1pGRkQHAwYMHqV69OrVq1WLXrl2kpKTkHxMZ\nGcmhQ4dOy+vaa6/lrbfe4ujRoxw5coTFixdz7bXXFul6cnNzmT9/PmvXrsXv9+P3+0lOTsbn8xEZ\nGUmTJk146623APjxxx85evQo3bt3Z/bs2fkvCeQ9jmzatGn+VEpnewHhTPfquuuuY8GCBWRlZRXK\nF2DUqFEMHz6c0aNHF+m6zkVB2CnW7FoDKAgTEZHybdiwYaSnpxcKwkaMGMHq1atp3bo1c+fOpUWL\nFmfNY+zYsRw+fJiWLVvy+OOP57eotWnThrZt29KiRQuGDx9Op06d8o+5/fbb6dmzJ926dSuUV7t2\n7bjtttvo0KEDV199NWPGjKFt27ZFupbly5fTuHFjGjVqlJ/WuXNn1q9fz44dO3j11VeZOnUqMTEx\ndOzYkZ07d9KzZ0/69OlDXFwcsbGxTJkyBYAHH3yQF154gbZt27Jnz54znvNM9+rKK6/k0UcfpUuX\nLrRp04YHHnig0DH79u0r8puo52LOVayBSePi4ty5xjD5Kb7Y/gVTVk/hD53+QHS96DI7j4iIVEyZ\nmZm0bNky1MWQEFi4cCHJycm8+uqrQbcH+90ws1TnXFyw/dUx/xTXNLqGRX2K/wxaREREzl/33HMP\nKSkpvPfee6WWp4IwERERkXN4/vnnSz1P9QkTERERCQEFYSIiIiIhoCBMREREJAQUhImIiIiEgIIw\nERGRCiQrK4vY2FhiY2Np2LAhjRs3zl8/ceJEkfOZNWsWO3fuzF8fPXo033zzTamVc+HChZgZmzZt\nKrU8zzcKwkRERCqQevXqkZaWRlpaGomJidx///3561WqFH3KvVODsNmzZ/PLX/6y1Mrp8/mIj4/H\n5/OVWp7BBJsCqaLQEBUiIiIlNHnlZDbs3VCqebao24LxHcaX6NhXXnmF6dOnc+LECTp27Mi0adPI\nzc1l9OjRpKWl4Zzj9ttvp0GDBqSlpTFkyBCqVq3KypUrue6665g2bRqtWrUiKiqKxMREUlJSqFat\nGsnJydSvX5+NGzcycuRIjh49Sp8+fZg+fTr79+8/rRwHDx5kxYoVLF26lIEDB/LYY4/lb3vmmWfw\n+XyEhYXRu3dvnn76ab799lsSExPJysoiPDycN998k02bNjFt2rT86YoSExOJj49n5MiRNGnShJEj\nR/LBBx/wyCOPkJWVxcsvv8yJEye44oormDt3LlWrVmXnzp3ccccdbN68GTNjxowZJCcn06hRI+6+\n+24Axo8fzyWXXMJdd91Vonv+U6glTERE5Dywbt06Fi9ezOeff05aWhrZ2dkkJSWRmprKnj17WLt2\nLevWrWPUqFEMGTKE2NhY3njjjaAtaAcOHKBLly6kp6dzzTXXMGvWLCAwYOmDDz7I2rVrueiii85Y\nlsWLF3PTTTfRokULqlevTnp6OgDvvPMOKSkprFy5kvT0dP73f/8XCEzBdP/995Oens7nn39O/fr1\nz3m99evX56uvvmLw4MEMHjyYVatWkZ6eTvPmzZkzZw4Ad911F927dycjI4PU1FRatmxJQkICr7zy\nCgA5OTksWLCA4cOHF/t+lwa1hImIiJRQSVusysLSpUtZtWoVcXGBGXKOHTvGxRdfTI8ePfjmm2+4\n9957uemmm7jxxhvPmVfVqlXp1asXAO3bt2f58uUArFixIn/E+OHDhzNhwoSgx/t8PsaPD9yboUOH\n4vP5aNOmDUuXLiUhIYGqVasCULduXfbt28eePXv4zW9+A0BERESRrnfIkCH5yxkZGTz++OPs37+f\nQ4cO0bt3bwA+/vhjkpKSAKhUqRI1a9akZs2aREZGsnbtWrZs2UKHDh2oU6dOkc5Z2hSEiYiInAec\ncyQkJPCHP/zhtG0ZGRmkpKQwffp0Fi1axIwZM86aV8GWsfDw8GL1u9q9ezeffPIJmZmZmBnZ2dlU\nrlyZP/7xj0W/GAJBU25ubv768ePHC22vXr16/vKoUaNISUmhVatWzJw5ky+//DJ/m5mdlvdvf/tb\n5syZg9/v54477ihWuUqTHkeKiIicB2644Qbmz5/Pnj17gMBblP/617/YvXs3zjkGDx7MxIkTWbNm\nDQCRkZEcOnSoWOfo0KEDixcvBshvYTrVggULSEhIYMuWLfj9frZu3UqjRo344osv6N69O7NmzeLY\nsWMA7N27lzp16nDhhRfyzjvvAIFg6+jRo1x66aV8/fXXnDhxgn379vHRRx+dsVxHjhyhYcOGnDx5\nktdffz0/vVu3brz44otA4NHjwYMHARg4cCDvvPMOaWlp3HDDDcW6B6VJQZiIiMh5oHXr1jzxxBPc\ncMMNxMTEcOONN7Jr1y7+/e9/07lzZ2JjYxk9ejTPPPMMEBiSYsyYMcUa2mLq1KlMnjyZmJgYNm/e\nTK1atU7bx+fz0b9//0JpAwcOxOfz0bt3b3r27ElcXByxsbH85S9/AWDevHn8+c9/JiYmhvj4eHbv\n3k2zZs3o168fV155JUOHDqVdu3ZnLNfEiRO56qqr6NSpE9HR0fnp06ZN44MPPqB169bExcWxYUPg\nJYqIiAg6d+7MsGHDCAsLXShkzrmQnbwk4uLi3OrVq0NdDBER+S+VmZlJy5YtQ12MkDhy5AjVqlXD\nzHjttddYvHgxixYtCnWxii03N5fY2FjeeustLrvsslLLN9jvhpmlOufigu2vPmEiIiJSJKtWrWLc\nuHHk5uZSp04dZs+eHeoiFdvatWvp06cPgwcPLtUArCQUhImIiEiRdO3albS0tFAX4ydp3bo1mzdv\nDnUxAPUJExERKbaK1pVHyl5JficUhImIiBRDREQEWVlZCsQkn3OOrKysIo9xlkePI0VERIqhSZMm\nbN26ld27d4e6KFKORERE0KRJk2IdoyBMRESkGCpXrkyzZs1CXQw5D+hxpIiIiEgIKAgTERERCQEF\nYSIiIiIhUOFGzDez3cCWMj5NFLCnjM8hxad6KX9UJ+WT6qX8UZ2UTz9HvVzqnLsw2IYKF4T9HMxs\n9ZmmGJDQUb2UP6qT8kn1Uv6oTsqnUNeLHkeKiIiIhICCMBEREZEQUBAW3IxQF0CCUr2UP6qT8kn1\nUv6oTsqnkNaL+oSJiIiIhIBawkRERERCQEGYiIiISAgoCDuFmfU0s2/MbJOZPRzq8pzPzGyWmf1g\nZusKpNU1syVmttH7WcdLNzOb6tVLhpm1K3DMrd7+G83s1lBcy/nEzC42s2Vmtt7Mvjaz+7x01U2I\nmFmEma00s3SvTp700puZ2Qrv3r9hZlW89Au89U3e9qYF8vqdl/6NmfUIzRWdP8ws3My+MrN/eOuq\nkxAzM7+ZrTWzNDNb7aWVz+8v55w+3gcIB74DLgOqAOlAdKjLdb5+gM5AO2BdgbQ/AQ97yw8Dk73l\nXwMpgAG/AlZ46XWB772fdbzlOqG+tor8AS4C2nnLkcC3QLTqJqR1YkANb7kysMK71/OBoV76i8BY\nb/lO4EVveSjwhrcc7X2vXQA0877vwkN9fRX5AzwAvA78w1tXnYS+TvxA1Clp5fL7Sy1hhXUANjnn\nvnfOnQCSgL4hLtN5yzn3KbD3lOS+wCve8itAvwLpc13Al0BtM7sI6AEscc7tdc7tA5YAPcu+9Ocv\n59wO59wab/kQkAk0RnUTMt69PeytVvY+DrgOWOiln1oneXW1ELjezMxLT3LO/eic2wxsIvC9JyVg\nZk2Am4CZ3rqhOimvyuX3l4KwwhoD/y6wvtVLk59PA+fcDm95J9DAWz5T3ajOypD3yKQtgZYX1U0I\neY+90oAfCPxB+A7Y75zL9nYpeH/z7723/QBQD9VJaXsO+H9ArrdeD9VJeeCAf5pZqpnd7qWVy++v\nSqWdoUhpcc45M9MYKiFiZjWARcA459zBwD/tAaqbn59zLgeINbPawGKgRYiL9F/NzHoDPzjnUs2s\na6jLI4XEO+e2mVl9YImZbSi4sTx9f6klrLBtwMUF1pt4afLz2eU1BeP9/MFLP1PdqM7KgJlVJhCA\nzXPOveklq27KAefcfmAZcA2BRyd5/0wXvL/5997bXgvIQnVSmjoBfczMT6DrynXAX1GdhJxzbpv3\n8wcC/7B0oJx+fykIK2wVcLn3dksVAp0n3w5xmf7bvA3kvYVyK5BcIH2U9ybLr4ADXtPyB8CNZlbH\ne9vlRi9NSsjrp/IykOmce7bAJtVNiJjZhV4LGGZWFehOoK/eMmCQt9updZJXV4OAj1ygt/HbwFDv\nTb1mwOXAyp/nKs4vzrnfOeeaOOeaEvhb8ZFzbgSqk5Ays+pmFpm3TOB7Zx3l9fsr1G8xlLcPgTcl\nviXQ3+LRUJfnfP4APmAHcJLA8/bfEugj8SGwEVgK1PX2NWC6Vy9rgbgC+SQQ6My6CRgd6uuq6B8g\nnkCfigwgzfv8WnUT0jqJAb7y6mQd8LiXfhmBP9ibgAXABV56hLe+ydt+WYG8HvXq6hugV6iv7Xz4\nAF35z9uRqpPQ1sVlBN42TQe+zvs7Xl6/vzRtkYiIiEgI6HGkiIiISAgoCBMREREJAQVhIiIiIiGg\nIExEREQkBBSEiYiIiISAgjARKXVm5szszwXWHzSz35dS3nPMbNC59/zJ5xlsZplmtuyU9KZmdszM\n0gp8RpXiebua2T9KKz8RKb80bZGIlIUfgQFm9kfn3J5QFyaPmVVy/5nX71x+C/yPc+6zINu+c87F\nlmLRROS/kFrCRKQsZAMzgPtP3XBqS5aZHfZ+djWzT8ws2cy+N7NJZjbCzFaa2Voza14gmxvMbLWZ\nfevN4Zc3wfX/mdkqM8swszsK5LvczN4G1gcpzzAv/3VmNtlLe5zAoLUvm9n/FfWizeywmf3FzL42\nsw/N7EIvPdbMvvTKtdgbgRsz+4WZLTWzdDNbU+Aaa5jZQjPbYGbzvFkM8O7Jei+fKUUtl4iUTwrC\nRKSsTAdGmFmtYhzTBkgEWgK3AFc45zoAM4F7CuzXlMB8cDcBL5pZBIGWqwPOuauAq4D/8aaBAWgH\n3Oecu6LgycysETCZwLx/scBVZtbPOTcRWA2McM49FKSczU95HHmtl14dWO2cuxL4BHjCS58LjHfO\nxRAYlTsvfR4w3TnXBuhIYAYJgLbAOCCawAjgncysHtAfuNLL56lz3UwRKd8UhIlImXDOHSQQfNxb\njMNWOed2OOd+JDCNyD+99LUEAq88851zuc65jcD3QAsCc7uNMrM0YAWBaUou9/Zf6ZzbHOR8VwEf\nO+d2e48p5wGdi1DO75xzsQU+y730XOANb/k1IN4LQms75z7x0l8BOnvz2zV2zi0GcM4dd84dLVDe\nrc65XALTRjUFDgDHCbTODQDy9hWRCkpBmIiUpecItFBVL5CWjffdY2ZhQJUC234ssJxbYD2Xwn1Y\nT51vzRGYA+6eAoFRM+dcXhB35CddRcmVdF64gvchB8jry9YBWAj0Bt7/iWUTkRBTECYiZcY5txeY\nTyAQy+MH2nvLfYDKJch6sJmFeX2oLiMw8fEHwFgzqwxgZleYWfWzZUJgIuUuZhZlZuHAMAKPEUsq\nDMjr7zYc+Mw5dwDYV+CR5S3AJ865Q8BWM+vnlfcCM6t2pozNrAZQyzn3HoG+dm1+QjlFpBzQ25Ei\nUtb+DNxdYP0lINnM0gm05pSklepfBAKomkCic+64mc0k8NhujdeRfTfQ72yZOOd2mNnDwDICLWnv\nOueSi3D+5t5jzzyznHNTCVxLBzObAPwADPG230qg71o1Ao9PR3vptwB/N7OJwElg8FnOGUngvkV4\nZX2gCOUUkXLMnCtpa7mIiBRkZoedczVCXQ4RqRj0OFJEREQkBNQSJiIiIhICagkTERERCQEFYSIi\nIiIhoCBMREREJAQUhImIiIiEgIIwERERkRD4//u/hIQ3M1PVAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4q7nFHubVOE",
        "colab_type": "code",
        "outputId": "e9aa2ba9-ecd4-419a-95c8-eab2ef429a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        }
      },
      "source": [
        "plotting_loss(epochs, training_error[2], validation_error[2], testing_error[2],\"MSE Losses of BGD w/ Regularization of 0.5 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/transforms.py:2832: RuntimeWarning: overflow encountered in double_scalars\n",
            "  elif vmax - vmin <= maxabsvalue * tiny:\n",
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:2477: RuntimeWarning: overflow encountered in double_scalars\n",
            "  delta = (x1t - x0t) * margin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAJcCAYAAAB5fZnuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSVJn/h8oNM7P/QWkrQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCvuSM73c1oH",
        "colab_type": "code",
        "outputId": "78e0de92-f980-4706-ecfa-0e5ad6b7b0ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "plotting_accuracy(epochs, training_accuracy[2], validation_accuracy[2], testing_accuracy[2], \"Accuracy of BGD w/ Regularization of 0.5 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py:2483: RuntimeWarning: overflow encountered in double_scalars\n",
            "  x0t -= delta\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAJcCAYAAAB5fZnuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6iUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcOClE2gev2b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normal_equation(x,y):\n",
        "    init_t = time.time()\n",
        "    x = np.insert(x, 0, 1, axis=1)\n",
        "    W_opt = (np.linalg.inv(np.dot(x.transpose(),x))).dot(x.transpose()).dot(y)\n",
        "    final_t = time.time()\n",
        "    print(\"Time: \", final_t - init_t)\n",
        "    return [W_opt[1:], W_opt[0]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcNDpycLfn9R",
        "colab_type": "code",
        "outputId": "5cca3903-a79d-4f32-f906-3ce690a00235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "[W_optimal, b] = normal_equation(trainData, trainTarget)\n",
        "reg = 0.5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time:  0.36717939376831055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLhrzjk8XGXM",
        "colab_type": "code",
        "outputId": "1d6552f6-5e95-418c-e919-d44caa8887f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Normal Equation Training MSE: \", MSE(W_optimal.transpose(), b, trainData, trainTarget, reg))\n",
        "print(\"Normal Equation Training Accuracy: \", accuracy(W_optimal.transpose(), b, trainData, trainTarget))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Equation Training MSE:  3.0501595221812434\n",
            "Normal Equation Training Accuracy:  0.9937142857142857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrkenaU-Xrwz",
        "colab_type": "code",
        "outputId": "6ce8cd00-d79e-40f8-def5-71ca7baf501a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Normal Equation Validation MSE: \", MSE(W_optimal.transpose(), b, validData, validTarget, reg))\n",
        "print(\"Normal Equation Validation Accuracy: \", accuracy(W_optimal.transpose(), b, validData, validTarget))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Equation Validation MSE:  3.079015902689379\n",
            "Normal Equation Validation Accuracy:  0.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SoHkoVRX4eW",
        "colab_type": "code",
        "outputId": "729572c3-f349-4756-884e-c917680ec385",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Normal Equation Testing MSE: \", MSE(W_optimal.transpose(), b, testData, testTarget, reg))\n",
        "print(\"Normal Equation Testing Accuracy: \", accuracy(W_optimal.transpose(), b, testData, testTarget))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Normal Equation Testing MSE:  3.088434914221085\n",
            "Normal Equation Testing Accuracy:  0.9448275862068966\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GNgilAtcSeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}