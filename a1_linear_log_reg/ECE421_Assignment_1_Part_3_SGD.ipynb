{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECE421 Assignment 1 Part 3 SGD",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3aGqcnC_OH3",
        "colab_type": "code",
        "outputId": "2967dcf9-2504-4936-c9f5-5a6293712a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNyfdJBe_jk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadData():\n",
        "    with np.load('notMNIST.npz') as data :\n",
        "        Data, Target = data ['images'], data['labels']\n",
        "        posClass = 2\n",
        "        negClass = 9\n",
        "        dataIndx = (Target==posClass) + (Target==negClass)\n",
        "        Data = Data[dataIndx]/255.\n",
        "        Target = Target[dataIndx].reshape(-1, 1)\n",
        "        Target[Target==posClass] = 1\n",
        "        Target[Target==negClass] = 0\n",
        "        np.random.seed(421)\n",
        "        randIndx = np.arange(len(Data))\n",
        "        np.random.shuffle(randIndx)\n",
        "        Data, Target = Data[randIndx], Target[randIndx]\n",
        "        trainData, trainTarget = Data[:3500], Target[:3500]\n",
        "        validData, validTarget = Data[3500:3600], Target[3500:3600]\n",
        "        testData, testTarget = Data[3600:], Target[3600:]\n",
        "    return trainData, validData, testData, trainTarget, validTarget, testTarget"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsdx4LXbBX_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainData, validData, testData, trainTarget, validTarget, testTarget = loadData()\n",
        "trainData = trainData.reshape(3500,784)\n",
        "validData = validData.reshape(100,784)\n",
        "testData = testData.reshape(145,784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYlaUfKDMszr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracySGD(predictions, labels):\n",
        "    return (np.sum((predictions>=0.5)==labels) / np.shape(predictions)[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvFarzwlhK8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 700\n",
        "batch_size = 500\n",
        "l_r = 0.001\n",
        "b1 = None\n",
        "b2 = None\n",
        "e = 10e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jL5mQnfWcqmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def buildGraph(beta1 = None, beta2 = None, epsilon = None, lossType=None, learning_rate = None):\n",
        "    num_batches = int(3500/batch_size)\n",
        "    lbda = 0\n",
        "    graph = tf.Graph()\n",
        "  \n",
        "    with graph.as_default():\n",
        "        W = tf.truncated_normal(shape=(784, 1), mean=0.0, stddev=0.5, dtype=tf.float32)\n",
        "        W = tf.Variable(W)\n",
        "        b = tf.zeros(1)\n",
        "        b = tf.Variable(b)\n",
        "\n",
        "        x = tf.placeholder(tf.float32, shape=(batch_size, 784))\n",
        "        y = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
        "\n",
        "        v_x = tf.placeholder(tf.float32, shape=(len(validData), 784))\n",
        "        v_y = tf.placeholder(tf.int8, shape=(len(validTarget), 1))\n",
        "\n",
        "        t_x = tf.placeholder(tf.float32, shape=(len(testData), 784))\n",
        "        t_y = tf.placeholder(tf.int8, shape=(len(testTarget), 1))\n",
        "\n",
        "        tf.set_random_seed(421)\n",
        "\n",
        "        if lossType == \"MSE\":\n",
        "            z = tf.matmul(x,W) + b\n",
        "            loss = tf.losses.mean_squared_error(y, z)\n",
        "            reg = tf.nn.l2_loss(W)\n",
        "            loss += (lbda/2.0)*reg\n",
        "\n",
        "            v_z = tf.matmul(v_x,W) + b\n",
        "            vloss = tf.losses.mean_squared_error(v_y, v_z)\n",
        "            vloss += (lbda/2.0)*reg\n",
        "\n",
        "            t_z = tf.matmul(t_x,W) + b\n",
        "            tloss = tf.losses.mean_squared_error(t_y, t_z)\n",
        "            tloss += (lbda/2.0)*reg\n",
        "\n",
        "            optimizer = tf.train.AdamOptimizer(learning_rate = 0.001, beta1 = 0.95).minimize(loss)\n",
        "\n",
        "        elif lossType == \"CE\":\n",
        "            z = tf.sigmoid(tf.matmul(x,W) + b)\n",
        "            loss = tf.losses.sigmoid_cross_entropy(y, z)\n",
        "            reg = tf.nn.l2_loss(W)\n",
        "            loss += (lbda/2.0)*reg\n",
        "\n",
        "            v_z = tf.sigmoid(tf.matmul(v_x,W) + b)\n",
        "            vloss = tf.losses.sigmoid_cross_entropy(v_y, v_z)\n",
        "            vloss += (lbda/2.0)*reg\n",
        "\n",
        "            t_z = tf.sigmoid(tf.matmul(t_x,W) + b)\n",
        "            tloss = tf.losses.sigmoid_cross_entropy(t_y, t_z)\n",
        "            tloss += (lbda/2.0)*reg\n",
        "\n",
        "            optimizer = tf.train.AdamOptimizer(learning_rate = 0.001, epsilon = 1e-04).minimize(loss)\n",
        "\n",
        "        with tf.Session(graph=graph) as session:\n",
        "            tf.global_variables_initializer().run()\n",
        "            training_loss = []\n",
        "            validation_loss = []\n",
        "            testing_loss = []\n",
        "            training_accuracy = []\n",
        "            validation_accuracy = []\n",
        "            testing_accuracy = []\n",
        "            for epoch in range(epochs):\n",
        "                total_loss = 0\n",
        "                for n in range(num_batches):\n",
        "                    x_batch = trainData[n*batch_size:(n+1)*batch_size,]\n",
        "                    y_batch = trainTarget[n*batch_size:(n+1)*batch_size,]\n",
        "                    _, opt_W, opt_b, train_loss, pred, v_loss, v_pred, t_loss, t_pred = session.run([optimizer, W, b, loss, z, vloss, v_z, tloss, t_z], \n",
        "                                                                                                                      {x: x_batch, \n",
        "                                                                                                                       y: y_batch,\n",
        "                                                                                                                       v_x: validData,\n",
        "                                                                                                                       v_y: validTarget,\n",
        "                                                                                                                         t_x: testData,\n",
        "                                                                                                                       t_y: testTarget})\n",
        "                if (n % 1 == 0):\n",
        "                    training_loss += [train_loss]\n",
        "                    t_accuracy = accuracySGD(pred, y_batch)\n",
        "                    training_accuracy += [t_accuracy]\n",
        "                    validation_loss += [v_loss]\n",
        "                    v_accuracy = accuracySGD(v_pred, validTarget)\n",
        "                    validation_accuracy += [v_accuracy]\n",
        "                    testing_loss += [t_loss]\n",
        "                    t_accuracy = accuracySGD(t_pred, testTarget)\n",
        "                    testing_accuracy += [t_accuracy]\n",
        "\n",
        "                    print('Epoch: {}, Training Loss: {}, Training Accuracy: {}'.format(epoch, train_loss, t_accuracy))\n",
        "                    print('Epoch: {}, Validation Loss: {}, Validation Accuracy: {}'.format(epoch, v_loss, v_accuracy))\n",
        "                    print('Epoch: {}, Testing Loss: {}, Testing Accuracy: {}'.format(epoch, t_loss, t_accuracy))\n",
        "\n",
        "    # Your implementation here\n",
        "    return opt_W, opt_b, (pred>=0.5), trainTarget, train_loss, optimizer, reg, training_loss, training_accuracy, validation_loss, validation_accuracy, testing_loss, testing_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BJoNhAxdEhE",
        "colab_type": "code",
        "outputId": "ba034e04-a421-4498-e9c0-ebeea4f6903c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "opt_W, opt_b, pred, trainTarget, train_loss, optimizer, reg, training_loss, training_accuracy, validation_loss, validation_accuracy, testing_loss, testing_accuracy = buildGraph(lossType = \"CE\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Training Loss: 0.7045921087265015, Training Accuracy: 0.5310344827586206\n",
            "Epoch: 0, Validation Loss: 0.7427818179130554, Validation Accuracy: 0.61\n",
            "Epoch: 0, Testing Loss: 0.8024340271949768, Testing Accuracy: 0.5310344827586206\n",
            "Epoch: 1, Training Loss: 0.6750874519348145, Training Accuracy: 0.5862068965517241\n",
            "Epoch: 1, Validation Loss: 0.7146576046943665, Validation Accuracy: 0.6\n",
            "Epoch: 1, Testing Loss: 0.7543880343437195, Testing Accuracy: 0.5862068965517241\n",
            "Epoch: 2, Training Loss: 0.6443548798561096, Training Accuracy: 0.6827586206896552\n",
            "Epoch: 2, Validation Loss: 0.6718742251396179, Validation Accuracy: 0.69\n",
            "Epoch: 2, Testing Loss: 0.7034984827041626, Testing Accuracy: 0.6827586206896552\n",
            "Epoch: 3, Training Loss: 0.6148713231086731, Training Accuracy: 0.7310344827586207\n",
            "Epoch: 3, Validation Loss: 0.6342689394950867, Validation Accuracy: 0.77\n",
            "Epoch: 3, Testing Loss: 0.6609775424003601, Testing Accuracy: 0.7310344827586207\n",
            "Epoch: 4, Training Loss: 0.587871789932251, Training Accuracy: 0.8482758620689655\n",
            "Epoch: 4, Validation Loss: 0.6028596758842468, Validation Accuracy: 0.82\n",
            "Epoch: 4, Testing Loss: 0.6255592107772827, Testing Accuracy: 0.8482758620689655\n",
            "Epoch: 5, Training Loss: 0.5688042640686035, Training Accuracy: 0.8689655172413793\n",
            "Epoch: 5, Validation Loss: 0.5840269327163696, Validation Accuracy: 0.84\n",
            "Epoch: 5, Testing Loss: 0.6011978983879089, Testing Accuracy: 0.8689655172413793\n",
            "Epoch: 6, Training Loss: 0.5577885508537292, Training Accuracy: 0.8827586206896552\n",
            "Epoch: 6, Validation Loss: 0.5746817588806152, Validation Accuracy: 0.83\n",
            "Epoch: 6, Testing Loss: 0.5881578922271729, Testing Accuracy: 0.8827586206896552\n",
            "Epoch: 7, Training Loss: 0.549842894077301, Training Accuracy: 0.8827586206896552\n",
            "Epoch: 7, Validation Loss: 0.5675343871116638, Validation Accuracy: 0.86\n",
            "Epoch: 7, Testing Loss: 0.5792419910430908, Testing Accuracy: 0.8827586206896552\n",
            "Epoch: 8, Training Loss: 0.5438215136528015, Training Accuracy: 0.9172413793103448\n",
            "Epoch: 8, Validation Loss: 0.5615518689155579, Validation Accuracy: 0.87\n",
            "Epoch: 8, Testing Loss: 0.5722835659980774, Testing Accuracy: 0.9172413793103448\n",
            "Epoch: 9, Training Loss: 0.539613664150238, Training Accuracy: 0.9172413793103448\n",
            "Epoch: 9, Validation Loss: 0.5566707849502563, Validation Accuracy: 0.88\n",
            "Epoch: 9, Testing Loss: 0.5671429634094238, Testing Accuracy: 0.9172413793103448\n",
            "Epoch: 10, Training Loss: 0.5367417335510254, Training Accuracy: 0.9241379310344827\n",
            "Epoch: 10, Validation Loss: 0.5525670051574707, Validation Accuracy: 0.89\n",
            "Epoch: 10, Testing Loss: 0.5632632374763489, Testing Accuracy: 0.9241379310344827\n",
            "Epoch: 11, Training Loss: 0.5346720218658447, Training Accuracy: 0.9310344827586207\n",
            "Epoch: 11, Validation Loss: 0.5490301251411438, Validation Accuracy: 0.9\n",
            "Epoch: 11, Testing Loss: 0.5602744221687317, Testing Accuracy: 0.9310344827586207\n",
            "Epoch: 12, Training Loss: 0.533039391040802, Training Accuracy: 0.9517241379310345\n",
            "Epoch: 12, Validation Loss: 0.5459943413734436, Validation Accuracy: 0.91\n",
            "Epoch: 12, Testing Loss: 0.558007001876831, Testing Accuracy: 0.9517241379310345\n",
            "Epoch: 13, Training Loss: 0.5316546559333801, Training Accuracy: 0.9517241379310345\n",
            "Epoch: 13, Validation Loss: 0.543403685092926, Validation Accuracy: 0.93\n",
            "Epoch: 13, Testing Loss: 0.5562639832496643, Testing Accuracy: 0.9517241379310345\n",
            "Epoch: 14, Training Loss: 0.530432939529419, Training Accuracy: 0.9517241379310345\n",
            "Epoch: 14, Validation Loss: 0.5411831140518188, Validation Accuracy: 0.93\n",
            "Epoch: 14, Testing Loss: 0.5548698306083679, Testing Accuracy: 0.9517241379310345\n",
            "Epoch: 15, Training Loss: 0.5293346047401428, Training Accuracy: 0.9517241379310345\n",
            "Epoch: 15, Validation Loss: 0.5392622351646423, Validation Accuracy: 0.94\n",
            "Epoch: 15, Testing Loss: 0.5537075996398926, Testing Accuracy: 0.9517241379310345\n",
            "Epoch: 16, Training Loss: 0.5283380746841431, Training Accuracy: 0.9517241379310345\n",
            "Epoch: 16, Validation Loss: 0.5375865697860718, Validation Accuracy: 0.94\n",
            "Epoch: 16, Testing Loss: 0.5527063608169556, Testing Accuracy: 0.9517241379310345\n",
            "Epoch: 17, Training Loss: 0.5274294018745422, Training Accuracy: 0.9517241379310345\n",
            "Epoch: 17, Validation Loss: 0.5361155867576599, Validation Accuracy: 0.94\n",
            "Epoch: 17, Testing Loss: 0.5518212914466858, Testing Accuracy: 0.9517241379310345\n",
            "Epoch: 18, Training Loss: 0.5265987515449524, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 18, Validation Loss: 0.5348178148269653, Validation Accuracy: 0.94\n",
            "Epoch: 18, Testing Loss: 0.5510223507881165, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 19, Training Loss: 0.5258389115333557, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 19, Validation Loss: 0.5336669683456421, Validation Accuracy: 0.95\n",
            "Epoch: 19, Testing Loss: 0.5502886772155762, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 20, Training Loss: 0.5251432657241821, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 20, Validation Loss: 0.532640814781189, Validation Accuracy: 0.95\n",
            "Epoch: 20, Testing Loss: 0.5496052503585815, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 21, Training Loss: 0.5245056748390198, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 21, Validation Loss: 0.5317203998565674, Validation Accuracy: 0.96\n",
            "Epoch: 21, Testing Loss: 0.5489617586135864, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 22, Training Loss: 0.5239201188087463, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 22, Validation Loss: 0.5308895707130432, Validation Accuracy: 0.96\n",
            "Epoch: 22, Testing Loss: 0.5483511686325073, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 23, Training Loss: 0.5233809351921082, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 23, Validation Loss: 0.530134916305542, Validation Accuracy: 0.96\n",
            "Epoch: 23, Testing Loss: 0.5477691888809204, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 24, Training Loss: 0.5228824019432068, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 24, Validation Loss: 0.5294457077980042, Validation Accuracy: 0.96\n",
            "Epoch: 24, Testing Loss: 0.5472131371498108, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 25, Training Loss: 0.5224194526672363, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 25, Validation Loss: 0.5288129448890686, Validation Accuracy: 0.96\n",
            "Epoch: 25, Testing Loss: 0.5466813445091248, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 26, Training Loss: 0.5219871997833252, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 26, Validation Loss: 0.5282294750213623, Validation Accuracy: 0.96\n",
            "Epoch: 26, Testing Loss: 0.5461726784706116, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 27, Training Loss: 0.52158123254776, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 27, Validation Loss: 0.5276891589164734, Validation Accuracy: 0.96\n",
            "Epoch: 27, Testing Loss: 0.5456865429878235, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 28, Training Loss: 0.5211977362632751, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 28, Validation Loss: 0.5271861553192139, Validation Accuracy: 0.96\n",
            "Epoch: 28, Testing Loss: 0.5451512932777405, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 29, Training Loss: 0.5208333730697632, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 29, Validation Loss: 0.5267180800437927, Validation Accuracy: 0.96\n",
            "Epoch: 29, Testing Loss: 0.5447794795036316, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 30, Training Loss: 0.5204852819442749, Training Accuracy: 0.9586206896551724\n",
            "Epoch: 30, Validation Loss: 0.526279091835022, Validation Accuracy: 0.96\n",
            "Epoch: 30, Testing Loss: 0.5443575382232666, Testing Accuracy: 0.9586206896551724\n",
            "Epoch: 31, Training Loss: 0.5201511383056641, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 31, Validation Loss: 0.5258667469024658, Validation Accuracy: 0.96\n",
            "Epoch: 31, Testing Loss: 0.5439560413360596, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 32, Training Loss: 0.5198288559913635, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 32, Validation Loss: 0.5254778861999512, Validation Accuracy: 0.96\n",
            "Epoch: 32, Testing Loss: 0.5435744524002075, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 33, Training Loss: 0.5195168852806091, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 33, Validation Loss: 0.5251101851463318, Validation Accuracy: 0.96\n",
            "Epoch: 33, Testing Loss: 0.5432122945785522, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 34, Training Loss: 0.5192140340805054, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 34, Validation Loss: 0.5247613787651062, Validation Accuracy: 0.96\n",
            "Epoch: 34, Testing Loss: 0.5428687334060669, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 35, Training Loss: 0.518919050693512, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 35, Validation Loss: 0.5244290232658386, Validation Accuracy: 0.96\n",
            "Epoch: 35, Testing Loss: 0.542542576789856, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 36, Training Loss: 0.5186309814453125, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 36, Validation Loss: 0.5241129994392395, Validation Accuracy: 0.96\n",
            "Epoch: 36, Testing Loss: 0.542234480381012, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 37, Training Loss: 0.5183492302894592, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 37, Validation Loss: 0.5238103270530701, Validation Accuracy: 0.96\n",
            "Epoch: 37, Testing Loss: 0.5419421195983887, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 38, Training Loss: 0.5180729627609253, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 38, Validation Loss: 0.523520290851593, Validation Accuracy: 0.96\n",
            "Epoch: 38, Testing Loss: 0.5416651368141174, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 39, Training Loss: 0.5178012251853943, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 39, Validation Loss: 0.5232416987419128, Validation Accuracy: 0.96\n",
            "Epoch: 39, Testing Loss: 0.5414026975631714, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 40, Training Loss: 0.5175334811210632, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 40, Validation Loss: 0.5229735374450684, Validation Accuracy: 0.96\n",
            "Epoch: 40, Testing Loss: 0.5411540865898132, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 41, Training Loss: 0.5172690749168396, Training Accuracy: 0.9655172413793104\n",
            "Epoch: 41, Validation Loss: 0.522715151309967, Validation Accuracy: 0.96\n",
            "Epoch: 41, Testing Loss: 0.5409184694290161, Testing Accuracy: 0.9655172413793104\n",
            "Epoch: 42, Training Loss: 0.5170069932937622, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 42, Validation Loss: 0.5224655270576477, Validation Accuracy: 0.96\n",
            "Epoch: 42, Testing Loss: 0.5406953692436218, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 43, Training Loss: 0.5167465806007385, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 43, Validation Loss: 0.5222240686416626, Validation Accuracy: 0.96\n",
            "Epoch: 43, Testing Loss: 0.5404842495918274, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 44, Training Loss: 0.5164869427680969, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 44, Validation Loss: 0.521990180015564, Validation Accuracy: 0.96\n",
            "Epoch: 44, Testing Loss: 0.5402848720550537, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 45, Training Loss: 0.5162273645401001, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 45, Validation Loss: 0.5217634439468384, Validation Accuracy: 0.96\n",
            "Epoch: 45, Testing Loss: 0.540097177028656, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 46, Training Loss: 0.5159668922424316, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 46, Validation Loss: 0.5215431451797485, Validation Accuracy: 0.96\n",
            "Epoch: 46, Testing Loss: 0.5399208068847656, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 47, Training Loss: 0.5157050490379333, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 47, Validation Loss: 0.521328866481781, Validation Accuracy: 0.96\n",
            "Epoch: 47, Testing Loss: 0.5397560000419617, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 48, Training Loss: 0.5154415965080261, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 48, Validation Loss: 0.5211203098297119, Validation Accuracy: 0.96\n",
            "Epoch: 48, Testing Loss: 0.5396026372909546, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 49, Training Loss: 0.5151761770248413, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 49, Validation Loss: 0.5209169983863831, Validation Accuracy: 0.96\n",
            "Epoch: 49, Testing Loss: 0.5394607186317444, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 50, Training Loss: 0.5149089694023132, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 50, Validation Loss: 0.520718514919281, Validation Accuracy: 0.96\n",
            "Epoch: 50, Testing Loss: 0.5393301248550415, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 51, Training Loss: 0.5146406888961792, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 51, Validation Loss: 0.5205246806144714, Validation Accuracy: 0.96\n",
            "Epoch: 51, Testing Loss: 0.5392105579376221, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 52, Training Loss: 0.5143718719482422, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 52, Validation Loss: 0.5203351378440857, Validation Accuracy: 0.96\n",
            "Epoch: 52, Testing Loss: 0.539101779460907, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 53, Training Loss: 0.5141040086746216, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 53, Validation Loss: 0.5201497673988342, Validation Accuracy: 0.96\n",
            "Epoch: 53, Testing Loss: 0.5390029549598694, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 54, Training Loss: 0.5138380527496338, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 54, Validation Loss: 0.5199682712554932, Validation Accuracy: 0.96\n",
            "Epoch: 54, Testing Loss: 0.5389134287834167, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 55, Training Loss: 0.513575553894043, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 55, Validation Loss: 0.5197907090187073, Validation Accuracy: 0.96\n",
            "Epoch: 55, Testing Loss: 0.5388322472572327, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 56, Training Loss: 0.5133177638053894, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 56, Validation Loss: 0.5196167230606079, Validation Accuracy: 0.96\n",
            "Epoch: 56, Testing Loss: 0.5387584567070007, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 57, Training Loss: 0.5130659341812134, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 57, Validation Loss: 0.5194464325904846, Validation Accuracy: 0.96\n",
            "Epoch: 57, Testing Loss: 0.5386910438537598, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 58, Training Loss: 0.5128208994865417, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 58, Validation Loss: 0.5192798972129822, Validation Accuracy: 0.96\n",
            "Epoch: 58, Testing Loss: 0.5386289954185486, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 59, Training Loss: 0.5125834941864014, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 59, Validation Loss: 0.519116997718811, Validation Accuracy: 0.96\n",
            "Epoch: 59, Testing Loss: 0.5385714769363403, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 60, Training Loss: 0.5123541355133057, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 60, Validation Loss: 0.5189578533172607, Validation Accuracy: 0.96\n",
            "Epoch: 60, Testing Loss: 0.5385178923606873, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 61, Training Loss: 0.5121330618858337, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 61, Validation Loss: 0.5187791585922241, Validation Accuracy: 0.96\n",
            "Epoch: 61, Testing Loss: 0.538467526435852, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 62, Training Loss: 0.5119203329086304, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 62, Validation Loss: 0.5186510682106018, Validation Accuracy: 0.96\n",
            "Epoch: 62, Testing Loss: 0.5384200811386108, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 63, Training Loss: 0.5117159485816956, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 63, Validation Loss: 0.5185036659240723, Validation Accuracy: 0.97\n",
            "Epoch: 63, Testing Loss: 0.5383750200271606, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 64, Training Loss: 0.5115196108818054, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 64, Validation Loss: 0.5183601975440979, Validation Accuracy: 0.97\n",
            "Epoch: 64, Testing Loss: 0.5383322834968567, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 65, Training Loss: 0.5113311409950256, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 65, Validation Loss: 0.518220841884613, Validation Accuracy: 0.97\n",
            "Epoch: 65, Testing Loss: 0.5382915735244751, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 66, Training Loss: 0.5111501812934875, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 66, Validation Loss: 0.5180855989456177, Validation Accuracy: 0.97\n",
            "Epoch: 66, Testing Loss: 0.538252592086792, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 67, Training Loss: 0.5109765529632568, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 67, Validation Loss: 0.5179544687271118, Validation Accuracy: 0.97\n",
            "Epoch: 67, Testing Loss: 0.5382152795791626, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 68, Training Loss: 0.5108097195625305, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 68, Validation Loss: 0.5178274512290955, Validation Accuracy: 0.97\n",
            "Epoch: 68, Testing Loss: 0.5381795763969421, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 69, Training Loss: 0.5106494426727295, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 69, Validation Loss: 0.5177045464515686, Validation Accuracy: 0.97\n",
            "Epoch: 69, Testing Loss: 0.5381454229354858, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 70, Training Loss: 0.5104953050613403, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 70, Validation Loss: 0.5175856947898865, Validation Accuracy: 0.97\n",
            "Epoch: 70, Testing Loss: 0.5381127595901489, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 71, Training Loss: 0.5103471279144287, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 71, Validation Loss: 0.5174709558486938, Validation Accuracy: 0.97\n",
            "Epoch: 71, Testing Loss: 0.5380815267562866, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 72, Training Loss: 0.5102044343948364, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 72, Validation Loss: 0.5173600912094116, Validation Accuracy: 0.97\n",
            "Epoch: 72, Testing Loss: 0.5380516052246094, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 73, Training Loss: 0.5100670456886292, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 73, Validation Loss: 0.5172531008720398, Validation Accuracy: 0.97\n",
            "Epoch: 73, Testing Loss: 0.5380231142044067, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 74, Training Loss: 0.509934663772583, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 74, Validation Loss: 0.5171498656272888, Validation Accuracy: 0.97\n",
            "Epoch: 74, Testing Loss: 0.5379959940910339, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 75, Training Loss: 0.5098069906234741, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 75, Validation Loss: 0.5170503258705139, Validation Accuracy: 0.97\n",
            "Epoch: 75, Testing Loss: 0.5379703044891357, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 76, Training Loss: 0.5096837282180786, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 76, Validation Loss: 0.5169543623924255, Validation Accuracy: 0.97\n",
            "Epoch: 76, Testing Loss: 0.5379457473754883, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 77, Training Loss: 0.5095648169517517, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 77, Validation Loss: 0.5168616771697998, Validation Accuracy: 0.97\n",
            "Epoch: 77, Testing Loss: 0.5379226207733154, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 78, Training Loss: 0.5094498991966248, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 78, Validation Loss: 0.516772449016571, Validation Accuracy: 0.97\n",
            "Epoch: 78, Testing Loss: 0.5379005670547485, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 79, Training Loss: 0.5093387365341187, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 79, Validation Loss: 0.5166862607002258, Validation Accuracy: 0.97\n",
            "Epoch: 79, Testing Loss: 0.5378796458244324, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 80, Training Loss: 0.5092312097549438, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 80, Validation Loss: 0.5166032910346985, Validation Accuracy: 0.97\n",
            "Epoch: 80, Testing Loss: 0.5378597974777222, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 81, Training Loss: 0.5091270208358765, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 81, Validation Loss: 0.5165231227874756, Validation Accuracy: 0.97\n",
            "Epoch: 81, Testing Loss: 0.5378409624099731, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 82, Training Loss: 0.5090261697769165, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 82, Validation Loss: 0.5164458155632019, Validation Accuracy: 0.97\n",
            "Epoch: 82, Testing Loss: 0.5378230214118958, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 83, Training Loss: 0.5089283585548401, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 83, Validation Loss: 0.5163711905479431, Validation Accuracy: 0.97\n",
            "Epoch: 83, Testing Loss: 0.5378059148788452, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 84, Training Loss: 0.5088334679603577, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 84, Validation Loss: 0.5162991881370544, Validation Accuracy: 0.97\n",
            "Epoch: 84, Testing Loss: 0.5377895832061768, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 85, Training Loss: 0.5087414383888245, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 85, Validation Loss: 0.5162296891212463, Validation Accuracy: 0.97\n",
            "Epoch: 85, Testing Loss: 0.5377739667892456, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 86, Training Loss: 0.5086520314216614, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 86, Validation Loss: 0.5161624550819397, Validation Accuracy: 0.97\n",
            "Epoch: 86, Testing Loss: 0.537759006023407, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 87, Training Loss: 0.5085651278495789, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 87, Validation Loss: 0.5160975456237793, Validation Accuracy: 0.97\n",
            "Epoch: 87, Testing Loss: 0.5377445816993713, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 88, Training Loss: 0.5084807276725769, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 88, Validation Loss: 0.5160348415374756, Validation Accuracy: 0.97\n",
            "Epoch: 88, Testing Loss: 0.5377306938171387, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 89, Training Loss: 0.5083985924720764, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 89, Validation Loss: 0.515974223613739, Validation Accuracy: 0.97\n",
            "Epoch: 89, Testing Loss: 0.5377174019813538, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 90, Training Loss: 0.5083187818527222, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 90, Validation Loss: 0.51591557264328, Validation Accuracy: 0.97\n",
            "Epoch: 90, Testing Loss: 0.5377044677734375, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 91, Training Loss: 0.5082411170005798, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 91, Validation Loss: 0.5158588886260986, Validation Accuracy: 0.97\n",
            "Epoch: 91, Testing Loss: 0.5376920104026794, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 92, Training Loss: 0.5081655979156494, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 92, Validation Loss: 0.5158040523529053, Validation Accuracy: 0.97\n",
            "Epoch: 92, Testing Loss: 0.5376799702644348, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 93, Training Loss: 0.5080919861793518, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 93, Validation Loss: 0.5157509446144104, Validation Accuracy: 0.97\n",
            "Epoch: 93, Testing Loss: 0.5376681685447693, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 94, Training Loss: 0.5080204606056213, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 94, Validation Loss: 0.5156995058059692, Validation Accuracy: 0.97\n",
            "Epoch: 94, Testing Loss: 0.5376567244529724, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 95, Training Loss: 0.5079507827758789, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 95, Validation Loss: 0.515649676322937, Validation Accuracy: 0.97\n",
            "Epoch: 95, Testing Loss: 0.5376455783843994, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 96, Training Loss: 0.5078830122947693, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 96, Validation Loss: 0.5156014561653137, Validation Accuracy: 0.97\n",
            "Epoch: 96, Testing Loss: 0.5376346707344055, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 97, Training Loss: 0.5078169703483582, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 97, Validation Loss: 0.515554666519165, Validation Accuracy: 0.97\n",
            "Epoch: 97, Testing Loss: 0.5376240015029907, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 98, Training Loss: 0.5077527165412903, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 98, Validation Loss: 0.5155093669891357, Validation Accuracy: 0.97\n",
            "Epoch: 98, Testing Loss: 0.5376135110855103, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 99, Training Loss: 0.5076900720596313, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 99, Validation Loss: 0.5154653787612915, Validation Accuracy: 0.97\n",
            "Epoch: 99, Testing Loss: 0.5376032590866089, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 100, Training Loss: 0.5076290965080261, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 100, Validation Loss: 0.5154227614402771, Validation Accuracy: 0.97\n",
            "Epoch: 100, Testing Loss: 0.5375930070877075, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 101, Training Loss: 0.5075696706771851, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 101, Validation Loss: 0.5153813362121582, Validation Accuracy: 0.97\n",
            "Epoch: 101, Testing Loss: 0.53758305311203, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 102, Training Loss: 0.5075117945671082, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 102, Validation Loss: 0.5153411626815796, Validation Accuracy: 0.97\n",
            "Epoch: 102, Testing Loss: 0.5375730395317078, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 103, Training Loss: 0.5074553489685059, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 103, Validation Loss: 0.5153021812438965, Validation Accuracy: 0.97\n",
            "Epoch: 103, Testing Loss: 0.537563145160675, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 104, Training Loss: 0.507400393486023, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 104, Validation Loss: 0.5152642130851746, Validation Accuracy: 0.97\n",
            "Epoch: 104, Testing Loss: 0.5375532507896423, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 105, Training Loss: 0.5073468089103699, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 105, Validation Loss: 0.5152273774147034, Validation Accuracy: 0.97\n",
            "Epoch: 105, Testing Loss: 0.5375434756278992, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 106, Training Loss: 0.5072945356369019, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 106, Validation Loss: 0.5151915550231934, Validation Accuracy: 0.97\n",
            "Epoch: 106, Testing Loss: 0.5375335812568665, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 107, Training Loss: 0.5072435140609741, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 107, Validation Loss: 0.5151566863059998, Validation Accuracy: 0.97\n",
            "Epoch: 107, Testing Loss: 0.5375236868858337, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 108, Training Loss: 0.5071938037872314, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 108, Validation Loss: 0.5151228308677673, Validation Accuracy: 0.97\n",
            "Epoch: 108, Testing Loss: 0.5375136733055115, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 109, Training Loss: 0.5071452260017395, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 109, Validation Loss: 0.5150898098945618, Validation Accuracy: 0.97\n",
            "Epoch: 109, Testing Loss: 0.5375036597251892, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 110, Training Loss: 0.5070977807044983, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 110, Validation Loss: 0.5150577425956726, Validation Accuracy: 0.97\n",
            "Epoch: 110, Testing Loss: 0.5374934673309326, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 111, Training Loss: 0.5070514678955078, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 111, Validation Loss: 0.5150265097618103, Validation Accuracy: 0.97\n",
            "Epoch: 111, Testing Loss: 0.537483274936676, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 112, Training Loss: 0.5070061683654785, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 112, Validation Loss: 0.5149960517883301, Validation Accuracy: 0.97\n",
            "Epoch: 112, Testing Loss: 0.5374728441238403, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 113, Training Loss: 0.5069619417190552, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 113, Validation Loss: 0.5149663686752319, Validation Accuracy: 0.97\n",
            "Epoch: 113, Testing Loss: 0.5374623537063599, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 114, Training Loss: 0.5069185495376587, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 114, Validation Loss: 0.5149374008178711, Validation Accuracy: 0.97\n",
            "Epoch: 114, Testing Loss: 0.5374515652656555, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 115, Training Loss: 0.5068761110305786, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 115, Validation Loss: 0.5149091482162476, Validation Accuracy: 0.97\n",
            "Epoch: 115, Testing Loss: 0.5374407172203064, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 116, Training Loss: 0.5068345069885254, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 116, Validation Loss: 0.5148816704750061, Validation Accuracy: 0.97\n",
            "Epoch: 116, Testing Loss: 0.5374296307563782, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 117, Training Loss: 0.506793737411499, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 117, Validation Loss: 0.5148548483848572, Validation Accuracy: 0.97\n",
            "Epoch: 117, Testing Loss: 0.5374184250831604, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 118, Training Loss: 0.5067538022994995, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 118, Validation Loss: 0.514828622341156, Validation Accuracy: 0.97\n",
            "Epoch: 118, Testing Loss: 0.5374069213867188, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 119, Training Loss: 0.5067145824432373, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 119, Validation Loss: 0.5148030519485474, Validation Accuracy: 0.97\n",
            "Epoch: 119, Testing Loss: 0.5373952984809875, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 120, Training Loss: 0.5066760182380676, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 120, Validation Loss: 0.5147754549980164, Validation Accuracy: 0.97\n",
            "Epoch: 120, Testing Loss: 0.5373834371566772, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 121, Training Loss: 0.5066381096839905, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 121, Validation Loss: 0.5147535800933838, Validation Accuracy: 0.97\n",
            "Epoch: 121, Testing Loss: 0.5373713970184326, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 122, Training Loss: 0.5066009163856506, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 122, Validation Loss: 0.5147297382354736, Validation Accuracy: 0.97\n",
            "Epoch: 122, Testing Loss: 0.5373591184616089, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 123, Training Loss: 0.5065642595291138, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 123, Validation Loss: 0.5147063732147217, Validation Accuracy: 0.97\n",
            "Epoch: 123, Testing Loss: 0.5373466610908508, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 124, Training Loss: 0.5065281391143799, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 124, Validation Loss: 0.5146835446357727, Validation Accuracy: 0.97\n",
            "Epoch: 124, Testing Loss: 0.5373339653015137, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 125, Training Loss: 0.5064926147460938, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 125, Validation Loss: 0.5146611928939819, Validation Accuracy: 0.97\n",
            "Epoch: 125, Testing Loss: 0.5373210906982422, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 126, Training Loss: 0.5064575672149658, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 126, Validation Loss: 0.5146393775939941, Validation Accuracy: 0.97\n",
            "Epoch: 126, Testing Loss: 0.5373080372810364, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 127, Training Loss: 0.5064229965209961, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 127, Validation Loss: 0.5146179795265198, Validation Accuracy: 0.97\n",
            "Epoch: 127, Testing Loss: 0.5372948050498962, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 128, Training Loss: 0.5063888430595398, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 128, Validation Loss: 0.5145970582962036, Validation Accuracy: 0.97\n",
            "Epoch: 128, Testing Loss: 0.5372814536094666, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 129, Training Loss: 0.5063550472259521, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 129, Validation Loss: 0.5145766139030457, Validation Accuracy: 0.97\n",
            "Epoch: 129, Testing Loss: 0.537267804145813, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 130, Training Loss: 0.5063216686248779, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 130, Validation Loss: 0.5145565271377563, Validation Accuracy: 0.97\n",
            "Epoch: 130, Testing Loss: 0.5372540354728699, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 131, Training Loss: 0.5062887072563171, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 131, Validation Loss: 0.5145368576049805, Validation Accuracy: 0.97\n",
            "Epoch: 131, Testing Loss: 0.5372400879859924, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 132, Training Loss: 0.5062560439109802, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 132, Validation Loss: 0.514517605304718, Validation Accuracy: 0.97\n",
            "Epoch: 132, Testing Loss: 0.5372259616851807, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 133, Training Loss: 0.5062236785888672, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 133, Validation Loss: 0.514498770236969, Validation Accuracy: 0.97\n",
            "Epoch: 133, Testing Loss: 0.5372117757797241, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 134, Training Loss: 0.506191611289978, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 134, Validation Loss: 0.5144802331924438, Validation Accuracy: 0.97\n",
            "Epoch: 134, Testing Loss: 0.5371974110603333, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 135, Training Loss: 0.506159782409668, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 135, Validation Loss: 0.5144621729850769, Validation Accuracy: 0.97\n",
            "Epoch: 135, Testing Loss: 0.5371828675270081, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 136, Training Loss: 0.5061282515525818, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 136, Validation Loss: 0.5144444704055786, Validation Accuracy: 0.97\n",
            "Epoch: 136, Testing Loss: 0.5371683239936829, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 137, Training Loss: 0.5060968995094299, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 137, Validation Loss: 0.5144270658493042, Validation Accuracy: 0.97\n",
            "Epoch: 137, Testing Loss: 0.5371536016464233, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 138, Training Loss: 0.5060657858848572, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 138, Validation Loss: 0.5144100785255432, Validation Accuracy: 0.97\n",
            "Epoch: 138, Testing Loss: 0.5371387600898743, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 139, Training Loss: 0.5060349702835083, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 139, Validation Loss: 0.5143933296203613, Validation Accuracy: 0.97\n",
            "Epoch: 139, Testing Loss: 0.5371237993240356, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 140, Training Loss: 0.5060041546821594, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 140, Validation Loss: 0.5143769979476929, Validation Accuracy: 0.97\n",
            "Epoch: 140, Testing Loss: 0.537108838558197, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 141, Training Loss: 0.5059735774993896, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 141, Validation Loss: 0.5143610239028931, Validation Accuracy: 0.97\n",
            "Epoch: 141, Testing Loss: 0.5370936989784241, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 142, Training Loss: 0.5059431195259094, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 142, Validation Loss: 0.5143453478813171, Validation Accuracy: 0.97\n",
            "Epoch: 142, Testing Loss: 0.5370785593986511, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 143, Training Loss: 0.5059128999710083, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 143, Validation Loss: 0.5143300294876099, Validation Accuracy: 0.97\n",
            "Epoch: 143, Testing Loss: 0.5370633602142334, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 144, Training Loss: 0.5058826804161072, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 144, Validation Loss: 0.5143150091171265, Validation Accuracy: 0.97\n",
            "Epoch: 144, Testing Loss: 0.5370480418205261, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 145, Training Loss: 0.5058526396751404, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 145, Validation Loss: 0.5143002867698669, Validation Accuracy: 0.97\n",
            "Epoch: 145, Testing Loss: 0.5370326638221741, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 146, Training Loss: 0.5058226585388184, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 146, Validation Loss: 0.5142859816551208, Validation Accuracy: 0.97\n",
            "Epoch: 146, Testing Loss: 0.5370174050331116, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 147, Training Loss: 0.5057927370071411, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 147, Validation Loss: 0.5142719149589539, Validation Accuracy: 0.97\n",
            "Epoch: 147, Testing Loss: 0.5370019674301147, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 148, Training Loss: 0.5057629346847534, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 148, Validation Loss: 0.5142582058906555, Validation Accuracy: 0.97\n",
            "Epoch: 148, Testing Loss: 0.5369865894317627, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 149, Training Loss: 0.505733072757721, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 149, Validation Loss: 0.514244794845581, Validation Accuracy: 0.97\n",
            "Epoch: 149, Testing Loss: 0.5369710922241211, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 150, Training Loss: 0.5057033896446228, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 150, Validation Loss: 0.5142317414283752, Validation Accuracy: 0.97\n",
            "Epoch: 150, Testing Loss: 0.5369556546211243, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 151, Training Loss: 0.5056737065315247, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 151, Validation Loss: 0.5142189264297485, Validation Accuracy: 0.97\n",
            "Epoch: 151, Testing Loss: 0.5369401574134827, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 152, Training Loss: 0.5056440234184265, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 152, Validation Loss: 0.5142065286636353, Validation Accuracy: 0.97\n",
            "Epoch: 152, Testing Loss: 0.5369247198104858, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 153, Training Loss: 0.5056143403053284, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 153, Validation Loss: 0.5141943693161011, Validation Accuracy: 0.97\n",
            "Epoch: 153, Testing Loss: 0.5369091629981995, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 154, Training Loss: 0.5055846571922302, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 154, Validation Loss: 0.5141825675964355, Validation Accuracy: 0.97\n",
            "Epoch: 154, Testing Loss: 0.5368937253952026, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 155, Training Loss: 0.5055549740791321, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 155, Validation Loss: 0.5141710042953491, Validation Accuracy: 0.97\n",
            "Epoch: 155, Testing Loss: 0.5368782877922058, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 156, Training Loss: 0.5055253505706787, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 156, Validation Loss: 0.5141598582267761, Validation Accuracy: 0.97\n",
            "Epoch: 156, Testing Loss: 0.5368627905845642, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 157, Training Loss: 0.5054956078529358, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 157, Validation Loss: 0.5141489505767822, Validation Accuracy: 0.97\n",
            "Epoch: 157, Testing Loss: 0.5368473529815674, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 158, Training Loss: 0.5054658651351929, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 158, Validation Loss: 0.514138400554657, Validation Accuracy: 0.97\n",
            "Epoch: 158, Testing Loss: 0.5368319749832153, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 159, Training Loss: 0.5054360628128052, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 159, Validation Loss: 0.5141281485557556, Validation Accuracy: 0.97\n",
            "Epoch: 159, Testing Loss: 0.5368165373802185, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 160, Training Loss: 0.5054062008857727, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 160, Validation Loss: 0.5141182541847229, Validation Accuracy: 0.97\n",
            "Epoch: 160, Testing Loss: 0.5368012189865112, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 161, Training Loss: 0.5053762793540955, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 161, Validation Loss: 0.5141087174415588, Validation Accuracy: 0.97\n",
            "Epoch: 161, Testing Loss: 0.5367859601974487, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 162, Training Loss: 0.5053462982177734, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 162, Validation Loss: 0.5140993595123291, Validation Accuracy: 0.97\n",
            "Epoch: 162, Testing Loss: 0.536770761013031, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 163, Training Loss: 0.5053161978721619, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 163, Validation Loss: 0.5140904784202576, Validation Accuracy: 0.97\n",
            "Epoch: 163, Testing Loss: 0.5367555022239685, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 164, Training Loss: 0.5052860379219055, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 164, Validation Loss: 0.5140818357467651, Validation Accuracy: 0.97\n",
            "Epoch: 164, Testing Loss: 0.5367404222488403, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 165, Training Loss: 0.5052556991577148, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 165, Validation Loss: 0.5140734910964966, Validation Accuracy: 0.97\n",
            "Epoch: 165, Testing Loss: 0.5367254018783569, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 166, Training Loss: 0.5052253603935242, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 166, Validation Loss: 0.5140655040740967, Validation Accuracy: 0.97\n",
            "Epoch: 166, Testing Loss: 0.5367104411125183, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 167, Training Loss: 0.5051947832107544, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 167, Validation Loss: 0.5140578150749207, Validation Accuracy: 0.97\n",
            "Epoch: 167, Testing Loss: 0.5366954803466797, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 168, Training Loss: 0.5051642060279846, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 168, Validation Loss: 0.5140504240989685, Validation Accuracy: 0.97\n",
            "Epoch: 168, Testing Loss: 0.5366807579994202, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 169, Training Loss: 0.5051333904266357, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 169, Validation Loss: 0.514043390750885, Validation Accuracy: 0.97\n",
            "Epoch: 169, Testing Loss: 0.5366660356521606, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 170, Training Loss: 0.5051024556159973, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 170, Validation Loss: 0.5140366554260254, Validation Accuracy: 0.97\n",
            "Epoch: 170, Testing Loss: 0.5366514921188354, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 171, Training Loss: 0.5050713419914246, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 171, Validation Loss: 0.5140302181243896, Validation Accuracy: 0.97\n",
            "Epoch: 171, Testing Loss: 0.5366370677947998, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 172, Training Loss: 0.5050401091575623, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 172, Validation Loss: 0.514024019241333, Validation Accuracy: 0.97\n",
            "Epoch: 172, Testing Loss: 0.5366227626800537, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 173, Training Loss: 0.5050086379051208, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 173, Validation Loss: 0.5140181183815002, Validation Accuracy: 0.97\n",
            "Epoch: 173, Testing Loss: 0.5366086363792419, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 174, Training Loss: 0.5049770474433899, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 174, Validation Loss: 0.5140125751495361, Validation Accuracy: 0.97\n",
            "Epoch: 174, Testing Loss: 0.5365946292877197, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 175, Training Loss: 0.5049453377723694, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 175, Validation Loss: 0.5140073299407959, Validation Accuracy: 0.97\n",
            "Epoch: 175, Testing Loss: 0.5365809202194214, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 176, Training Loss: 0.5049134492874146, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 176, Validation Loss: 0.51400226354599, Validation Accuracy: 0.97\n",
            "Epoch: 176, Testing Loss: 0.5365673303604126, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 177, Training Loss: 0.5048813223838806, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 177, Validation Loss: 0.5139974355697632, Validation Accuracy: 0.97\n",
            "Epoch: 177, Testing Loss: 0.5365539789199829, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 178, Training Loss: 0.5048490166664124, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 178, Validation Loss: 0.513992965221405, Validation Accuracy: 0.97\n",
            "Epoch: 178, Testing Loss: 0.5365408062934875, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 179, Training Loss: 0.5048166513442993, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 179, Validation Loss: 0.5139886736869812, Validation Accuracy: 0.97\n",
            "Epoch: 179, Testing Loss: 0.5365279316902161, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 180, Training Loss: 0.5047840476036072, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 180, Validation Loss: 0.5139846205711365, Validation Accuracy: 0.97\n",
            "Epoch: 180, Testing Loss: 0.5365153551101685, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 181, Training Loss: 0.5047513246536255, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 181, Validation Loss: 0.5139807462692261, Validation Accuracy: 0.97\n",
            "Epoch: 181, Testing Loss: 0.5365028977394104, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 182, Training Loss: 0.5047184824943542, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 182, Validation Loss: 0.5139771103858948, Validation Accuracy: 0.97\n",
            "Epoch: 182, Testing Loss: 0.5364909172058105, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 183, Training Loss: 0.5046855211257935, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 183, Validation Loss: 0.5139736533164978, Validation Accuracy: 0.97\n",
            "Epoch: 183, Testing Loss: 0.5364791750907898, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 184, Training Loss: 0.5046524405479431, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 184, Validation Loss: 0.5139703154563904, Validation Accuracy: 0.97\n",
            "Epoch: 184, Testing Loss: 0.5364678502082825, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 185, Training Loss: 0.504619300365448, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 185, Validation Loss: 0.5139672160148621, Validation Accuracy: 0.97\n",
            "Epoch: 185, Testing Loss: 0.536456823348999, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 186, Training Loss: 0.5045861005783081, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 186, Validation Loss: 0.5139641761779785, Validation Accuracy: 0.97\n",
            "Epoch: 186, Testing Loss: 0.536446213722229, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 187, Training Loss: 0.5045528411865234, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 187, Validation Loss: 0.5139612555503845, Validation Accuracy: 0.97\n",
            "Epoch: 187, Testing Loss: 0.5364359021186829, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 188, Training Loss: 0.5045196413993835, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 188, Validation Loss: 0.5139625072479248, Validation Accuracy: 0.97\n",
            "Epoch: 188, Testing Loss: 0.5364035367965698, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 189, Training Loss: 0.5044864416122437, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 189, Validation Loss: 0.5139557123184204, Validation Accuracy: 0.97\n",
            "Epoch: 189, Testing Loss: 0.5364165306091309, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 190, Training Loss: 0.5044532418251038, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 190, Validation Loss: 0.5139530301094055, Validation Accuracy: 0.97\n",
            "Epoch: 190, Testing Loss: 0.5364075303077698, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 191, Training Loss: 0.5044202208518982, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 191, Validation Loss: 0.5139504075050354, Validation Accuracy: 0.97\n",
            "Epoch: 191, Testing Loss: 0.5363987684249878, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 192, Training Loss: 0.5043873190879822, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 192, Validation Loss: 0.5139477849006653, Validation Accuracy: 0.97\n",
            "Epoch: 192, Testing Loss: 0.5363906621932983, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 193, Training Loss: 0.5043545365333557, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 193, Validation Loss: 0.5139452219009399, Validation Accuracy: 0.97\n",
            "Epoch: 193, Testing Loss: 0.5363827347755432, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 194, Training Loss: 0.5043218731880188, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 194, Validation Loss: 0.513942539691925, Validation Accuracy: 0.97\n",
            "Epoch: 194, Testing Loss: 0.5363752841949463, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 195, Training Loss: 0.5042895674705505, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 195, Validation Loss: 0.5139399170875549, Validation Accuracy: 0.97\n",
            "Epoch: 195, Testing Loss: 0.536368191242218, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 196, Training Loss: 0.5042574405670166, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 196, Validation Loss: 0.5139373540878296, Validation Accuracy: 0.97\n",
            "Epoch: 196, Testing Loss: 0.5363614559173584, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 197, Training Loss: 0.5042255520820618, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 197, Validation Loss: 0.5139346122741699, Validation Accuracy: 0.97\n",
            "Epoch: 197, Testing Loss: 0.5363550782203674, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 198, Training Loss: 0.5041939616203308, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 198, Validation Loss: 0.5139318704605103, Validation Accuracy: 0.97\n",
            "Epoch: 198, Testing Loss: 0.5363489389419556, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 199, Training Loss: 0.5041626691818237, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 199, Validation Loss: 0.513929009437561, Validation Accuracy: 0.97\n",
            "Epoch: 199, Testing Loss: 0.5363431572914124, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 200, Training Loss: 0.5041317939758301, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 200, Validation Loss: 0.5139262080192566, Validation Accuracy: 0.97\n",
            "Epoch: 200, Testing Loss: 0.5363376140594482, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 201, Training Loss: 0.5041012167930603, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 201, Validation Loss: 0.5139232277870178, Validation Accuracy: 0.97\n",
            "Epoch: 201, Testing Loss: 0.5363322496414185, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 202, Training Loss: 0.5040708780288696, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 202, Validation Loss: 0.5139201879501343, Validation Accuracy: 0.97\n",
            "Epoch: 202, Testing Loss: 0.5363269448280334, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 203, Training Loss: 0.5040410757064819, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 203, Validation Loss: 0.513917088508606, Validation Accuracy: 0.97\n",
            "Epoch: 203, Testing Loss: 0.5363219380378723, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 204, Training Loss: 0.5040114521980286, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 204, Validation Loss: 0.5139138698577881, Validation Accuracy: 0.97\n",
            "Epoch: 204, Testing Loss: 0.5363168120384216, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 205, Training Loss: 0.5039822459220886, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 205, Validation Loss: 0.5139105319976807, Validation Accuracy: 0.97\n",
            "Epoch: 205, Testing Loss: 0.5363118052482605, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 206, Training Loss: 0.5039534568786621, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 206, Validation Loss: 0.5139071941375732, Validation Accuracy: 0.97\n",
            "Epoch: 206, Testing Loss: 0.5363067388534546, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 207, Training Loss: 0.5039250254631042, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 207, Validation Loss: 0.5139036774635315, Validation Accuracy: 0.97\n",
            "Epoch: 207, Testing Loss: 0.5363017320632935, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 208, Training Loss: 0.5038968920707703, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 208, Validation Loss: 0.513900101184845, Validation Accuracy: 0.97\n",
            "Epoch: 208, Testing Loss: 0.5362964272499084, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 209, Training Loss: 0.5038690567016602, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 209, Validation Loss: 0.5138964653015137, Validation Accuracy: 0.97\n",
            "Epoch: 209, Testing Loss: 0.5362911224365234, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 210, Training Loss: 0.5038416385650635, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 210, Validation Loss: 0.5138927102088928, Validation Accuracy: 0.97\n",
            "Epoch: 210, Testing Loss: 0.5362856388092041, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 211, Training Loss: 0.5038144588470459, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 211, Validation Loss: 0.5138888955116272, Validation Accuracy: 0.97\n",
            "Epoch: 211, Testing Loss: 0.5362799167633057, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 212, Training Loss: 0.5037875771522522, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 212, Validation Loss: 0.513884961605072, Validation Accuracy: 0.97\n",
            "Epoch: 212, Testing Loss: 0.5362739562988281, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 213, Training Loss: 0.5037609934806824, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 213, Validation Loss: 0.5138809680938721, Validation Accuracy: 0.97\n",
            "Epoch: 213, Testing Loss: 0.5362676978111267, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 214, Training Loss: 0.5037347078323364, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 214, Validation Loss: 0.5138768553733826, Validation Accuracy: 0.97\n",
            "Epoch: 214, Testing Loss: 0.5362610816955566, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 215, Training Loss: 0.5037086009979248, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 215, Validation Loss: 0.5138727426528931, Validation Accuracy: 0.97\n",
            "Epoch: 215, Testing Loss: 0.5362541079521179, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 216, Training Loss: 0.5036827325820923, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 216, Validation Loss: 0.513868510723114, Validation Accuracy: 0.97\n",
            "Epoch: 216, Testing Loss: 0.5362467765808105, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 217, Training Loss: 0.5036571025848389, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 217, Validation Loss: 0.5138641595840454, Validation Accuracy: 0.97\n",
            "Epoch: 217, Testing Loss: 0.5362390875816345, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 218, Training Loss: 0.5036316514015198, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 218, Validation Loss: 0.5138598084449768, Validation Accuracy: 0.97\n",
            "Epoch: 218, Testing Loss: 0.5362310409545898, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 219, Training Loss: 0.503606379032135, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 219, Validation Loss: 0.5138553977012634, Validation Accuracy: 0.97\n",
            "Epoch: 219, Testing Loss: 0.5362224578857422, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 220, Training Loss: 0.5035812258720398, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 220, Validation Loss: 0.5138509273529053, Validation Accuracy: 0.97\n",
            "Epoch: 220, Testing Loss: 0.5362135171890259, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 221, Training Loss: 0.5035561323165894, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 221, Validation Loss: 0.5138463377952576, Validation Accuracy: 0.97\n",
            "Epoch: 221, Testing Loss: 0.5362040400505066, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 222, Training Loss: 0.503531277179718, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 222, Validation Loss: 0.5138417482376099, Validation Accuracy: 0.97\n",
            "Epoch: 222, Testing Loss: 0.5361941456794739, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 223, Training Loss: 0.5035064816474915, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 223, Validation Loss: 0.5138370990753174, Validation Accuracy: 0.97\n",
            "Epoch: 223, Testing Loss: 0.536183774471283, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 224, Training Loss: 0.5034817457199097, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 224, Validation Loss: 0.5138365626335144, Validation Accuracy: 0.97\n",
            "Epoch: 224, Testing Loss: 0.5361729264259338, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 225, Training Loss: 0.5034570097923279, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 225, Validation Loss: 0.5138276815414429, Validation Accuracy: 0.97\n",
            "Epoch: 225, Testing Loss: 0.5361615419387817, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 226, Training Loss: 0.5034323930740356, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 226, Validation Loss: 0.5138229131698608, Validation Accuracy: 0.97\n",
            "Epoch: 226, Testing Loss: 0.5361497402191162, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 227, Training Loss: 0.5034077167510986, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 227, Validation Loss: 0.513818085193634, Validation Accuracy: 0.97\n",
            "Epoch: 227, Testing Loss: 0.5361373424530029, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 228, Training Loss: 0.5033830404281616, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 228, Validation Loss: 0.5138132572174072, Validation Accuracy: 0.97\n",
            "Epoch: 228, Testing Loss: 0.5361245274543762, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 229, Training Loss: 0.5033583641052246, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 229, Validation Loss: 0.5138084292411804, Validation Accuracy: 0.97\n",
            "Epoch: 229, Testing Loss: 0.5361111164093018, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 230, Training Loss: 0.5033336281776428, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 230, Validation Loss: 0.5138035416603088, Validation Accuracy: 0.97\n",
            "Epoch: 230, Testing Loss: 0.5360972285270691, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 231, Training Loss: 0.503308892250061, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 231, Validation Loss: 0.5137986540794373, Validation Accuracy: 0.97\n",
            "Epoch: 231, Testing Loss: 0.5360828638076782, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 232, Training Loss: 0.5032840371131897, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 232, Validation Loss: 0.5137937068939209, Validation Accuracy: 0.97\n",
            "Epoch: 232, Testing Loss: 0.5360679626464844, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 233, Training Loss: 0.5032591223716736, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 233, Validation Loss: 0.5137888193130493, Validation Accuracy: 0.97\n",
            "Epoch: 233, Testing Loss: 0.5360526442527771, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 234, Training Loss: 0.5032340288162231, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 234, Validation Loss: 0.5137838125228882, Validation Accuracy: 0.97\n",
            "Epoch: 234, Testing Loss: 0.5360367298126221, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 235, Training Loss: 0.5032088160514832, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 235, Validation Loss: 0.5137789249420166, Validation Accuracy: 0.97\n",
            "Epoch: 235, Testing Loss: 0.5360203981399536, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 236, Training Loss: 0.5031834840774536, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 236, Validation Loss: 0.5137739777565002, Validation Accuracy: 0.97\n",
            "Epoch: 236, Testing Loss: 0.5360035300254822, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 237, Training Loss: 0.5031579732894897, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 237, Validation Loss: 0.5137690901756287, Validation Accuracy: 0.97\n",
            "Epoch: 237, Testing Loss: 0.5359861850738525, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 238, Training Loss: 0.5031322836875916, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 238, Validation Loss: 0.5137641429901123, Validation Accuracy: 0.97\n",
            "Epoch: 238, Testing Loss: 0.5359683036804199, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 239, Training Loss: 0.5031063556671143, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 239, Validation Loss: 0.5137592554092407, Validation Accuracy: 0.97\n",
            "Epoch: 239, Testing Loss: 0.5359500050544739, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 240, Training Loss: 0.5030803084373474, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 240, Validation Loss: 0.5137543678283691, Validation Accuracy: 0.97\n",
            "Epoch: 240, Testing Loss: 0.5359312891960144, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 241, Training Loss: 0.5030540227890015, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 241, Validation Loss: 0.5137494802474976, Validation Accuracy: 0.97\n",
            "Epoch: 241, Testing Loss: 0.5359120965003967, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 242, Training Loss: 0.5030275583267212, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 242, Validation Loss: 0.5137446522712708, Validation Accuracy: 0.97\n",
            "Epoch: 242, Testing Loss: 0.5358924865722656, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 243, Training Loss: 0.503000795841217, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 243, Validation Loss: 0.513739824295044, Validation Accuracy: 0.97\n",
            "Epoch: 243, Testing Loss: 0.5358723998069763, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 244, Training Loss: 0.5029738545417786, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 244, Validation Loss: 0.5137349963188171, Validation Accuracy: 0.97\n",
            "Epoch: 244, Testing Loss: 0.5358519554138184, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 245, Training Loss: 0.5029466152191162, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 245, Validation Loss: 0.5137301087379456, Validation Accuracy: 0.97\n",
            "Epoch: 245, Testing Loss: 0.535831093788147, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 246, Training Loss: 0.5029191970825195, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 246, Validation Loss: 0.5137253403663635, Validation Accuracy: 0.97\n",
            "Epoch: 246, Testing Loss: 0.5358099341392517, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 247, Training Loss: 0.502891480922699, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 247, Validation Loss: 0.5137205123901367, Validation Accuracy: 0.97\n",
            "Epoch: 247, Testing Loss: 0.5357884764671326, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 248, Training Loss: 0.5028636455535889, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 248, Validation Loss: 0.5137157440185547, Validation Accuracy: 0.97\n",
            "Epoch: 248, Testing Loss: 0.5357666611671448, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 249, Training Loss: 0.5028355121612549, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 249, Validation Loss: 0.5137109160423279, Validation Accuracy: 0.97\n",
            "Epoch: 249, Testing Loss: 0.5357446074485779, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 250, Training Loss: 0.5028071999549866, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 250, Validation Loss: 0.5137061476707458, Validation Accuracy: 0.97\n",
            "Epoch: 250, Testing Loss: 0.5357223749160767, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 251, Training Loss: 0.5027787685394287, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 251, Validation Loss: 0.513701319694519, Validation Accuracy: 0.97\n",
            "Epoch: 251, Testing Loss: 0.5356999635696411, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 252, Training Loss: 0.5027501583099365, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 252, Validation Loss: 0.5136964917182922, Validation Accuracy: 0.97\n",
            "Epoch: 252, Testing Loss: 0.5356773734092712, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 253, Training Loss: 0.5027214884757996, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 253, Validation Loss: 0.5136916041374207, Validation Accuracy: 0.97\n",
            "Epoch: 253, Testing Loss: 0.5356547236442566, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 254, Training Loss: 0.502692699432373, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 254, Validation Loss: 0.5136866569519043, Validation Accuracy: 0.97\n",
            "Epoch: 254, Testing Loss: 0.5356321334838867, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 255, Training Loss: 0.502663791179657, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 255, Validation Loss: 0.5136816501617432, Validation Accuracy: 0.97\n",
            "Epoch: 255, Testing Loss: 0.5356094837188721, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 256, Training Loss: 0.5026350021362305, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 256, Validation Loss: 0.513676643371582, Validation Accuracy: 0.97\n",
            "Epoch: 256, Testing Loss: 0.535586953163147, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 257, Training Loss: 0.5026061534881592, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 257, Validation Loss: 0.5136715173721313, Validation Accuracy: 0.97\n",
            "Epoch: 257, Testing Loss: 0.5355645418167114, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 258, Training Loss: 0.5025774240493774, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 258, Validation Loss: 0.5136663317680359, Validation Accuracy: 0.97\n",
            "Epoch: 258, Testing Loss: 0.5355424284934998, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 259, Training Loss: 0.50254887342453, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 259, Validation Loss: 0.5136610269546509, Validation Accuracy: 0.97\n",
            "Epoch: 259, Testing Loss: 0.5355204939842224, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 260, Training Loss: 0.5025204420089722, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 260, Validation Loss: 0.5136556029319763, Validation Accuracy: 0.97\n",
            "Epoch: 260, Testing Loss: 0.5354989171028137, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 261, Training Loss: 0.5024921894073486, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 261, Validation Loss: 0.5136501789093018, Validation Accuracy: 0.97\n",
            "Epoch: 261, Testing Loss: 0.5354447960853577, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 262, Training Loss: 0.5024643540382385, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 262, Validation Loss: 0.5136445164680481, Validation Accuracy: 0.97\n",
            "Epoch: 262, Testing Loss: 0.5354570150375366, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 263, Training Loss: 0.5024367570877075, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 263, Validation Loss: 0.5136387348175049, Validation Accuracy: 0.97\n",
            "Epoch: 263, Testing Loss: 0.535436749458313, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 264, Training Loss: 0.5024095177650452, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 264, Validation Loss: 0.5136328339576721, Validation Accuracy: 0.97\n",
            "Epoch: 264, Testing Loss: 0.5354169607162476, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 265, Training Loss: 0.5023826956748962, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 265, Validation Loss: 0.513626754283905, Validation Accuracy: 0.97\n",
            "Epoch: 265, Testing Loss: 0.5353977680206299, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 266, Training Loss: 0.5023562908172607, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 266, Validation Loss: 0.5136205554008484, Validation Accuracy: 0.97\n",
            "Epoch: 266, Testing Loss: 0.5353791117668152, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 267, Training Loss: 0.5023304224014282, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 267, Validation Loss: 0.5136141777038574, Validation Accuracy: 0.97\n",
            "Epoch: 267, Testing Loss: 0.5353611707687378, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 268, Training Loss: 0.5023050308227539, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 268, Validation Loss: 0.5136076211929321, Validation Accuracy: 0.97\n",
            "Epoch: 268, Testing Loss: 0.5353438258171082, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 269, Training Loss: 0.5022801160812378, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 269, Validation Loss: 0.5136009454727173, Validation Accuracy: 0.97\n",
            "Epoch: 269, Testing Loss: 0.535327136516571, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 270, Training Loss: 0.5022557973861694, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 270, Validation Loss: 0.5135940313339233, Validation Accuracy: 0.97\n",
            "Epoch: 270, Testing Loss: 0.5353111624717712, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 271, Training Loss: 0.502232015132904, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 271, Validation Loss: 0.5135870575904846, Validation Accuracy: 0.97\n",
            "Epoch: 271, Testing Loss: 0.535295844078064, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 272, Training Loss: 0.5022088289260864, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 272, Validation Loss: 0.5135799050331116, Validation Accuracy: 0.97\n",
            "Epoch: 272, Testing Loss: 0.5352811217308044, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 273, Training Loss: 0.5021861791610718, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 273, Validation Loss: 0.5135725140571594, Validation Accuracy: 0.97\n",
            "Epoch: 273, Testing Loss: 0.535267174243927, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 274, Training Loss: 0.5021641850471497, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 274, Validation Loss: 0.5135650038719177, Validation Accuracy: 0.97\n",
            "Epoch: 274, Testing Loss: 0.5352538228034973, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 275, Training Loss: 0.5021427273750305, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 275, Validation Loss: 0.5135573744773865, Validation Accuracy: 0.97\n",
            "Epoch: 275, Testing Loss: 0.5352411270141602, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 276, Training Loss: 0.5021218061447144, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 276, Validation Loss: 0.5135495662689209, Validation Accuracy: 0.97\n",
            "Epoch: 276, Testing Loss: 0.5352290868759155, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 277, Training Loss: 0.5021014213562012, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 277, Validation Loss: 0.513541579246521, Validation Accuracy: 0.97\n",
            "Epoch: 277, Testing Loss: 0.5352177023887634, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 278, Training Loss: 0.5020816922187805, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 278, Validation Loss: 0.5135335326194763, Validation Accuracy: 0.97\n",
            "Epoch: 278, Testing Loss: 0.5352069139480591, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 279, Training Loss: 0.5020624399185181, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 279, Validation Loss: 0.5135253071784973, Validation Accuracy: 0.97\n",
            "Epoch: 279, Testing Loss: 0.5351967811584473, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 280, Training Loss: 0.5020437836647034, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 280, Validation Loss: 0.5135169625282288, Validation Accuracy: 0.97\n",
            "Epoch: 280, Testing Loss: 0.5351871848106384, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 281, Training Loss: 0.5020254850387573, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 281, Validation Loss: 0.5135084986686707, Validation Accuracy: 0.97\n",
            "Epoch: 281, Testing Loss: 0.5351782441139221, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 282, Training Loss: 0.5020078420639038, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 282, Validation Loss: 0.513499915599823, Validation Accuracy: 0.97\n",
            "Epoch: 282, Testing Loss: 0.5351697206497192, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 283, Training Loss: 0.5019906163215637, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 283, Validation Loss: 0.513491153717041, Validation Accuracy: 0.97\n",
            "Epoch: 283, Testing Loss: 0.5351618528366089, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 284, Training Loss: 0.5019738078117371, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 284, Validation Loss: 0.5134823322296143, Validation Accuracy: 0.97\n",
            "Epoch: 284, Testing Loss: 0.5351544618606567, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 285, Training Loss: 0.5019575357437134, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 285, Validation Loss: 0.513473391532898, Validation Accuracy: 0.97\n",
            "Epoch: 285, Testing Loss: 0.5351475477218628, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 286, Training Loss: 0.5019415616989136, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 286, Validation Loss: 0.5134643316268921, Validation Accuracy: 0.97\n",
            "Epoch: 286, Testing Loss: 0.535141110420227, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 287, Training Loss: 0.5019261240959167, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 287, Validation Loss: 0.5134552121162415, Validation Accuracy: 0.97\n",
            "Epoch: 287, Testing Loss: 0.5351352095603943, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 288, Training Loss: 0.5019110441207886, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 288, Validation Loss: 0.5134459733963013, Validation Accuracy: 0.97\n",
            "Epoch: 288, Testing Loss: 0.5351296067237854, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 289, Training Loss: 0.501896321773529, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 289, Validation Loss: 0.5134366750717163, Validation Accuracy: 0.97\n",
            "Epoch: 289, Testing Loss: 0.5351245999336243, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 290, Training Loss: 0.501882016658783, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 290, Validation Loss: 0.5134272575378418, Validation Accuracy: 0.97\n",
            "Epoch: 290, Testing Loss: 0.535119891166687, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 291, Training Loss: 0.5018680095672607, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 291, Validation Loss: 0.5134177803993225, Validation Accuracy: 0.97\n",
            "Epoch: 291, Testing Loss: 0.535115659236908, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 292, Training Loss: 0.5018543004989624, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 292, Validation Loss: 0.5134081840515137, Validation Accuracy: 0.97\n",
            "Epoch: 292, Testing Loss: 0.5351117253303528, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 293, Training Loss: 0.5018409490585327, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 293, Validation Loss: 0.5133985280990601, Validation Accuracy: 0.97\n",
            "Epoch: 293, Testing Loss: 0.535108208656311, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 294, Training Loss: 0.5018279552459717, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 294, Validation Loss: 0.5133888125419617, Validation Accuracy: 0.97\n",
            "Epoch: 294, Testing Loss: 0.5351049900054932, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 295, Training Loss: 0.5018151998519897, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 295, Validation Loss: 0.5133790373802185, Validation Accuracy: 0.97\n",
            "Epoch: 295, Testing Loss: 0.5351021885871887, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 296, Training Loss: 0.5018027424812317, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 296, Validation Loss: 0.5133692026138306, Validation Accuracy: 0.97\n",
            "Epoch: 296, Testing Loss: 0.5350995063781738, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 297, Training Loss: 0.5017905235290527, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 297, Validation Loss: 0.5133592486381531, Validation Accuracy: 0.97\n",
            "Epoch: 297, Testing Loss: 0.5350973010063171, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 298, Training Loss: 0.5017786026000977, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 298, Validation Loss: 0.5133492946624756, Validation Accuracy: 0.97\n",
            "Epoch: 298, Testing Loss: 0.5350953340530396, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 299, Training Loss: 0.5017668604850769, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 299, Validation Loss: 0.5133392214775085, Validation Accuracy: 0.97\n",
            "Epoch: 299, Testing Loss: 0.5350936651229858, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 300, Training Loss: 0.50175541639328, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 300, Validation Loss: 0.5133291482925415, Validation Accuracy: 0.97\n",
            "Epoch: 300, Testing Loss: 0.5350921750068665, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 301, Training Loss: 0.5017441511154175, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 301, Validation Loss: 0.5133189558982849, Validation Accuracy: 0.97\n",
            "Epoch: 301, Testing Loss: 0.535090982913971, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 302, Training Loss: 0.5017330646514893, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 302, Validation Loss: 0.5133087635040283, Validation Accuracy: 0.97\n",
            "Epoch: 302, Testing Loss: 0.5350900292396545, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 303, Training Loss: 0.5017222762107849, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 303, Validation Loss: 0.5132986307144165, Validation Accuracy: 0.97\n",
            "Epoch: 303, Testing Loss: 0.5350891947746277, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 304, Training Loss: 0.5017116069793701, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 304, Validation Loss: 0.5132883191108704, Validation Accuracy: 0.97\n",
            "Epoch: 304, Testing Loss: 0.5350887179374695, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 305, Training Loss: 0.5017011761665344, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 305, Validation Loss: 0.5132779479026794, Validation Accuracy: 0.97\n",
            "Epoch: 305, Testing Loss: 0.535088300704956, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 306, Training Loss: 0.5016909241676331, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 306, Validation Loss: 0.5132675766944885, Validation Accuracy: 0.97\n",
            "Epoch: 306, Testing Loss: 0.5350881814956665, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 307, Training Loss: 0.5016807913780212, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 307, Validation Loss: 0.5132572054862976, Validation Accuracy: 0.97\n",
            "Epoch: 307, Testing Loss: 0.5350881814956665, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 308, Training Loss: 0.5016708970069885, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 308, Validation Loss: 0.5132467150688171, Validation Accuracy: 0.97\n",
            "Epoch: 308, Testing Loss: 0.5350883603096008, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 309, Training Loss: 0.5016611218452454, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 309, Validation Loss: 0.5132362246513367, Validation Accuracy: 0.97\n",
            "Epoch: 309, Testing Loss: 0.5350887179374695, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 310, Training Loss: 0.5016514658927917, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 310, Validation Loss: 0.5132257342338562, Validation Accuracy: 0.97\n",
            "Epoch: 310, Testing Loss: 0.5350891351699829, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 311, Training Loss: 0.5016420483589172, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 311, Validation Loss: 0.513215184211731, Validation Accuracy: 0.97\n",
            "Epoch: 311, Testing Loss: 0.5350897312164307, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 312, Training Loss: 0.5016326904296875, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 312, Validation Loss: 0.5132045745849609, Validation Accuracy: 0.97\n",
            "Epoch: 312, Testing Loss: 0.5350905060768127, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 313, Training Loss: 0.5016234517097473, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 313, Validation Loss: 0.5131939053535461, Validation Accuracy: 0.97\n",
            "Epoch: 313, Testing Loss: 0.5350913405418396, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 314, Training Loss: 0.5016143918037415, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 314, Validation Loss: 0.5131832957267761, Validation Accuracy: 0.97\n",
            "Epoch: 314, Testing Loss: 0.535092294216156, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 315, Training Loss: 0.5016055107116699, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 315, Validation Loss: 0.5131726264953613, Validation Accuracy: 0.97\n",
            "Epoch: 315, Testing Loss: 0.5350933074951172, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 316, Training Loss: 0.5015966892242432, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 316, Validation Loss: 0.5131618976593018, Validation Accuracy: 0.97\n",
            "Epoch: 316, Testing Loss: 0.5350944995880127, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 317, Training Loss: 0.5015879273414612, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 317, Validation Loss: 0.513151228427887, Validation Accuracy: 0.97\n",
            "Epoch: 317, Testing Loss: 0.5350956320762634, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 318, Training Loss: 0.5015794038772583, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 318, Validation Loss: 0.5131404399871826, Validation Accuracy: 0.97\n",
            "Epoch: 318, Testing Loss: 0.5350969433784485, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 319, Training Loss: 0.5015709400177002, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 319, Validation Loss: 0.513129711151123, Validation Accuracy: 0.97\n",
            "Epoch: 319, Testing Loss: 0.5350982546806335, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 320, Training Loss: 0.5015625357627869, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 320, Validation Loss: 0.5131189227104187, Validation Accuracy: 0.97\n",
            "Epoch: 320, Testing Loss: 0.5350996255874634, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 321, Training Loss: 0.5015543103218079, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 321, Validation Loss: 0.5131080746650696, Validation Accuracy: 0.97\n",
            "Epoch: 321, Testing Loss: 0.5351011157035828, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 322, Training Loss: 0.5015461444854736, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 322, Validation Loss: 0.5130972862243652, Validation Accuracy: 0.97\n",
            "Epoch: 322, Testing Loss: 0.5351026058197021, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 323, Training Loss: 0.5015380382537842, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 323, Validation Loss: 0.5130864381790161, Validation Accuracy: 0.97\n",
            "Epoch: 323, Testing Loss: 0.5351040363311768, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 324, Training Loss: 0.501530110836029, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 324, Validation Loss: 0.513075590133667, Validation Accuracy: 0.97\n",
            "Epoch: 324, Testing Loss: 0.5351055860519409, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 325, Training Loss: 0.5015221834182739, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 325, Validation Loss: 0.5130646824836731, Validation Accuracy: 0.97\n",
            "Epoch: 325, Testing Loss: 0.5351071357727051, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 326, Training Loss: 0.5015143752098083, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 326, Validation Loss: 0.513053834438324, Validation Accuracy: 0.97\n",
            "Epoch: 326, Testing Loss: 0.5351085662841797, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 327, Training Loss: 0.5015066862106323, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 327, Validation Loss: 0.5130429267883301, Validation Accuracy: 0.97\n",
            "Epoch: 327, Testing Loss: 0.5351101756095886, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 328, Training Loss: 0.5014990568161011, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 328, Validation Loss: 0.5130320191383362, Validation Accuracy: 0.97\n",
            "Epoch: 328, Testing Loss: 0.535111665725708, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 329, Training Loss: 0.5014914870262146, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 329, Validation Loss: 0.5130210518836975, Validation Accuracy: 0.97\n",
            "Epoch: 329, Testing Loss: 0.5351132154464722, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 330, Training Loss: 0.5014840364456177, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 330, Validation Loss: 0.5130101442337036, Validation Accuracy: 0.97\n",
            "Epoch: 330, Testing Loss: 0.5351147055625916, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 331, Training Loss: 0.5014766454696655, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 331, Validation Loss: 0.5129991769790649, Validation Accuracy: 0.97\n",
            "Epoch: 331, Testing Loss: 0.5351161360740662, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 332, Training Loss: 0.5014693140983582, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 332, Validation Loss: 0.512988269329071, Validation Accuracy: 0.97\n",
            "Epoch: 332, Testing Loss: 0.5351175665855408, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 333, Training Loss: 0.5014619827270508, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 333, Validation Loss: 0.5129772424697876, Validation Accuracy: 0.97\n",
            "Epoch: 333, Testing Loss: 0.5351189374923706, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 334, Training Loss: 0.5014548301696777, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 334, Validation Loss: 0.5129663348197937, Validation Accuracy: 0.97\n",
            "Epoch: 334, Testing Loss: 0.5351202487945557, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 335, Training Loss: 0.5014476776123047, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 335, Validation Loss: 0.5129598379135132, Validation Accuracy: 0.97\n",
            "Epoch: 335, Testing Loss: 0.5350931286811829, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 336, Training Loss: 0.5014405846595764, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 336, Validation Loss: 0.5129444003105164, Validation Accuracy: 0.97\n",
            "Epoch: 336, Testing Loss: 0.5351227521896362, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 337, Training Loss: 0.5014335513114929, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 337, Validation Loss: 0.5129334926605225, Validation Accuracy: 0.97\n",
            "Epoch: 337, Testing Loss: 0.5351238250732422, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 338, Training Loss: 0.5014265775680542, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 338, Validation Loss: 0.5129225254058838, Validation Accuracy: 0.97\n",
            "Epoch: 338, Testing Loss: 0.5351249575614929, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 339, Training Loss: 0.5014196634292603, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 339, Validation Loss: 0.5129115581512451, Validation Accuracy: 0.97\n",
            "Epoch: 339, Testing Loss: 0.5351259112358093, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 340, Training Loss: 0.5014128684997559, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 340, Validation Loss: 0.5129005908966064, Validation Accuracy: 0.97\n",
            "Epoch: 340, Testing Loss: 0.535126805305481, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 341, Training Loss: 0.5014060735702515, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 341, Validation Loss: 0.5128896236419678, Validation Accuracy: 0.97\n",
            "Epoch: 341, Testing Loss: 0.5351276397705078, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 342, Training Loss: 0.5013993382453918, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 342, Validation Loss: 0.5128786563873291, Validation Accuracy: 0.97\n",
            "Epoch: 342, Testing Loss: 0.5351283550262451, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 343, Training Loss: 0.501392662525177, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 343, Validation Loss: 0.5128677487373352, Validation Accuracy: 0.97\n",
            "Epoch: 343, Testing Loss: 0.5351289510726929, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 344, Training Loss: 0.5013859868049622, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 344, Validation Loss: 0.5128567814826965, Validation Accuracy: 0.97\n",
            "Epoch: 344, Testing Loss: 0.5351294279098511, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 345, Training Loss: 0.5013794302940369, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 345, Validation Loss: 0.5128458142280579, Validation Accuracy: 0.97\n",
            "Epoch: 345, Testing Loss: 0.5351298451423645, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 346, Training Loss: 0.5013728737831116, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 346, Validation Loss: 0.512834906578064, Validation Accuracy: 0.97\n",
            "Epoch: 346, Testing Loss: 0.5351300835609436, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 347, Training Loss: 0.501366376876831, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 347, Validation Loss: 0.5128240585327148, Validation Accuracy: 0.97\n",
            "Epoch: 347, Testing Loss: 0.5351302623748779, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 348, Training Loss: 0.5013599395751953, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 348, Validation Loss: 0.512813150882721, Validation Accuracy: 0.97\n",
            "Epoch: 348, Testing Loss: 0.5351303815841675, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 349, Training Loss: 0.5013535022735596, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 349, Validation Loss: 0.5128023028373718, Validation Accuracy: 0.97\n",
            "Epoch: 349, Testing Loss: 0.5351302623748779, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 350, Training Loss: 0.5013471841812134, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 350, Validation Loss: 0.5127913951873779, Validation Accuracy: 0.97\n",
            "Epoch: 350, Testing Loss: 0.5351300239562988, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 351, Training Loss: 0.5013408660888672, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 351, Validation Loss: 0.5127805471420288, Validation Accuracy: 0.97\n",
            "Epoch: 351, Testing Loss: 0.5351296663284302, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 352, Training Loss: 0.501334547996521, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 352, Validation Loss: 0.5127697587013245, Validation Accuracy: 0.97\n",
            "Epoch: 352, Testing Loss: 0.535129189491272, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 353, Training Loss: 0.5013282895088196, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 353, Validation Loss: 0.5127589106559753, Validation Accuracy: 0.97\n",
            "Epoch: 353, Testing Loss: 0.5351285934448242, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 354, Training Loss: 0.5013220906257629, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 354, Validation Loss: 0.5127480626106262, Validation Accuracy: 0.97\n",
            "Epoch: 354, Testing Loss: 0.5351278185844421, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 355, Training Loss: 0.5013159513473511, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 355, Validation Loss: 0.5127373337745667, Validation Accuracy: 0.97\n",
            "Epoch: 355, Testing Loss: 0.5351269245147705, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 356, Training Loss: 0.5013098120689392, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 356, Validation Loss: 0.5127265453338623, Validation Accuracy: 0.97\n",
            "Epoch: 356, Testing Loss: 0.5351259708404541, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 357, Training Loss: 0.5013036727905273, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 357, Validation Loss: 0.5127158164978027, Validation Accuracy: 0.97\n",
            "Epoch: 357, Testing Loss: 0.535124659538269, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 358, Training Loss: 0.501297652721405, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 358, Validation Loss: 0.5127050876617432, Validation Accuracy: 0.97\n",
            "Epoch: 358, Testing Loss: 0.535123348236084, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 359, Training Loss: 0.5012915730476379, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 359, Validation Loss: 0.5126944184303284, Validation Accuracy: 0.97\n",
            "Epoch: 359, Testing Loss: 0.5351219177246094, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 360, Training Loss: 0.5012855529785156, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 360, Validation Loss: 0.5126837491989136, Validation Accuracy: 0.97\n",
            "Epoch: 360, Testing Loss: 0.5351202487945557, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 361, Training Loss: 0.5012796521186829, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 361, Validation Loss: 0.5126731395721436, Validation Accuracy: 0.97\n",
            "Epoch: 361, Testing Loss: 0.5351184606552124, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 362, Training Loss: 0.5012736916542053, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 362, Validation Loss: 0.5126625299453735, Validation Accuracy: 0.97\n",
            "Epoch: 362, Testing Loss: 0.5351165533065796, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 363, Training Loss: 0.5012677907943726, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 363, Validation Loss: 0.5126520395278931, Validation Accuracy: 0.97\n",
            "Epoch: 363, Testing Loss: 0.5351144671440125, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 364, Training Loss: 0.5012618899345398, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 364, Validation Loss: 0.512641429901123, Validation Accuracy: 0.97\n",
            "Epoch: 364, Testing Loss: 0.535112202167511, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 365, Training Loss: 0.5012560486793518, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 365, Validation Loss: 0.5126309394836426, Validation Accuracy: 0.97\n",
            "Epoch: 365, Testing Loss: 0.53510981798172, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 366, Training Loss: 0.5012502670288086, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 366, Validation Loss: 0.5126205086708069, Validation Accuracy: 0.97\n",
            "Epoch: 366, Testing Loss: 0.5351073145866394, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 367, Training Loss: 0.5012444853782654, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 367, Validation Loss: 0.5126100778579712, Validation Accuracy: 0.97\n",
            "Epoch: 367, Testing Loss: 0.5351045727729797, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 368, Training Loss: 0.5012387037277222, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 368, Validation Loss: 0.5125997066497803, Validation Accuracy: 0.97\n",
            "Epoch: 368, Testing Loss: 0.5351017117500305, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 369, Training Loss: 0.5012329816818237, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 369, Validation Loss: 0.5125893354415894, Validation Accuracy: 0.97\n",
            "Epoch: 369, Testing Loss: 0.5350987315177917, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 370, Training Loss: 0.5012273192405701, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 370, Validation Loss: 0.5125790238380432, Validation Accuracy: 0.97\n",
            "Epoch: 370, Testing Loss: 0.5350956320762634, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 371, Training Loss: 0.5012216567993164, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 371, Validation Loss: 0.5125687718391418, Validation Accuracy: 0.97\n",
            "Epoch: 371, Testing Loss: 0.535092294216156, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 372, Training Loss: 0.5012159943580627, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 372, Validation Loss: 0.5125585198402405, Validation Accuracy: 0.97\n",
            "Epoch: 372, Testing Loss: 0.5350887775421143, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 373, Training Loss: 0.5012103915214539, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 373, Validation Loss: 0.5125483870506287, Validation Accuracy: 0.97\n",
            "Epoch: 373, Testing Loss: 0.5350852012634277, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 374, Training Loss: 0.501204788684845, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 374, Validation Loss: 0.5125381946563721, Validation Accuracy: 0.97\n",
            "Epoch: 374, Testing Loss: 0.5350815057754517, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 375, Training Loss: 0.5011992454528809, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 375, Validation Loss: 0.5125281810760498, Validation Accuracy: 0.97\n",
            "Epoch: 375, Testing Loss: 0.5350776314735413, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 376, Training Loss: 0.5011937022209167, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 376, Validation Loss: 0.5125181078910828, Validation Accuracy: 0.97\n",
            "Epoch: 376, Testing Loss: 0.5350735187530518, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 377, Training Loss: 0.5011882185935974, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 377, Validation Loss: 0.5125081539154053, Validation Accuracy: 0.97\n",
            "Epoch: 377, Testing Loss: 0.5350694060325623, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 378, Training Loss: 0.5011827349662781, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 378, Validation Loss: 0.5124981999397278, Validation Accuracy: 0.97\n",
            "Epoch: 378, Testing Loss: 0.5350651144981384, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 379, Training Loss: 0.5011772513389587, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 379, Validation Loss: 0.5124883651733398, Validation Accuracy: 0.97\n",
            "Epoch: 379, Testing Loss: 0.5350605845451355, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 380, Training Loss: 0.5011718273162842, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 380, Validation Loss: 0.5124785304069519, Validation Accuracy: 0.97\n",
            "Epoch: 380, Testing Loss: 0.5350559949874878, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 381, Training Loss: 0.5011664628982544, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 381, Validation Loss: 0.5124687552452087, Validation Accuracy: 0.97\n",
            "Epoch: 381, Testing Loss: 0.5350512266159058, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 382, Training Loss: 0.5011610984802246, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 382, Validation Loss: 0.5124590396881104, Validation Accuracy: 0.97\n",
            "Epoch: 382, Testing Loss: 0.535046398639679, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 383, Training Loss: 0.5011557340621948, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 383, Validation Loss: 0.5124493837356567, Validation Accuracy: 0.97\n",
            "Epoch: 383, Testing Loss: 0.535041332244873, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 384, Training Loss: 0.501150369644165, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 384, Validation Loss: 0.5124398469924927, Validation Accuracy: 0.97\n",
            "Epoch: 384, Testing Loss: 0.5350362062454224, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 385, Training Loss: 0.50114506483078, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 385, Validation Loss: 0.5124303102493286, Validation Accuracy: 0.97\n",
            "Epoch: 385, Testing Loss: 0.5350309014320374, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 386, Training Loss: 0.5011398196220398, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 386, Validation Loss: 0.5124208331108093, Validation Accuracy: 0.97\n",
            "Epoch: 386, Testing Loss: 0.5350255370140076, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 387, Training Loss: 0.5011345148086548, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 387, Validation Loss: 0.5124114751815796, Validation Accuracy: 0.97\n",
            "Epoch: 387, Testing Loss: 0.5350200533866882, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 388, Training Loss: 0.5011293292045593, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 388, Validation Loss: 0.5124021172523499, Validation Accuracy: 0.97\n",
            "Epoch: 388, Testing Loss: 0.5350143909454346, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 389, Training Loss: 0.5011240839958191, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 389, Validation Loss: 0.5123928189277649, Validation Accuracy: 0.97\n",
            "Epoch: 389, Testing Loss: 0.5350085496902466, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 390, Training Loss: 0.5011188387870789, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 390, Validation Loss: 0.5123836398124695, Validation Accuracy: 0.97\n",
            "Epoch: 390, Testing Loss: 0.5350027084350586, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 391, Training Loss: 0.5011137127876282, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 391, Validation Loss: 0.5123745203018188, Validation Accuracy: 0.97\n",
            "Epoch: 391, Testing Loss: 0.5349966287612915, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 392, Training Loss: 0.5011085867881775, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 392, Validation Loss: 0.512365460395813, Validation Accuracy: 0.97\n",
            "Epoch: 392, Testing Loss: 0.5349904894828796, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 393, Training Loss: 0.5011034607887268, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 393, Validation Loss: 0.5123565196990967, Validation Accuracy: 0.97\n",
            "Epoch: 393, Testing Loss: 0.534984290599823, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 394, Training Loss: 0.5010983347892761, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 394, Validation Loss: 0.5123475790023804, Validation Accuracy: 0.97\n",
            "Epoch: 394, Testing Loss: 0.5349778532981873, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 395, Training Loss: 0.5010932683944702, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 395, Validation Loss: 0.5123387575149536, Validation Accuracy: 0.97\n",
            "Epoch: 395, Testing Loss: 0.5349713563919067, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 396, Training Loss: 0.5010882019996643, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 396, Validation Loss: 0.5123299956321716, Validation Accuracy: 0.97\n",
            "Epoch: 396, Testing Loss: 0.5349647402763367, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 397, Training Loss: 0.5010831952095032, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 397, Validation Loss: 0.5123212933540344, Validation Accuracy: 0.97\n",
            "Epoch: 397, Testing Loss: 0.534958004951477, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 398, Training Loss: 0.5010781288146973, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 398, Validation Loss: 0.5123127102851868, Validation Accuracy: 0.97\n",
            "Epoch: 398, Testing Loss: 0.5349511504173279, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 399, Training Loss: 0.5010732412338257, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 399, Validation Loss: 0.5123041868209839, Validation Accuracy: 0.97\n",
            "Epoch: 399, Testing Loss: 0.5349441766738892, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 400, Training Loss: 0.5010682344436646, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 400, Validation Loss: 0.5122957229614258, Validation Accuracy: 0.97\n",
            "Epoch: 400, Testing Loss: 0.5349371433258057, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 401, Training Loss: 0.5010632872581482, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 401, Validation Loss: 0.5122873783111572, Validation Accuracy: 0.97\n",
            "Epoch: 401, Testing Loss: 0.5349299907684326, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 402, Training Loss: 0.5010583996772766, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 402, Validation Loss: 0.5122790932655334, Validation Accuracy: 0.97\n",
            "Epoch: 402, Testing Loss: 0.5349226593971252, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 403, Training Loss: 0.5010534524917603, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 403, Validation Loss: 0.5122709274291992, Validation Accuracy: 0.97\n",
            "Epoch: 403, Testing Loss: 0.5349152684211731, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 404, Training Loss: 0.5010485649108887, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 404, Validation Loss: 0.5122628211975098, Validation Accuracy: 0.97\n",
            "Epoch: 404, Testing Loss: 0.5349078178405762, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 405, Training Loss: 0.5010437369346619, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 405, Validation Loss: 0.5122547745704651, Validation Accuracy: 0.97\n",
            "Epoch: 405, Testing Loss: 0.5349001288414001, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 406, Training Loss: 0.5010389089584351, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 406, Validation Loss: 0.51224684715271, Validation Accuracy: 0.97\n",
            "Epoch: 406, Testing Loss: 0.5348923802375793, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 407, Training Loss: 0.501034140586853, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 407, Validation Loss: 0.5122389793395996, Validation Accuracy: 0.97\n",
            "Epoch: 407, Testing Loss: 0.534884512424469, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 408, Training Loss: 0.5010293126106262, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 408, Validation Loss: 0.512231171131134, Validation Accuracy: 0.97\n",
            "Epoch: 408, Testing Loss: 0.5348765254020691, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 409, Training Loss: 0.5010245442390442, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 409, Validation Loss: 0.512223482131958, Validation Accuracy: 0.97\n",
            "Epoch: 409, Testing Loss: 0.5348684191703796, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 410, Training Loss: 0.5010198354721069, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 410, Validation Loss: 0.5122159123420715, Validation Accuracy: 0.97\n",
            "Epoch: 410, Testing Loss: 0.534833550453186, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 411, Training Loss: 0.5010150671005249, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 411, Validation Loss: 0.5122084617614746, Validation Accuracy: 0.97\n",
            "Epoch: 411, Testing Loss: 0.5348519682884216, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 412, Training Loss: 0.5010103583335876, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 412, Validation Loss: 0.5122010111808777, Validation Accuracy: 0.97\n",
            "Epoch: 412, Testing Loss: 0.5348435044288635, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 413, Training Loss: 0.5010056495666504, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 413, Validation Loss: 0.5121937394142151, Validation Accuracy: 0.97\n",
            "Epoch: 413, Testing Loss: 0.5348349809646606, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 414, Training Loss: 0.5010009407997131, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 414, Validation Loss: 0.5121864676475525, Validation Accuracy: 0.97\n",
            "Epoch: 414, Testing Loss: 0.5348263382911682, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 415, Training Loss: 0.5009962916374207, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 415, Validation Loss: 0.5121793150901794, Validation Accuracy: 0.97\n",
            "Epoch: 415, Testing Loss: 0.5348175764083862, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 416, Training Loss: 0.500991702079773, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 416, Validation Loss: 0.5121723413467407, Validation Accuracy: 0.97\n",
            "Epoch: 416, Testing Loss: 0.5348086357116699, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 417, Training Loss: 0.5009871125221252, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 417, Validation Loss: 0.5121654272079468, Validation Accuracy: 0.97\n",
            "Epoch: 417, Testing Loss: 0.5347996354103088, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 418, Training Loss: 0.5009824633598328, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 418, Validation Loss: 0.5121585726737976, Validation Accuracy: 0.97\n",
            "Epoch: 418, Testing Loss: 0.5347905158996582, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 419, Training Loss: 0.5009779334068298, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 419, Validation Loss: 0.512151837348938, Validation Accuracy: 0.97\n",
            "Epoch: 419, Testing Loss: 0.5347812175750732, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 420, Training Loss: 0.5009733438491821, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 420, Validation Loss: 0.5121451616287231, Validation Accuracy: 0.97\n",
            "Epoch: 420, Testing Loss: 0.5347718596458435, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 421, Training Loss: 0.5009687542915344, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 421, Validation Loss: 0.5121386051177979, Validation Accuracy: 0.97\n",
            "Epoch: 421, Testing Loss: 0.5347622632980347, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 422, Training Loss: 0.500964343547821, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 422, Validation Loss: 0.5121321678161621, Validation Accuracy: 0.97\n",
            "Epoch: 422, Testing Loss: 0.5347525477409363, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 423, Training Loss: 0.5009598135948181, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 423, Validation Loss: 0.5121257901191711, Validation Accuracy: 0.97\n",
            "Epoch: 423, Testing Loss: 0.5347428321838379, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 424, Training Loss: 0.50095534324646, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 424, Validation Loss: 0.5121195316314697, Validation Accuracy: 0.97\n",
            "Epoch: 424, Testing Loss: 0.5347328782081604, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 425, Training Loss: 0.5009508728981018, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 425, Validation Loss: 0.5121134519577026, Validation Accuracy: 0.97\n",
            "Epoch: 425, Testing Loss: 0.5347228050231934, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 426, Training Loss: 0.5009464621543884, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 426, Validation Loss: 0.5121073722839355, Validation Accuracy: 0.97\n",
            "Epoch: 426, Testing Loss: 0.5347126126289368, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 427, Training Loss: 0.5009419918060303, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 427, Validation Loss: 0.5121014714241028, Validation Accuracy: 0.97\n",
            "Epoch: 427, Testing Loss: 0.5347022414207458, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 428, Training Loss: 0.5009376406669617, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 428, Validation Loss: 0.5120956301689148, Validation Accuracy: 0.97\n",
            "Epoch: 428, Testing Loss: 0.5346916317939758, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 429, Training Loss: 0.5009332299232483, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 429, Validation Loss: 0.5120899081230164, Validation Accuracy: 0.97\n",
            "Epoch: 429, Testing Loss: 0.5346810221672058, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 430, Training Loss: 0.5009289383888245, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 430, Validation Loss: 0.5120842456817627, Validation Accuracy: 0.97\n",
            "Epoch: 430, Testing Loss: 0.5346701741218567, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 431, Training Loss: 0.5009245872497559, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 431, Validation Loss: 0.5120787620544434, Validation Accuracy: 0.97\n",
            "Epoch: 431, Testing Loss: 0.534659206867218, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 432, Training Loss: 0.5009202361106873, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 432, Validation Loss: 0.5120733976364136, Validation Accuracy: 0.97\n",
            "Epoch: 432, Testing Loss: 0.534648060798645, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 433, Training Loss: 0.5009159445762634, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 433, Validation Loss: 0.5120680928230286, Validation Accuracy: 0.97\n",
            "Epoch: 433, Testing Loss: 0.5346367955207825, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 434, Training Loss: 0.5009116530418396, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 434, Validation Loss: 0.5120628476142883, Validation Accuracy: 0.97\n",
            "Epoch: 434, Testing Loss: 0.5346252918243408, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 435, Training Loss: 0.5009074211120605, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 435, Validation Loss: 0.5120578408241272, Validation Accuracy: 0.97\n",
            "Epoch: 435, Testing Loss: 0.5346136093139648, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 436, Training Loss: 0.5009031891822815, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 436, Validation Loss: 0.5120528936386108, Validation Accuracy: 0.97\n",
            "Epoch: 436, Testing Loss: 0.5346018075942993, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 437, Training Loss: 0.5008989572525024, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 437, Validation Loss: 0.5120479464530945, Validation Accuracy: 0.97\n",
            "Epoch: 437, Testing Loss: 0.5345898270606995, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 438, Training Loss: 0.5008947849273682, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 438, Validation Loss: 0.5120431780815125, Validation Accuracy: 0.97\n",
            "Epoch: 438, Testing Loss: 0.5345776677131653, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 439, Training Loss: 0.5008906126022339, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 439, Validation Loss: 0.5120385885238647, Validation Accuracy: 0.97\n",
            "Epoch: 439, Testing Loss: 0.5345653891563416, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 440, Training Loss: 0.5008864998817444, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 440, Validation Loss: 0.5120340585708618, Validation Accuracy: 0.97\n",
            "Epoch: 440, Testing Loss: 0.5345528721809387, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 441, Training Loss: 0.5008823275566101, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 441, Validation Loss: 0.5120297074317932, Validation Accuracy: 0.97\n",
            "Epoch: 441, Testing Loss: 0.5345401763916016, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 442, Training Loss: 0.5008782148361206, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 442, Validation Loss: 0.5120253562927246, Validation Accuracy: 0.97\n",
            "Epoch: 442, Testing Loss: 0.5345273017883301, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 443, Training Loss: 0.5008741617202759, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 443, Validation Loss: 0.5120211839675903, Validation Accuracy: 0.97\n",
            "Epoch: 443, Testing Loss: 0.534514307975769, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 444, Training Loss: 0.5008701086044312, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 444, Validation Loss: 0.5120170712471008, Validation Accuracy: 0.97\n",
            "Epoch: 444, Testing Loss: 0.5345010757446289, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 445, Training Loss: 0.5008661150932312, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 445, Validation Loss: 0.5120130777359009, Validation Accuracy: 0.97\n",
            "Epoch: 445, Testing Loss: 0.5344877243041992, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 446, Training Loss: 0.5008620619773865, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 446, Validation Loss: 0.5120092630386353, Validation Accuracy: 0.97\n",
            "Epoch: 446, Testing Loss: 0.53447425365448, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 447, Training Loss: 0.5008580684661865, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 447, Validation Loss: 0.5120054483413696, Validation Accuracy: 0.97\n",
            "Epoch: 447, Testing Loss: 0.5344605445861816, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 448, Training Loss: 0.5008541345596313, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 448, Validation Loss: 0.5120018124580383, Validation Accuracy: 0.97\n",
            "Epoch: 448, Testing Loss: 0.5344467759132385, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 449, Training Loss: 0.5008501410484314, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 449, Validation Loss: 0.5119982361793518, Validation Accuracy: 0.97\n",
            "Epoch: 449, Testing Loss: 0.5344327688217163, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 450, Training Loss: 0.500846266746521, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 450, Validation Loss: 0.5119947195053101, Validation Accuracy: 0.97\n",
            "Epoch: 450, Testing Loss: 0.5344186425209045, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 451, Training Loss: 0.5008423924446106, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 451, Validation Loss: 0.5119913816452026, Validation Accuracy: 0.97\n",
            "Epoch: 451, Testing Loss: 0.534404456615448, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 452, Training Loss: 0.5008385181427002, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 452, Validation Loss: 0.5119951367378235, Validation Accuracy: 0.97\n",
            "Epoch: 452, Testing Loss: 0.5343902111053467, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 453, Training Loss: 0.5008347034454346, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 453, Validation Loss: 0.5119848847389221, Validation Accuracy: 0.98\n",
            "Epoch: 453, Testing Loss: 0.5343757271766663, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 454, Training Loss: 0.500830888748169, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 454, Validation Loss: 0.5119817852973938, Validation Accuracy: 0.98\n",
            "Epoch: 454, Testing Loss: 0.5343613028526306, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 455, Training Loss: 0.5008270740509033, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 455, Validation Loss: 0.5119787454605103, Validation Accuracy: 0.98\n",
            "Epoch: 455, Testing Loss: 0.5343468189239502, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 456, Training Loss: 0.5008233189582825, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 456, Validation Loss: 0.5119757056236267, Validation Accuracy: 0.98\n",
            "Epoch: 456, Testing Loss: 0.5343322157859802, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 457, Training Loss: 0.5008195638656616, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 457, Validation Loss: 0.5119801759719849, Validation Accuracy: 0.98\n",
            "Epoch: 457, Testing Loss: 0.5343106389045715, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 458, Training Loss: 0.5008158683776855, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 458, Validation Loss: 0.5119698643684387, Validation Accuracy: 0.98\n",
            "Epoch: 458, Testing Loss: 0.5343031883239746, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 459, Training Loss: 0.5008121728897095, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 459, Validation Loss: 0.5119669437408447, Validation Accuracy: 0.98\n",
            "Epoch: 459, Testing Loss: 0.534288763999939, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 460, Training Loss: 0.5008085370063782, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 460, Validation Loss: 0.5119641423225403, Validation Accuracy: 0.98\n",
            "Epoch: 460, Testing Loss: 0.5342743992805481, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 461, Training Loss: 0.5008049607276917, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 461, Validation Loss: 0.5119613409042358, Validation Accuracy: 0.98\n",
            "Epoch: 461, Testing Loss: 0.534260094165802, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 462, Training Loss: 0.5008013248443604, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 462, Validation Loss: 0.5119584798812866, Validation Accuracy: 0.98\n",
            "Epoch: 462, Testing Loss: 0.5342460870742798, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 463, Training Loss: 0.5007977485656738, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 463, Validation Loss: 0.5119556784629822, Validation Accuracy: 0.98\n",
            "Epoch: 463, Testing Loss: 0.5342320799827576, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 464, Training Loss: 0.5007941722869873, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 464, Validation Loss: 0.5119528770446777, Validation Accuracy: 0.98\n",
            "Epoch: 464, Testing Loss: 0.5342184901237488, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 465, Training Loss: 0.5007906556129456, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 465, Validation Loss: 0.5119499564170837, Validation Accuracy: 0.98\n",
            "Epoch: 465, Testing Loss: 0.5342050194740295, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 466, Training Loss: 0.5007871985435486, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 466, Validation Loss: 0.5119470357894897, Validation Accuracy: 0.98\n",
            "Epoch: 466, Testing Loss: 0.534191906452179, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 467, Training Loss: 0.5007836818695068, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 467, Validation Loss: 0.5119439959526062, Validation Accuracy: 0.98\n",
            "Epoch: 467, Testing Loss: 0.5341790318489075, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 468, Training Loss: 0.5007802248001099, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 468, Validation Loss: 0.5119409561157227, Validation Accuracy: 0.98\n",
            "Epoch: 468, Testing Loss: 0.5341665744781494, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 469, Training Loss: 0.5007767677307129, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 469, Validation Loss: 0.5119378566741943, Validation Accuracy: 0.98\n",
            "Epoch: 469, Testing Loss: 0.5341545343399048, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 470, Training Loss: 0.5007733702659607, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 470, Validation Loss: 0.5119346380233765, Validation Accuracy: 0.98\n",
            "Epoch: 470, Testing Loss: 0.5341428518295288, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 471, Training Loss: 0.5007699131965637, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 471, Validation Loss: 0.5119312405586243, Validation Accuracy: 0.98\n",
            "Epoch: 471, Testing Loss: 0.5341315865516663, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 472, Training Loss: 0.5007665157318115, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 472, Validation Loss: 0.5119277834892273, Validation Accuracy: 0.98\n",
            "Epoch: 472, Testing Loss: 0.5341207385063171, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 473, Training Loss: 0.5007631778717041, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 473, Validation Loss: 0.5119242072105408, Validation Accuracy: 0.98\n",
            "Epoch: 473, Testing Loss: 0.534110426902771, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 474, Training Loss: 0.5007598400115967, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 474, Validation Loss: 0.5119205117225647, Validation Accuracy: 0.98\n",
            "Epoch: 474, Testing Loss: 0.5341005325317383, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 475, Training Loss: 0.5007565021514893, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 475, Validation Loss: 0.5119166970252991, Validation Accuracy: 0.98\n",
            "Epoch: 475, Testing Loss: 0.534091055393219, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 476, Training Loss: 0.5007531642913818, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 476, Validation Loss: 0.5119127035140991, Validation Accuracy: 0.98\n",
            "Epoch: 476, Testing Loss: 0.5340822339057922, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 477, Training Loss: 0.5007498860359192, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 477, Validation Loss: 0.5119085907936096, Validation Accuracy: 0.98\n",
            "Epoch: 477, Testing Loss: 0.5340737700462341, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 478, Training Loss: 0.5007465481758118, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 478, Validation Loss: 0.5119043588638306, Validation Accuracy: 0.98\n",
            "Epoch: 478, Testing Loss: 0.534065842628479, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 479, Training Loss: 0.5007432699203491, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 479, Validation Loss: 0.511900007724762, Validation Accuracy: 0.98\n",
            "Epoch: 479, Testing Loss: 0.5340583324432373, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 480, Training Loss: 0.5007399916648865, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 480, Validation Loss: 0.511895477771759, Validation Accuracy: 0.98\n",
            "Epoch: 480, Testing Loss: 0.5340512990951538, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 481, Training Loss: 0.5007367134094238, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 481, Validation Loss: 0.5118908286094666, Validation Accuracy: 0.98\n",
            "Epoch: 481, Testing Loss: 0.5340447425842285, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 482, Training Loss: 0.5007334351539612, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 482, Validation Loss: 0.5118861198425293, Validation Accuracy: 0.98\n",
            "Epoch: 482, Testing Loss: 0.5340385437011719, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 483, Training Loss: 0.5007301568984985, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 483, Validation Loss: 0.5118812322616577, Validation Accuracy: 0.98\n",
            "Epoch: 483, Testing Loss: 0.5340328812599182, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 484, Training Loss: 0.5007268786430359, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 484, Validation Loss: 0.5118761658668518, Validation Accuracy: 0.98\n",
            "Epoch: 484, Testing Loss: 0.5340275764465332, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 485, Training Loss: 0.5007236003875732, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 485, Validation Loss: 0.5118710398674011, Validation Accuracy: 0.98\n",
            "Epoch: 485, Testing Loss: 0.5340226888656616, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 486, Training Loss: 0.5007203817367554, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 486, Validation Loss: 0.5118657946586609, Validation Accuracy: 0.98\n",
            "Epoch: 486, Testing Loss: 0.5340181589126587, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 487, Training Loss: 0.5007171034812927, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 487, Validation Loss: 0.5118604898452759, Validation Accuracy: 0.98\n",
            "Epoch: 487, Testing Loss: 0.5340139269828796, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 488, Training Loss: 0.5007138252258301, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 488, Validation Loss: 0.5118549466133118, Validation Accuracy: 0.98\n",
            "Epoch: 488, Testing Loss: 0.5340101718902588, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 489, Training Loss: 0.5007105469703674, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 489, Validation Loss: 0.5118494629859924, Validation Accuracy: 0.98\n",
            "Epoch: 489, Testing Loss: 0.534006655216217, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 490, Training Loss: 0.5007073283195496, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 490, Validation Loss: 0.5118438601493835, Validation Accuracy: 0.98\n",
            "Epoch: 490, Testing Loss: 0.5340035557746887, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 491, Training Loss: 0.5007040500640869, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 491, Validation Loss: 0.5118381381034851, Validation Accuracy: 0.98\n",
            "Epoch: 491, Testing Loss: 0.53400057554245, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 492, Training Loss: 0.500700831413269, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 492, Validation Loss: 0.5118322968482971, Validation Accuracy: 0.98\n",
            "Epoch: 492, Testing Loss: 0.5339980721473694, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 493, Training Loss: 0.5006975531578064, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 493, Validation Loss: 0.5118265151977539, Validation Accuracy: 0.98\n",
            "Epoch: 493, Testing Loss: 0.5339957475662231, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 494, Training Loss: 0.5006943345069885, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 494, Validation Loss: 0.5118205547332764, Validation Accuracy: 0.98\n",
            "Epoch: 494, Testing Loss: 0.533993661403656, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 495, Training Loss: 0.5006910562515259, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 495, Validation Loss: 0.5118145942687988, Validation Accuracy: 0.98\n",
            "Epoch: 495, Testing Loss: 0.5339918732643127, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 496, Training Loss: 0.500687837600708, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 496, Validation Loss: 0.5118085741996765, Validation Accuracy: 0.98\n",
            "Epoch: 496, Testing Loss: 0.5339903831481934, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 497, Training Loss: 0.5006845593452454, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 497, Validation Loss: 0.5118024945259094, Validation Accuracy: 0.98\n",
            "Epoch: 497, Testing Loss: 0.5339890718460083, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 498, Training Loss: 0.5006812810897827, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 498, Validation Loss: 0.5117964148521423, Validation Accuracy: 0.98\n",
            "Epoch: 498, Testing Loss: 0.5339879393577576, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 499, Training Loss: 0.5006780624389648, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 499, Validation Loss: 0.5117902159690857, Validation Accuracy: 0.98\n",
            "Epoch: 499, Testing Loss: 0.5339871048927307, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 500, Training Loss: 0.5006747841835022, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 500, Validation Loss: 0.5117840766906738, Validation Accuracy: 0.98\n",
            "Epoch: 500, Testing Loss: 0.533986508846283, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 501, Training Loss: 0.5006715655326843, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 501, Validation Loss: 0.5117778182029724, Validation Accuracy: 0.98\n",
            "Epoch: 501, Testing Loss: 0.5339860320091248, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 502, Training Loss: 0.5006683468818665, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 502, Validation Loss: 0.5117716193199158, Validation Accuracy: 0.98\n",
            "Epoch: 502, Testing Loss: 0.5339859127998352, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 503, Training Loss: 0.5006650686264038, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 503, Validation Loss: 0.5117653012275696, Validation Accuracy: 0.98\n",
            "Epoch: 503, Testing Loss: 0.5339858531951904, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 504, Training Loss: 0.5006618499755859, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 504, Validation Loss: 0.5117590427398682, Validation Accuracy: 0.98\n",
            "Epoch: 504, Testing Loss: 0.5339860916137695, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 505, Training Loss: 0.5006586313247681, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 505, Validation Loss: 0.511752724647522, Validation Accuracy: 0.98\n",
            "Epoch: 505, Testing Loss: 0.533986508846283, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 506, Training Loss: 0.5006554126739502, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 506, Validation Loss: 0.5117464065551758, Validation Accuracy: 0.98\n",
            "Epoch: 506, Testing Loss: 0.5339871644973755, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 507, Training Loss: 0.5006521940231323, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 507, Validation Loss: 0.5117400288581848, Validation Accuracy: 0.98\n",
            "Epoch: 507, Testing Loss: 0.5339879989624023, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 508, Training Loss: 0.5006489753723145, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 508, Validation Loss: 0.5117336511611938, Validation Accuracy: 0.98\n",
            "Epoch: 508, Testing Loss: 0.5339890718460083, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 509, Training Loss: 0.5006457567214966, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 509, Validation Loss: 0.5117272734642029, Validation Accuracy: 0.98\n",
            "Epoch: 509, Testing Loss: 0.5339903235435486, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 510, Training Loss: 0.5006425380706787, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 510, Validation Loss: 0.5117208957672119, Validation Accuracy: 0.98\n",
            "Epoch: 510, Testing Loss: 0.5339918732643127, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 511, Training Loss: 0.5006393790245056, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 511, Validation Loss: 0.5117144584655762, Validation Accuracy: 0.98\n",
            "Epoch: 511, Testing Loss: 0.5339935421943665, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 512, Training Loss: 0.5006362199783325, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 512, Validation Loss: 0.5117080211639404, Validation Accuracy: 0.98\n",
            "Epoch: 512, Testing Loss: 0.533995509147644, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 513, Training Loss: 0.5006330013275146, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 513, Validation Loss: 0.5117015838623047, Validation Accuracy: 0.98\n",
            "Epoch: 513, Testing Loss: 0.533997654914856, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 514, Training Loss: 0.5006298422813416, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 514, Validation Loss: 0.5116950869560242, Validation Accuracy: 0.98\n",
            "Epoch: 514, Testing Loss: 0.534000039100647, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 515, Training Loss: 0.5006266832351685, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 515, Validation Loss: 0.5116885900497437, Validation Accuracy: 0.98\n",
            "Epoch: 515, Testing Loss: 0.5340026617050171, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 516, Training Loss: 0.5006235837936401, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 516, Validation Loss: 0.5116820335388184, Validation Accuracy: 0.98\n",
            "Epoch: 516, Testing Loss: 0.5340056419372559, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 517, Training Loss: 0.500620424747467, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 517, Validation Loss: 0.5116755366325378, Validation Accuracy: 0.98\n",
            "Epoch: 517, Testing Loss: 0.5340088605880737, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 518, Training Loss: 0.500617265701294, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 518, Validation Loss: 0.5116689801216125, Validation Accuracy: 0.98\n",
            "Epoch: 518, Testing Loss: 0.5340122580528259, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 519, Training Loss: 0.5006141662597656, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 519, Validation Loss: 0.5116623044013977, Validation Accuracy: 0.98\n",
            "Epoch: 519, Testing Loss: 0.534015953540802, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 520, Training Loss: 0.5006111264228821, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 520, Validation Loss: 0.5116557478904724, Validation Accuracy: 0.98\n",
            "Epoch: 520, Testing Loss: 0.534019947052002, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 521, Training Loss: 0.5006080269813538, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 521, Validation Loss: 0.5116490721702576, Validation Accuracy: 0.98\n",
            "Epoch: 521, Testing Loss: 0.5340242385864258, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 522, Training Loss: 0.5006048679351807, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 522, Validation Loss: 0.5116423964500427, Validation Accuracy: 0.98\n",
            "Epoch: 522, Testing Loss: 0.534028947353363, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 523, Training Loss: 0.5006018280982971, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 523, Validation Loss: 0.5116356611251831, Validation Accuracy: 0.98\n",
            "Epoch: 523, Testing Loss: 0.5340338349342346, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 524, Training Loss: 0.5005987882614136, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 524, Validation Loss: 0.5116288661956787, Validation Accuracy: 0.98\n",
            "Epoch: 524, Testing Loss: 0.5340390205383301, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 525, Training Loss: 0.50059574842453, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 525, Validation Loss: 0.5116220712661743, Validation Accuracy: 0.98\n",
            "Epoch: 525, Testing Loss: 0.5340446829795837, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 526, Training Loss: 0.5005927681922913, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 526, Validation Loss: 0.5116152167320251, Validation Accuracy: 0.98\n",
            "Epoch: 526, Testing Loss: 0.5340505838394165, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 527, Training Loss: 0.5005897879600525, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 527, Validation Loss: 0.5116083025932312, Validation Accuracy: 0.98\n",
            "Epoch: 527, Testing Loss: 0.5340569019317627, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 528, Training Loss: 0.500586748123169, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 528, Validation Loss: 0.5116012692451477, Validation Accuracy: 0.98\n",
            "Epoch: 528, Testing Loss: 0.5340635776519775, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 529, Training Loss: 0.500583827495575, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 529, Validation Loss: 0.511594295501709, Validation Accuracy: 0.98\n",
            "Epoch: 529, Testing Loss: 0.5340705513954163, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 530, Training Loss: 0.5005808472633362, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 530, Validation Loss: 0.5115870833396912, Validation Accuracy: 0.98\n",
            "Epoch: 530, Testing Loss: 0.534078061580658, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 531, Training Loss: 0.500577986240387, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 531, Validation Loss: 0.5115799307823181, Validation Accuracy: 0.98\n",
            "Epoch: 531, Testing Loss: 0.5340859293937683, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 532, Training Loss: 0.500575065612793, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 532, Validation Loss: 0.5115726590156555, Validation Accuracy: 0.98\n",
            "Epoch: 532, Testing Loss: 0.5340942144393921, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 533, Training Loss: 0.500572144985199, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 533, Validation Loss: 0.5115652680397034, Validation Accuracy: 0.98\n",
            "Epoch: 533, Testing Loss: 0.5341029763221741, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 534, Training Loss: 0.5005692839622498, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 534, Validation Loss: 0.5115578770637512, Validation Accuracy: 0.98\n",
            "Epoch: 534, Testing Loss: 0.5341121554374695, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 535, Training Loss: 0.5005664825439453, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 535, Validation Loss: 0.5115503072738647, Validation Accuracy: 0.98\n",
            "Epoch: 535, Testing Loss: 0.5341217517852783, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 536, Training Loss: 0.5005636811256409, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 536, Validation Loss: 0.5115426778793335, Validation Accuracy: 0.98\n",
            "Epoch: 536, Testing Loss: 0.5341318845748901, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 537, Training Loss: 0.5005608797073364, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 537, Validation Loss: 0.5115349292755127, Validation Accuracy: 0.98\n",
            "Epoch: 537, Testing Loss: 0.5341425538063049, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 538, Training Loss: 0.500558078289032, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 538, Validation Loss: 0.5115270614624023, Validation Accuracy: 0.98\n",
            "Epoch: 538, Testing Loss: 0.5341536402702332, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 539, Training Loss: 0.5005553364753723, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 539, Validation Loss: 0.5115190744400024, Validation Accuracy: 0.98\n",
            "Epoch: 539, Testing Loss: 0.5341653823852539, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 540, Training Loss: 0.5005526542663574, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 540, Validation Loss: 0.5115109086036682, Validation Accuracy: 0.98\n",
            "Epoch: 540, Testing Loss: 0.5341774821281433, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 541, Training Loss: 0.5005499720573425, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 541, Validation Loss: 0.5115026235580444, Validation Accuracy: 0.98\n",
            "Epoch: 541, Testing Loss: 0.5341902375221252, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 542, Training Loss: 0.5005473494529724, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 542, Validation Loss: 0.5114942789077759, Validation Accuracy: 0.98\n",
            "Epoch: 542, Testing Loss: 0.5342034697532654, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 543, Training Loss: 0.5005447268486023, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 543, Validation Loss: 0.5114856958389282, Validation Accuracy: 0.98\n",
            "Epoch: 543, Testing Loss: 0.5342172384262085, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 544, Training Loss: 0.500542163848877, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 544, Validation Loss: 0.5114770531654358, Validation Accuracy: 0.98\n",
            "Epoch: 544, Testing Loss: 0.5342316031455994, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 545, Training Loss: 0.5005396008491516, Training Accuracy: 0.9793103448275862\n",
            "Epoch: 545, Validation Loss: 0.5114681720733643, Validation Accuracy: 0.98\n",
            "Epoch: 545, Testing Loss: 0.5342466235160828, Testing Accuracy: 0.9793103448275862\n",
            "Epoch: 546, Training Loss: 0.5005370378494263, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 546, Validation Loss: 0.5114591717720032, Validation Accuracy: 0.98\n",
            "Epoch: 546, Testing Loss: 0.5342621207237244, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 547, Training Loss: 0.5005345940589905, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 547, Validation Loss: 0.5114500522613525, Validation Accuracy: 0.98\n",
            "Epoch: 547, Testing Loss: 0.5342782139778137, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 548, Training Loss: 0.5005321502685547, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 548, Validation Loss: 0.5114406943321228, Validation Accuracy: 0.98\n",
            "Epoch: 548, Testing Loss: 0.5342947244644165, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 549, Training Loss: 0.5005297064781189, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 549, Validation Loss: 0.5114312171936035, Validation Accuracy: 0.98\n",
            "Epoch: 549, Testing Loss: 0.5343118906021118, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 550, Training Loss: 0.5005273222923279, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 550, Validation Loss: 0.5114216208457947, Validation Accuracy: 0.98\n",
            "Epoch: 550, Testing Loss: 0.5343039631843567, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 551, Training Loss: 0.5005249977111816, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 551, Validation Loss: 0.5114118456840515, Validation Accuracy: 0.98\n",
            "Epoch: 551, Testing Loss: 0.5343477725982666, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 552, Training Loss: 0.5005227327346802, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 552, Validation Loss: 0.511401891708374, Validation Accuracy: 0.98\n",
            "Epoch: 552, Testing Loss: 0.5343664884567261, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 553, Training Loss: 0.5005204677581787, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 553, Validation Loss: 0.5113917589187622, Validation Accuracy: 0.98\n",
            "Epoch: 553, Testing Loss: 0.534385621547699, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 554, Training Loss: 0.500518262386322, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 554, Validation Loss: 0.5113815069198608, Validation Accuracy: 0.98\n",
            "Epoch: 554, Testing Loss: 0.5344052314758301, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 555, Training Loss: 0.5005160570144653, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 555, Validation Loss: 0.5113711357116699, Validation Accuracy: 0.98\n",
            "Epoch: 555, Testing Loss: 0.5344250798225403, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 556, Training Loss: 0.5005139708518982, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 556, Validation Loss: 0.5113605260848999, Validation Accuracy: 0.98\n",
            "Epoch: 556, Testing Loss: 0.5344454050064087, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 557, Training Loss: 0.500511884689331, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 557, Validation Loss: 0.5113499164581299, Validation Accuracy: 0.98\n",
            "Epoch: 557, Testing Loss: 0.534466028213501, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 558, Training Loss: 0.5005097985267639, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 558, Validation Loss: 0.5113391280174255, Validation Accuracy: 0.98\n",
            "Epoch: 558, Testing Loss: 0.5344868898391724, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 559, Training Loss: 0.5005077719688416, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 559, Validation Loss: 0.5113283395767212, Validation Accuracy: 0.98\n",
            "Epoch: 559, Testing Loss: 0.5345079302787781, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 560, Training Loss: 0.5005057454109192, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 560, Validation Loss: 0.5113174319267273, Validation Accuracy: 0.98\n",
            "Epoch: 560, Testing Loss: 0.5345290899276733, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 561, Training Loss: 0.5005037784576416, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 561, Validation Loss: 0.5113064050674438, Validation Accuracy: 0.98\n",
            "Epoch: 561, Testing Loss: 0.5345503091812134, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 562, Training Loss: 0.500501811504364, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 562, Validation Loss: 0.5112953782081604, Validation Accuracy: 0.98\n",
            "Epoch: 562, Testing Loss: 0.5345715880393982, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 563, Training Loss: 0.5004999041557312, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 563, Validation Loss: 0.5112842321395874, Validation Accuracy: 0.98\n",
            "Epoch: 563, Testing Loss: 0.5345927476882935, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 564, Training Loss: 0.5004979372024536, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 564, Validation Loss: 0.5112731456756592, Validation Accuracy: 0.98\n",
            "Epoch: 564, Testing Loss: 0.5346137881278992, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 565, Training Loss: 0.5004960298538208, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 565, Validation Loss: 0.5112619996070862, Validation Accuracy: 0.98\n",
            "Epoch: 565, Testing Loss: 0.5346345901489258, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 566, Training Loss: 0.500494122505188, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 566, Validation Loss: 0.5112509727478027, Validation Accuracy: 0.98\n",
            "Epoch: 566, Testing Loss: 0.5346551537513733, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 567, Training Loss: 0.5004921555519104, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 567, Validation Loss: 0.5112399458885193, Validation Accuracy: 0.98\n",
            "Epoch: 567, Testing Loss: 0.5346752405166626, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 568, Training Loss: 0.5004902482032776, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 568, Validation Loss: 0.5112289786338806, Validation Accuracy: 0.98\n",
            "Epoch: 568, Testing Loss: 0.534695029258728, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 569, Training Loss: 0.5004883408546448, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 569, Validation Loss: 0.5112181305885315, Validation Accuracy: 0.98\n",
            "Epoch: 569, Testing Loss: 0.5347142219543457, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 570, Training Loss: 0.5004863739013672, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 570, Validation Loss: 0.5112073421478271, Validation Accuracy: 0.98\n",
            "Epoch: 570, Testing Loss: 0.5347329378128052, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 571, Training Loss: 0.5004843473434448, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 571, Validation Loss: 0.5111967325210571, Validation Accuracy: 0.98\n",
            "Epoch: 571, Testing Loss: 0.5347511172294617, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 572, Training Loss: 0.5004823803901672, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 572, Validation Loss: 0.5111861824989319, Validation Accuracy: 0.98\n",
            "Epoch: 572, Testing Loss: 0.5347685813903809, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 573, Training Loss: 0.5004803538322449, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 573, Validation Loss: 0.5111758708953857, Validation Accuracy: 0.98\n",
            "Epoch: 573, Testing Loss: 0.5347853302955627, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 574, Training Loss: 0.5004783272743225, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 574, Validation Loss: 0.5111657381057739, Validation Accuracy: 0.98\n",
            "Epoch: 574, Testing Loss: 0.5348014831542969, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 575, Training Loss: 0.5004762411117554, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 575, Validation Loss: 0.5111558437347412, Validation Accuracy: 0.98\n",
            "Epoch: 575, Testing Loss: 0.5348169803619385, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 576, Training Loss: 0.5004741549491882, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 576, Validation Loss: 0.511146068572998, Validation Accuracy: 0.98\n",
            "Epoch: 576, Testing Loss: 0.534831702709198, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 577, Training Loss: 0.5004720687866211, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 577, Validation Loss: 0.511136531829834, Validation Accuracy: 0.98\n",
            "Epoch: 577, Testing Loss: 0.5348457098007202, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 578, Training Loss: 0.5004699230194092, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 578, Validation Loss: 0.511127233505249, Validation Accuracy: 0.98\n",
            "Epoch: 578, Testing Loss: 0.5348590612411499, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 579, Training Loss: 0.5004677176475525, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 579, Validation Loss: 0.5111181735992432, Validation Accuracy: 0.98\n",
            "Epoch: 579, Testing Loss: 0.5348717570304871, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 580, Training Loss: 0.5004655122756958, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 580, Validation Loss: 0.5111093521118164, Validation Accuracy: 0.98\n",
            "Epoch: 580, Testing Loss: 0.5348837971687317, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 581, Training Loss: 0.5004632472991943, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 581, Validation Loss: 0.5111008286476135, Validation Accuracy: 0.98\n",
            "Epoch: 581, Testing Loss: 0.5348951816558838, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 582, Training Loss: 0.5004609823226929, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 582, Validation Loss: 0.511092483997345, Validation Accuracy: 0.98\n",
            "Epoch: 582, Testing Loss: 0.5349059104919434, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 583, Training Loss: 0.5004587173461914, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 583, Validation Loss: 0.5110843777656555, Validation Accuracy: 0.98\n",
            "Epoch: 583, Testing Loss: 0.5349160432815552, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 584, Training Loss: 0.5004564523696899, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 584, Validation Loss: 0.5110765695571899, Validation Accuracy: 0.98\n",
            "Epoch: 584, Testing Loss: 0.5349257588386536, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 585, Training Loss: 0.5004541277885437, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 585, Validation Loss: 0.5110689997673035, Validation Accuracy: 0.98\n",
            "Epoch: 585, Testing Loss: 0.5349347591400146, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 586, Training Loss: 0.5004517436027527, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 586, Validation Loss: 0.5110616087913513, Validation Accuracy: 0.98\n",
            "Epoch: 586, Testing Loss: 0.5349432826042175, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 587, Training Loss: 0.5004494190216064, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 587, Validation Loss: 0.511054515838623, Validation Accuracy: 0.98\n",
            "Epoch: 587, Testing Loss: 0.534951388835907, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 588, Training Loss: 0.5004470348358154, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 588, Validation Loss: 0.5110476016998291, Validation Accuracy: 0.98\n",
            "Epoch: 588, Testing Loss: 0.5349590182304382, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 589, Training Loss: 0.5004445910453796, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 589, Validation Loss: 0.511040985584259, Validation Accuracy: 0.98\n",
            "Epoch: 589, Testing Loss: 0.534966230392456, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 590, Training Loss: 0.5004421472549438, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 590, Validation Loss: 0.5110345482826233, Validation Accuracy: 0.98\n",
            "Epoch: 590, Testing Loss: 0.5349730253219604, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 591, Training Loss: 0.5004397630691528, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 591, Validation Loss: 0.5110283493995667, Validation Accuracy: 0.98\n",
            "Epoch: 591, Testing Loss: 0.5349793434143066, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 592, Training Loss: 0.500437319278717, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 592, Validation Loss: 0.5110223889350891, Validation Accuracy: 0.98\n",
            "Epoch: 592, Testing Loss: 0.5349854230880737, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 593, Training Loss: 0.5004348158836365, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 593, Validation Loss: 0.5110166072845459, Validation Accuracy: 0.98\n",
            "Epoch: 593, Testing Loss: 0.5349911451339722, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 594, Training Loss: 0.5004323720932007, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 594, Validation Loss: 0.511011004447937, Validation Accuracy: 0.98\n",
            "Epoch: 594, Testing Loss: 0.5349964499473572, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 595, Training Loss: 0.5004298686981201, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 595, Validation Loss: 0.5110056400299072, Validation Accuracy: 0.98\n",
            "Epoch: 595, Testing Loss: 0.5350015163421631, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 596, Training Loss: 0.5004274249076843, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 596, Validation Loss: 0.5110004544258118, Validation Accuracy: 0.98\n",
            "Epoch: 596, Testing Loss: 0.5350062847137451, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 597, Training Loss: 0.500424861907959, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 597, Validation Loss: 0.5109954476356506, Validation Accuracy: 0.98\n",
            "Epoch: 597, Testing Loss: 0.5350106954574585, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 598, Training Loss: 0.5004223585128784, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 598, Validation Loss: 0.5109906196594238, Validation Accuracy: 0.98\n",
            "Epoch: 598, Testing Loss: 0.5350149273872375, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 599, Training Loss: 0.5004198551177979, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 599, Validation Loss: 0.5109859704971313, Validation Accuracy: 0.98\n",
            "Epoch: 599, Testing Loss: 0.5350189208984375, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 600, Training Loss: 0.5004172921180725, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 600, Validation Loss: 0.5109815001487732, Validation Accuracy: 0.98\n",
            "Epoch: 600, Testing Loss: 0.5350226163864136, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 601, Training Loss: 0.5004147291183472, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 601, Validation Loss: 0.5109772682189941, Validation Accuracy: 0.98\n",
            "Epoch: 601, Testing Loss: 0.5350068807601929, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 602, Training Loss: 0.5004122257232666, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 602, Validation Loss: 0.5109730362892151, Validation Accuracy: 0.98\n",
            "Epoch: 602, Testing Loss: 0.535029411315918, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 603, Training Loss: 0.5004096627235413, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 603, Validation Loss: 0.5109690427780151, Validation Accuracy: 0.98\n",
            "Epoch: 603, Testing Loss: 0.5350325107574463, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 604, Training Loss: 0.5004070997238159, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 604, Validation Loss: 0.5109651684761047, Validation Accuracy: 0.98\n",
            "Epoch: 604, Testing Loss: 0.5350353121757507, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 605, Training Loss: 0.5004044771194458, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 605, Validation Loss: 0.5109614729881287, Validation Accuracy: 0.98\n",
            "Epoch: 605, Testing Loss: 0.5350380539894104, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 606, Training Loss: 0.5004019141197205, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 606, Validation Loss: 0.5109578967094421, Validation Accuracy: 0.98\n",
            "Epoch: 606, Testing Loss: 0.5350406765937805, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 607, Training Loss: 0.5003993511199951, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 607, Validation Loss: 0.5109544992446899, Validation Accuracy: 0.98\n",
            "Epoch: 607, Testing Loss: 0.5350430011749268, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 608, Training Loss: 0.5003967881202698, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 608, Validation Loss: 0.5109511017799377, Validation Accuracy: 0.98\n",
            "Epoch: 608, Testing Loss: 0.5350452065467834, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 609, Training Loss: 0.5003941059112549, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 609, Validation Loss: 0.5109479427337646, Validation Accuracy: 0.98\n",
            "Epoch: 609, Testing Loss: 0.5350472927093506, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 610, Training Loss: 0.5003915429115295, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 610, Validation Loss: 0.5109447836875916, Validation Accuracy: 0.98\n",
            "Epoch: 610, Testing Loss: 0.5350492000579834, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 611, Training Loss: 0.5003889203071594, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 611, Validation Loss: 0.5109418034553528, Validation Accuracy: 0.98\n",
            "Epoch: 611, Testing Loss: 0.5350509881973267, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 612, Training Loss: 0.5003862977027893, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 612, Validation Loss: 0.5109388828277588, Validation Accuracy: 0.98\n",
            "Epoch: 612, Testing Loss: 0.5350526571273804, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 613, Training Loss: 0.5003836750984192, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 613, Validation Loss: 0.5109361410140991, Validation Accuracy: 0.98\n",
            "Epoch: 613, Testing Loss: 0.5350541472434998, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 614, Training Loss: 0.5003811120986938, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 614, Validation Loss: 0.5109333992004395, Validation Accuracy: 0.98\n",
            "Epoch: 614, Testing Loss: 0.5350556373596191, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 615, Training Loss: 0.500378429889679, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 615, Validation Loss: 0.5109308362007141, Validation Accuracy: 0.98\n",
            "Epoch: 615, Testing Loss: 0.5350568890571594, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 616, Training Loss: 0.5003758072853088, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 616, Validation Loss: 0.5109282732009888, Validation Accuracy: 0.98\n",
            "Epoch: 616, Testing Loss: 0.5350582003593445, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 617, Training Loss: 0.5003731846809387, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 617, Validation Loss: 0.5109258890151978, Validation Accuracy: 0.98\n",
            "Epoch: 617, Testing Loss: 0.5350592136383057, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 618, Training Loss: 0.5003705024719238, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 618, Validation Loss: 0.5109235048294067, Validation Accuracy: 0.98\n",
            "Epoch: 618, Testing Loss: 0.5350602269172668, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 619, Training Loss: 0.5003678202629089, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 619, Validation Loss: 0.5109212398529053, Validation Accuracy: 0.98\n",
            "Epoch: 619, Testing Loss: 0.5350611209869385, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 620, Training Loss: 0.5003651976585388, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 620, Validation Loss: 0.5109189748764038, Validation Accuracy: 0.98\n",
            "Epoch: 620, Testing Loss: 0.5350619554519653, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 621, Training Loss: 0.5003625154495239, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 621, Validation Loss: 0.5109168887138367, Validation Accuracy: 0.98\n",
            "Epoch: 621, Testing Loss: 0.5350626707077026, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 622, Training Loss: 0.5003597736358643, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 622, Validation Loss: 0.5109148025512695, Validation Accuracy: 0.98\n",
            "Epoch: 622, Testing Loss: 0.5350633263587952, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 623, Training Loss: 0.5003570914268494, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 623, Validation Loss: 0.5109127759933472, Validation Accuracy: 0.98\n",
            "Epoch: 623, Testing Loss: 0.5350638628005981, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 624, Training Loss: 0.5003544092178345, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 624, Validation Loss: 0.5109108090400696, Validation Accuracy: 0.98\n",
            "Epoch: 624, Testing Loss: 0.5350643992424011, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 625, Training Loss: 0.5003517270088196, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 625, Validation Loss: 0.5109089016914368, Validation Accuracy: 0.98\n",
            "Epoch: 625, Testing Loss: 0.5350648164749146, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 626, Training Loss: 0.5003489851951599, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 626, Validation Loss: 0.5109070539474487, Validation Accuracy: 0.98\n",
            "Epoch: 626, Testing Loss: 0.5350651144981384, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 627, Training Loss: 0.5003462433815002, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 627, Validation Loss: 0.5109052658081055, Validation Accuracy: 0.98\n",
            "Epoch: 627, Testing Loss: 0.5350654125213623, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 628, Training Loss: 0.5003435611724854, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 628, Validation Loss: 0.5109034776687622, Validation Accuracy: 0.98\n",
            "Epoch: 628, Testing Loss: 0.5350656509399414, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 629, Training Loss: 0.5003408193588257, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 629, Validation Loss: 0.5109017491340637, Validation Accuracy: 0.98\n",
            "Epoch: 629, Testing Loss: 0.5350658297538757, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 630, Training Loss: 0.5003380179405212, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 630, Validation Loss: 0.51090008020401, Validation Accuracy: 0.98\n",
            "Epoch: 630, Testing Loss: 0.5350659489631653, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 631, Training Loss: 0.5003352761268616, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 631, Validation Loss: 0.5108984708786011, Validation Accuracy: 0.98\n",
            "Epoch: 631, Testing Loss: 0.5350660085678101, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 632, Training Loss: 0.5003324747085571, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 632, Validation Loss: 0.5108968615531921, Validation Accuracy: 0.98\n",
            "Epoch: 632, Testing Loss: 0.5350660681724548, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 633, Training Loss: 0.5003296732902527, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 633, Validation Loss: 0.510895311832428, Validation Accuracy: 0.98\n",
            "Epoch: 633, Testing Loss: 0.5350660085678101, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 634, Training Loss: 0.500326931476593, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 634, Validation Loss: 0.5108938217163086, Validation Accuracy: 0.98\n",
            "Epoch: 634, Testing Loss: 0.5350658297538757, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 635, Training Loss: 0.500324010848999, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 635, Validation Loss: 0.5108922719955444, Validation Accuracy: 0.98\n",
            "Epoch: 635, Testing Loss: 0.535065770149231, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 636, Training Loss: 0.5003212094306946, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 636, Validation Loss: 0.5108908414840698, Validation Accuracy: 0.98\n",
            "Epoch: 636, Testing Loss: 0.5350656509399414, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 637, Training Loss: 0.5003184080123901, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 637, Validation Loss: 0.5108894109725952, Validation Accuracy: 0.98\n",
            "Epoch: 637, Testing Loss: 0.5350653529167175, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 638, Training Loss: 0.5003155469894409, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 638, Validation Loss: 0.5108880400657654, Validation Accuracy: 0.98\n",
            "Epoch: 638, Testing Loss: 0.5350651741027832, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 639, Training Loss: 0.5003126263618469, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 639, Validation Loss: 0.5108866095542908, Validation Accuracy: 0.98\n",
            "Epoch: 639, Testing Loss: 0.5350649356842041, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 640, Training Loss: 0.5003097653388977, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 640, Validation Loss: 0.5108852386474609, Validation Accuracy: 0.98\n",
            "Epoch: 640, Testing Loss: 0.5350645184516907, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 641, Training Loss: 0.5003068447113037, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 641, Validation Loss: 0.5108839273452759, Validation Accuracy: 0.98\n",
            "Epoch: 641, Testing Loss: 0.535064160823822, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 642, Training Loss: 0.5003038644790649, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 642, Validation Loss: 0.510882556438446, Validation Accuracy: 0.98\n",
            "Epoch: 642, Testing Loss: 0.5350637435913086, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 643, Training Loss: 0.500300943851471, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 643, Validation Loss: 0.510881245136261, Validation Accuracy: 0.98\n",
            "Epoch: 643, Testing Loss: 0.5350634455680847, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 644, Training Loss: 0.5002979636192322, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 644, Validation Loss: 0.5108799934387207, Validation Accuracy: 0.98\n",
            "Epoch: 644, Testing Loss: 0.5350629687309265, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 645, Training Loss: 0.5002949833869934, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 645, Validation Loss: 0.5108787417411804, Validation Accuracy: 0.98\n",
            "Epoch: 645, Testing Loss: 0.5350624918937683, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 646, Training Loss: 0.5002920031547546, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 646, Validation Loss: 0.5108774304389954, Validation Accuracy: 0.98\n",
            "Epoch: 646, Testing Loss: 0.5350620150566101, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 647, Training Loss: 0.5002889633178711, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 647, Validation Loss: 0.5108762979507446, Validation Accuracy: 0.98\n",
            "Epoch: 647, Testing Loss: 0.5350614786148071, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 648, Training Loss: 0.5002858638763428, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 648, Validation Loss: 0.5108749866485596, Validation Accuracy: 0.98\n",
            "Epoch: 648, Testing Loss: 0.5350609421730042, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 649, Training Loss: 0.5002827644348145, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 649, Validation Loss: 0.5108737945556641, Validation Accuracy: 0.98\n",
            "Epoch: 649, Testing Loss: 0.5350604057312012, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 650, Training Loss: 0.5002796649932861, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 650, Validation Loss: 0.5108726024627686, Validation Accuracy: 0.98\n",
            "Epoch: 650, Testing Loss: 0.5350598692893982, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 651, Training Loss: 0.500276505947113, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 651, Validation Loss: 0.510871410369873, Validation Accuracy: 0.98\n",
            "Epoch: 651, Testing Loss: 0.5350592136383057, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 652, Training Loss: 0.5002733469009399, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 652, Validation Loss: 0.5108771324157715, Validation Accuracy: 0.98\n",
            "Epoch: 652, Testing Loss: 0.5350586175918579, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 653, Training Loss: 0.5002701282501221, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 653, Validation Loss: 0.510869026184082, Validation Accuracy: 0.98\n",
            "Epoch: 653, Testing Loss: 0.5350580811500549, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 654, Training Loss: 0.5002669095993042, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 654, Validation Loss: 0.5108678340911865, Validation Accuracy: 0.98\n",
            "Epoch: 654, Testing Loss: 0.5350573658943176, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 655, Training Loss: 0.5002636909484863, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 655, Validation Loss: 0.510866641998291, Validation Accuracy: 0.98\n",
            "Epoch: 655, Testing Loss: 0.5350567102432251, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 656, Training Loss: 0.5002603530883789, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 656, Validation Loss: 0.5108655095100403, Validation Accuracy: 0.98\n",
            "Epoch: 656, Testing Loss: 0.5350560545921326, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 657, Training Loss: 0.5002570152282715, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 657, Validation Loss: 0.5108643770217896, Validation Accuracy: 0.98\n",
            "Epoch: 657, Testing Loss: 0.5350554585456848, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 658, Training Loss: 0.5002536773681641, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 658, Validation Loss: 0.5108632445335388, Validation Accuracy: 0.98\n",
            "Epoch: 658, Testing Loss: 0.5350546836853027, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 659, Training Loss: 0.5002502202987671, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 659, Validation Loss: 0.5108620524406433, Validation Accuracy: 0.98\n",
            "Epoch: 659, Testing Loss: 0.5350540280342102, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 660, Training Loss: 0.5002467632293701, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 660, Validation Loss: 0.5108609199523926, Validation Accuracy: 0.98\n",
            "Epoch: 660, Testing Loss: 0.5350533127784729, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 661, Training Loss: 0.5002433061599731, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 661, Validation Loss: 0.5108597874641418, Validation Accuracy: 0.98\n",
            "Epoch: 661, Testing Loss: 0.5350526571273804, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 662, Training Loss: 0.5002397298812866, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 662, Validation Loss: 0.5108585953712463, Validation Accuracy: 0.98\n",
            "Epoch: 662, Testing Loss: 0.5350518822669983, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 663, Training Loss: 0.5002361536026001, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 663, Validation Loss: 0.5108574628829956, Validation Accuracy: 0.98\n",
            "Epoch: 663, Testing Loss: 0.535051167011261, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 664, Training Loss: 0.5002325177192688, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 664, Validation Loss: 0.5108563303947449, Validation Accuracy: 0.98\n",
            "Epoch: 664, Testing Loss: 0.5350505113601685, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 665, Training Loss: 0.5002288222312927, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 665, Validation Loss: 0.5108551979064941, Validation Accuracy: 0.98\n",
            "Epoch: 665, Testing Loss: 0.5350497364997864, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 666, Training Loss: 0.5002251267433167, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 666, Validation Loss: 0.5108540058135986, Validation Accuracy: 0.98\n",
            "Epoch: 666, Testing Loss: 0.5350490808486938, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 667, Training Loss: 0.5002212524414062, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 667, Validation Loss: 0.5108528733253479, Validation Accuracy: 0.98\n",
            "Epoch: 667, Testing Loss: 0.5350483059883118, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 668, Training Loss: 0.5002174377441406, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 668, Validation Loss: 0.5108517408370972, Validation Accuracy: 0.98\n",
            "Epoch: 668, Testing Loss: 0.5350475907325745, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 669, Training Loss: 0.5002135038375854, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 669, Validation Loss: 0.5108505487442017, Validation Accuracy: 0.98\n",
            "Epoch: 669, Testing Loss: 0.5350468158721924, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 670, Training Loss: 0.5002095103263855, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 670, Validation Loss: 0.5108494162559509, Validation Accuracy: 0.98\n",
            "Epoch: 670, Testing Loss: 0.5350461602210999, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 671, Training Loss: 0.5002055168151855, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 671, Validation Loss: 0.5108482241630554, Validation Accuracy: 0.98\n",
            "Epoch: 671, Testing Loss: 0.5350454449653625, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 672, Training Loss: 0.500201404094696, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 672, Validation Loss: 0.5108470916748047, Validation Accuracy: 0.98\n",
            "Epoch: 672, Testing Loss: 0.5350447297096252, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 673, Training Loss: 0.5001972317695618, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 673, Validation Loss: 0.5108458995819092, Validation Accuracy: 0.98\n",
            "Epoch: 673, Testing Loss: 0.5350439548492432, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 674, Training Loss: 0.5001929998397827, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 674, Validation Loss: 0.5108447670936584, Validation Accuracy: 0.98\n",
            "Epoch: 674, Testing Loss: 0.5350432395935059, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 675, Training Loss: 0.5001886487007141, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 675, Validation Loss: 0.5108435153961182, Validation Accuracy: 0.98\n",
            "Epoch: 675, Testing Loss: 0.5350425243377686, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 676, Training Loss: 0.5001842975616455, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 676, Validation Loss: 0.5108423829078674, Validation Accuracy: 0.98\n",
            "Epoch: 676, Testing Loss: 0.535041868686676, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 677, Training Loss: 0.5001798272132874, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 677, Validation Loss: 0.5108411908149719, Validation Accuracy: 0.98\n",
            "Epoch: 677, Testing Loss: 0.5350411534309387, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 678, Training Loss: 0.5001752376556396, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 678, Validation Loss: 0.5108399987220764, Validation Accuracy: 0.98\n",
            "Epoch: 678, Testing Loss: 0.5350404381752014, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 679, Training Loss: 0.5001705884933472, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 679, Validation Loss: 0.5108387470245361, Validation Accuracy: 0.98\n",
            "Epoch: 679, Testing Loss: 0.5350397825241089, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 680, Training Loss: 0.5001658201217651, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 680, Validation Loss: 0.5108376145362854, Validation Accuracy: 0.98\n",
            "Epoch: 680, Testing Loss: 0.5350391268730164, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 681, Training Loss: 0.5001609921455383, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 681, Validation Loss: 0.5108363628387451, Validation Accuracy: 0.98\n",
            "Epoch: 681, Testing Loss: 0.535038411617279, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 682, Training Loss: 0.500156044960022, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 682, Validation Loss: 0.5108351707458496, Validation Accuracy: 0.98\n",
            "Epoch: 682, Testing Loss: 0.5350377559661865, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 683, Training Loss: 0.5001510381698608, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 683, Validation Loss: 0.5108339190483093, Validation Accuracy: 0.98\n",
            "Epoch: 683, Testing Loss: 0.5350370407104492, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 684, Training Loss: 0.5001459121704102, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 684, Validation Loss: 0.5108327269554138, Validation Accuracy: 0.98\n",
            "Epoch: 684, Testing Loss: 0.5350363850593567, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 685, Training Loss: 0.5001406669616699, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 685, Validation Loss: 0.5108314752578735, Validation Accuracy: 0.98\n",
            "Epoch: 685, Testing Loss: 0.5350357294082642, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 686, Training Loss: 0.5001353621482849, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 686, Validation Loss: 0.5108301639556885, Validation Accuracy: 0.98\n",
            "Epoch: 686, Testing Loss: 0.5350350141525269, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 687, Training Loss: 0.5001299381256104, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 687, Validation Loss: 0.5108289122581482, Validation Accuracy: 0.98\n",
            "Epoch: 687, Testing Loss: 0.5350343585014343, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 688, Training Loss: 0.5001243352890015, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 688, Validation Loss: 0.5108306407928467, Validation Accuracy: 0.98\n",
            "Epoch: 688, Testing Loss: 0.5350337028503418, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 689, Training Loss: 0.5001186728477478, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 689, Validation Loss: 0.5108264088630676, Validation Accuracy: 0.98\n",
            "Epoch: 689, Testing Loss: 0.5350330471992493, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 690, Training Loss: 0.5001128315925598, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 690, Validation Loss: 0.5108251571655273, Validation Accuracy: 0.98\n",
            "Epoch: 690, Testing Loss: 0.535032331943512, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 691, Training Loss: 0.500106930732727, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 691, Validation Loss: 0.5108238458633423, Validation Accuracy: 0.98\n",
            "Epoch: 691, Testing Loss: 0.5350316762924194, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 692, Training Loss: 0.5001009106636047, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 692, Validation Loss: 0.510822594165802, Validation Accuracy: 0.98\n",
            "Epoch: 692, Testing Loss: 0.5350309014320374, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 693, Training Loss: 0.5000947713851929, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 693, Validation Loss: 0.5108213424682617, Validation Accuracy: 0.98\n",
            "Epoch: 693, Testing Loss: 0.5350301861763, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 694, Training Loss: 0.5000885128974915, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 694, Validation Loss: 0.5108200311660767, Validation Accuracy: 0.98\n",
            "Epoch: 694, Testing Loss: 0.5350294709205627, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 695, Training Loss: 0.5000820755958557, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 695, Validation Loss: 0.5108187198638916, Validation Accuracy: 0.98\n",
            "Epoch: 695, Testing Loss: 0.5350286960601807, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 696, Training Loss: 0.5000755786895752, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 696, Validation Loss: 0.5108174681663513, Validation Accuracy: 0.98\n",
            "Epoch: 696, Testing Loss: 0.5350279211997986, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 697, Training Loss: 0.5000689029693604, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 697, Validation Loss: 0.510816216468811, Validation Accuracy: 0.98\n",
            "Epoch: 697, Testing Loss: 0.5350271463394165, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 698, Training Loss: 0.500062108039856, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 698, Validation Loss: 0.510814905166626, Validation Accuracy: 0.98\n",
            "Epoch: 698, Testing Loss: 0.5350263118743896, Testing Accuracy: 0.9724137931034482\n",
            "Epoch: 699, Training Loss: 0.500055193901062, Training Accuracy: 0.9724137931034482\n",
            "Epoch: 699, Validation Loss: 0.5108136534690857, Validation Accuracy: 0.98\n",
            "Epoch: 699, Testing Loss: 0.535025417804718, Testing Accuracy: 0.9724137931034482\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVcZHvug8fLQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotting_loss(epoch, training_error, validation_error, testing_error, title):\n",
        "    epoch_idx = np.arange(0, epoch)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.plot(epoch_idx,training_error)\n",
        "    plt.plot(epoch_idx,validation_error)\n",
        "    plt.plot(epoch_idx,testing_error)\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training Loss', 'Validation Loss', 'Testing Loss'])\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn6jaufL8jKS",
        "colab_type": "code",
        "outputId": "8de55164-58fc-4113-fdd4-16ea3d09a231",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plotting_loss(epochs, training_loss, validation_loss, testing_loss,\"BCE Losses of SGD w/ epsilon of 1e-04, lr of 0.001, and batch of 500 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAJcCAYAAAC8DwN/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiUkMUzkRERERqiMKZiIiISA35/4nKlTkXV1Y5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Xca-jC8oS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotting_accuracy(epoch, training_accuracy, validation_accuracy, testing_accuracy, title):\n",
        "    epoch_idx = np.arange(0, epoch)\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.plot(epoch_idx,training_accuracy)\n",
        "    plt.plot(epoch_idx,validation_accuracy)\n",
        "    plt.plot(epoch_idx,testing_accuracy)\n",
        "    plt.xlabel('Number of Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(['Training Accuracy', 'Validation Accuracy', 'Testing Accuracy'])\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1-XWZFT9sCu",
        "colab_type": "code",
        "outputId": "75d95b4d-8da6-4f07-e48a-62857c172023",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        }
      },
      "source": [
        "plotting_accuracy(epochs, training_accuracy, validation_accuracy, testing_accuracy, \"BCE Accuracy of SGD w/ epsilon of 1e-04, lr of 0.001, and batch of 500 on notMNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAJcCAYAAACxEXM4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQJMwpZRSSikX0CRMKaWUUsoF/j++yBXBqk5ZdAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpACPdRi9wLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}